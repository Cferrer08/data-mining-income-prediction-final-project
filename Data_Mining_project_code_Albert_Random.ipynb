{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/albertbaezd/data-mining-final-project/blob/develop/Data_Mining_project_code_Albert_Random.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "c-24Su6VnRt3"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from google.colab import drive\n",
        "from sklearn.utils import resample\n",
        "import matplotlib.pyplot as plt\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import seaborn as sns\n",
        "\n",
        "\n",
        "# import the datasets: -  - Albert: remove comment if you want to manually place the files here. If not, it's going to use a Google Drive folder\n",
        "# train_data = pd.read_csv(\"census-income.data.csv\") - Albert: remove comment if you want to manually place the files here. If not, it's going to use a Google Drive folder\n",
        "# test_data = pd.read_csv(\"census-income.test.csv\")  - Albert: remove comment if you want to manually place the files here. If not, it's going to use a Google Drive folder\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QmTZkEWhn0w0",
        "outputId": "127e3c32-36d6-4652-fac9-97006070da91"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "       Unnamed: 0   age  work-class    fnlwgt  education_num  marital-status  \\\n",
            "0               0  39.0         6.0   77516.0           13.0             4.0   \n",
            "1               1  50.0         5.0   83311.0           13.0             2.0   \n",
            "2               2  38.0         3.0  215646.0            9.0             0.0   \n",
            "3               3  53.0         3.0  234721.0            7.0             2.0   \n",
            "4               4  28.0         3.0  338409.0           13.0             2.0   \n",
            "...           ...   ...         ...       ...            ...             ...   \n",
            "32556       32556  27.0         3.0  257302.0           12.0             2.0   \n",
            "32557       32557  40.0         3.0  154374.0            9.0             2.0   \n",
            "32558       32558  58.0         3.0  151910.0            9.0             6.0   \n",
            "32559       32559  22.0         3.0  201490.0            9.0             4.0   \n",
            "32560       32560  52.0         4.0  287927.0            9.0             2.0   \n",
            "\n",
            "       relationship  race  sex  capital-gain  capital-loss  \\\n",
            "0               1.0   4.0  1.0        2174.0           0.0   \n",
            "1               0.0   4.0  1.0           0.0           0.0   \n",
            "2               1.0   4.0  1.0           0.0           0.0   \n",
            "3               0.0   2.0  1.0           0.0           0.0   \n",
            "4               5.0   2.0  0.0           0.0           0.0   \n",
            "...             ...   ...  ...           ...           ...   \n",
            "32556           5.0   4.0  0.0           0.0           0.0   \n",
            "32557           0.0   4.0  1.0           0.0           0.0   \n",
            "32558           4.0   4.0  0.0           0.0           0.0   \n",
            "32559           3.0   4.0  1.0           0.0           0.0   \n",
            "32560           5.0   4.0  0.0       15024.0           0.0   \n",
            "\n",
            "       hours-worked-per-week  native-country  occupation  income  \n",
            "0                       40.0            38.0           0       0  \n",
            "1                       13.0            38.0           3       0  \n",
            "2                       40.0            38.0           5       0  \n",
            "3                       40.0            38.0           5       0  \n",
            "4                       40.0             4.0           9       0  \n",
            "...                      ...             ...         ...     ...  \n",
            "32556                   38.0            38.0          12       0  \n",
            "32557                   40.0            38.0           6       1  \n",
            "32558                   40.0            38.0           0       0  \n",
            "32559                   20.0            38.0           0       0  \n",
            "32560                   40.0            38.0           3       1  \n",
            "\n",
            "[32561 rows x 15 columns]\n",
            "       Unnamed: 0   age  work-class    fnlwgt  education_num  marital-status  \\\n",
            "0               0  25.0         3.0  226802.0            7.0             4.0   \n",
            "1               1  38.0         3.0   89814.0            9.0             2.0   \n",
            "2               2  28.0         1.0  336951.0           12.0             2.0   \n",
            "3               3  44.0         3.0  160323.0           10.0             2.0   \n",
            "4               4  18.0         3.0  103497.0           10.0             4.0   \n",
            "...           ...   ...         ...       ...            ...             ...   \n",
            "16276       16276  39.0         3.0  215419.0           13.0             0.0   \n",
            "16277       16277  64.0         3.0  321403.0            9.0             6.0   \n",
            "16278       16278  38.0         3.0  374983.0           13.0             2.0   \n",
            "16279       16279  44.0         3.0   83891.0           13.0             0.0   \n",
            "16280       16280  35.0         4.0  182148.0           13.0             2.0   \n",
            "\n",
            "       relationship  race  sex  capital-gain  capital-loss  \\\n",
            "0               3.0   2.0  1.0           0.0           0.0   \n",
            "1               0.0   4.0  1.0           0.0           0.0   \n",
            "2               0.0   4.0  1.0           0.0           0.0   \n",
            "3               0.0   2.0  1.0        7688.0           0.0   \n",
            "4               3.0   4.0  0.0           0.0           0.0   \n",
            "...             ...   ...  ...           ...           ...   \n",
            "16276           1.0   4.0  0.0           0.0           0.0   \n",
            "16277           2.0   2.0  1.0           0.0           0.0   \n",
            "16278           0.0   4.0  1.0           0.0           0.0   \n",
            "16279           3.0   1.0  1.0        5455.0           0.0   \n",
            "16280           0.0   4.0  1.0           0.0           0.0   \n",
            "\n",
            "       hours-worked-per-week  native-country  occupation  income  \n",
            "0                       40.0            37.0           6       0  \n",
            "1                       50.0            37.0           4       0  \n",
            "2                       40.0            37.0          10       1  \n",
            "3                       40.0            37.0           6       1  \n",
            "4                       30.0            37.0          14       0  \n",
            "...                      ...             ...         ...     ...  \n",
            "16276                   36.0            37.0           9       0  \n",
            "16277                   40.0            37.0          14       0  \n",
            "16278                   50.0            37.0           9       0  \n",
            "16279                   40.0            37.0           0       0  \n",
            "16280                   60.0            37.0           3       1  \n",
            "\n",
            "[16281 rows x 15 columns]\n"
          ]
        }
      ],
      "source": [
        "'''\n",
        "Here, we authenticate with Google Drive to add the datafiles from a Drive folder\n",
        "\n",
        "Instructions:\n",
        "\n",
        "1. Create a folder in your Google Drive, called data-mining-csv-files\n",
        "2. Insert both csv files (test and train) with the original names there.\n",
        "3. Just run this cell to import the code\n",
        "'''\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# train_data = pd.read_csv(\"/content/drive/My Drive/data-mining-csv-files/census-income.data.csv\") #- Albert: remove comment if you want to manually place the files here. If not, it's going to use a Google Drive folder\n",
        "# test_data = pd.read_csv(\"/content/drive/My Drive/data-mining-csv-files/census-income.test.csv\")  #- Albert: remove comment if you want to manually place the files here. If not, it's going to use a Google Drive folder\n",
        "train_data = pd.read_csv(\"/content/drive/My Drive/data-mining-csv-files/train_data_d.csv\") #- Albert: remove comment if you want to manually place the files here. If not, it's going to use a Google Drive folder\n",
        "test_data = pd.read_csv(\"/content/drive/My Drive/data-mining-csv-files/test_data_d.csv\")  #- Albert: remove comment if you want to manually place the files here. If not, it's going to use a Google Drive folder\n",
        "\n",
        "# Displaying results:\n",
        "\n",
        "print(train_data)\n",
        "print(test_data)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uqDHw3rz0hV7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Class Distribution: Plot the distribution of the target variable (income)\n",
        "# to check for class imbalance.\n",
        "\n",
        "# Set up a subplot grid for training and testing distributions\n",
        "fig, axs = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "# Different sky-blue-themed colors\n",
        "train_palette = ['skyblue', 'deepskyblue']\n",
        "test_palette = ['skyblue', 'deepskyblue']\n",
        "\n",
        "# Training data\n",
        "sns.countplot(x='income', data=train_data, ax=axs[0], palette=train_palette)\n",
        "axs[0].set_title('Training Data Income Distribution')\n",
        "axs[0].set_ylabel('Count')\n",
        "axs[0].set_xlabel('Income')\n",
        "\n",
        "# Testing data\n",
        "sns.countplot(x='income', data=test_data, ax=axs[1], palette=test_palette)\n",
        "axs[1].set_title('Testing Data Income Distribution')\n",
        "axs[1].set_ylabel('Count')\n",
        "axs[1].set_xlabel('Income')\n",
        "\n",
        "# Adjust layout\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 437
        },
        "id": "Ef3XL2rIbIZr",
        "outputId": "8ceeff3a-9354-4ecc-9b21-d5958b8f6a21"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-a472cde6df97>:12: FutureWarning: \n",
            "\n",
            "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n",
            "\n",
            "  sns.countplot(x='income', data=train_data, ax=axs[0], palette=train_palette)\n",
            "<ipython-input-25-a472cde6df97>:18: FutureWarning: \n",
            "\n",
            "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n",
            "\n",
            "  sns.countplot(x='income', data=test_data, ax=axs[1], palette=test_palette)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1400x500 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "V0: just OHE\n",
        "'''\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# Assuming train_data and test_data are already loaded as dataframes\n",
        "# train_data, test_data\n",
        "\n",
        "# Function to preprocess data\n",
        "def preprocess_data(data, transformer=None, is_train=True):\n",
        "    print(\"Initial columns:\", data.columns)  # Initial check of all columns in the dataset\n",
        "\n",
        "    income_column = 'income'\n",
        "    if income_column not in data.columns:\n",
        "        raise ValueError(f\"The column '{income_column}' does not exist in the dataset.\")\n",
        "\n",
        "    # If it's test data, handle the period at the end\n",
        "    if not is_train:\n",
        "        data[income_column] = data[income_column].str.strip().str.replace('.', '')\n",
        "        print(\"Adjusted 'income' for test data:\", data[income_column].unique())  # Debug\n",
        "\n",
        "    # Identify and store categorical features excluding 'income'\n",
        "    categorical_features = data.select_dtypes(include=['object']).columns.tolist()\n",
        "    if income_column in categorical_features:\n",
        "        categorical_features.remove(income_column)\n",
        "    print(\"Categorical features before encoding:\", categorical_features)  # Debug statement\n",
        "\n",
        "    # Apply ColumnTransformer only to categorical features excluding 'income'\n",
        "    if transformer is None:\n",
        "        transformer = ColumnTransformer(\n",
        "            transformers=[('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)],\n",
        "            remainder='passthrough')\n",
        "        X = transformer.fit_transform(data.drop(columns=[income_column]))\n",
        "    else:\n",
        "        X = transformer.transform(data.drop(columns=[income_column]))\n",
        "\n",
        "    # Now encode the 'income' column after categorical handling\n",
        "    y = LabelEncoder().fit_transform(data[income_column])\n",
        "    print(\"Encoded 'income':\", np.unique(y))  # Debug the output of the encoded income\n",
        "\n",
        "    return X, y, transformer\n",
        "\n",
        "# Function to train the Random Forest model\n",
        "def train_random_forest(X, y):\n",
        "    model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "    model.fit(X, y)\n",
        "\n",
        "    return model\n",
        "\n",
        "# Evaluate the model\n",
        "def evaluate_model(model, X, y):\n",
        "    y_pred = model.predict(X)\n",
        "    accuracy = accuracy_score(y, y_pred)\n",
        "    report = classification_report(y, y_pred)\n",
        "\n",
        "    return accuracy, report\n",
        "\n",
        "# Main execution function\n",
        "def main():\n",
        "    # Preprocess training data\n",
        "    X_train, y_train, transformer = preprocess_data(train_data, is_train=True)\n",
        "\n",
        "    # Train model without SMOTE\n",
        "    model = train_random_forest(X_train, y_train)\n",
        "\n",
        "    # Preprocess testing data using the same transformer\n",
        "    X_test, y_test, _ = preprocess_data(test_data, transformer, is_train=False)\n",
        "\n",
        "    # Evaluate the test model\n",
        "    accuracy_test, report_test = evaluate_model(model, X_test, y_test)\n",
        "    print(f'Accuracy (Test Data): {accuracy_test}')\n",
        "    print(f'Classification Report (Test Data):\\n{report_test}')\n",
        "\n",
        "    # Evaluate the training model to check for overfitting\n",
        "    accuracy_train, report_train = evaluate_model(model, X_train, y_train)\n",
        "    print(f'Accuracy (Training Data): {accuracy_train}')\n",
        "    print(f'Classification Report (Training Data):\\n{report_train}')\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()\n"
      ],
      "metadata": {
        "id": "TVcTc1YG0jVb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3c2f1950-a8c3-4d73-84e3-d6a8488509c5"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial columns: Index(['age', 'work-class', 'fnlwgt', 'education', 'education_num',\n",
            "       'marital-status', 'occupation', 'relationship', 'race', 'sex',\n",
            "       'capital-gain', 'capital-loss', 'hours-worked-per-week',\n",
            "       'native-country', 'income'],\n",
            "      dtype='object')\n",
            "Categorical features before encoding: ['work-class', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'native-country']\n",
            "Encoded 'income': [0 1]\n",
            "Initial columns: Index(['age', 'work-class', 'fnlwgt', 'education', 'education_num',\n",
            "       'marital-status', 'occupation', 'relationship', 'race', 'sex',\n",
            "       'capital-gain', 'capital-loss', 'hours-worked-per-week',\n",
            "       'native-country', 'income'],\n",
            "      dtype='object')\n",
            "Adjusted 'income' for test data: ['<=50K' '>50K']\n",
            "Categorical features before encoding: ['work-class', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'native-country']\n",
            "Encoded 'income': [0 1]\n",
            "Accuracy (Test Data): 0.8515447454087587\n",
            "Classification Report (Test Data):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.93      0.91     12435\n",
            "           1       0.72      0.61      0.66      3846\n",
            "\n",
            "    accuracy                           0.85     16281\n",
            "   macro avg       0.80      0.77      0.78     16281\n",
            "weighted avg       0.85      0.85      0.85     16281\n",
            "\n",
            "Accuracy (Training Data): 0.9999692884125181\n",
            "Classification Report (Training Data):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00     24720\n",
            "           1       1.00      1.00      1.00      7841\n",
            "\n",
            "    accuracy                           1.00     32561\n",
            "   macro avg       1.00      1.00      1.00     32561\n",
            "weighted avg       1.00      1.00      1.00     32561\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DMxm_vjjcTWh",
        "outputId": "b489b58c-778d-4f90-ae60-a32168a8ca57"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial columns: Index(['age', 'work-class', 'fnlwgt', 'education', 'education_num',\n",
            "       'marital-status', 'occupation', 'relationship', 'race', 'sex',\n",
            "       'capital-gain', 'capital-loss', 'hours-worked-per-week',\n",
            "       'native-country', 'income'],\n",
            "      dtype='object')\n",
            "Categorical features before encoding: ['work-class', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'native-country']\n",
            "Encoded 'income': [0 1]\n",
            "Initial columns: Index(['age', 'work-class', 'fnlwgt', 'education', 'education_num',\n",
            "       'marital-status', 'occupation', 'relationship', 'race', 'sex',\n",
            "       'capital-gain', 'capital-loss', 'hours-worked-per-week',\n",
            "       'native-country', 'income'],\n",
            "      dtype='object')\n",
            "Adjusted 'income' for test data: ['<=50K' '>50K']\n",
            "Categorical features before encoding: ['work-class', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'native-country']\n",
            "Encoded 'income': [0 1]\n",
            "Accuracy test: 0.8487193661323015\n",
            "Classification Report test:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      0.92      0.90     12435\n",
            "           1       0.70      0.62      0.66      3846\n",
            "\n",
            "    accuracy                           0.85     16281\n",
            "   macro avg       0.80      0.77      0.78     16281\n",
            "weighted avg       0.84      0.85      0.85     16281\n",
            "\n",
            "Accuracy train: 0.9998771536500721\n",
            "Classification Report train:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00     24720\n",
            "           1       1.00      1.00      1.00      7841\n",
            "\n",
            "    accuracy                           1.00     32561\n",
            "   macro avg       1.00      1.00      1.00     32561\n",
            "weighted avg       1.00      1.00      1.00     32561\n",
            "\n"
          ]
        }
      ],
      "source": [
        "'''\n",
        "One Hot Encoding Implementation, Smote # default, version 1\n",
        "'''\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "\n",
        "# Assuming train_data and test_data are already loaded as dataframes\n",
        "# train_data, test_data\n",
        "\n",
        "# Function to preprocess data\n",
        "\n",
        "def preprocess_data(data, transformer=None, is_train=True):\n",
        "    print(\"Initial columns:\", data.columns)  # Initial check of all columns in the dataset\n",
        "\n",
        "    income_column = 'income'\n",
        "    if income_column not in data.columns:\n",
        "        raise ValueError(f\"The column '{income_column}' does not exist in the dataset.\")\n",
        "\n",
        "    # If it's test data, handle the period at the end\n",
        "    if not is_train:\n",
        "        data[income_column] = data[income_column].str.strip().str.replace('.', '')\n",
        "        print(\"Adjusted 'income' for test data:\", data[income_column].unique())  # Debug\n",
        "\n",
        "    # Identify and store categorical features excluding 'income'\n",
        "    categorical_features = data.select_dtypes(include=['object']).columns.tolist()\n",
        "    if income_column in categorical_features:\n",
        "        categorical_features.remove(income_column)\n",
        "    print(\"Categorical features before encoding:\", categorical_features)  # Debug statement\n",
        "\n",
        "    # Apply ColumnTransformer only to categorical features excluding 'income'\n",
        "    if transformer is None:\n",
        "        transformer = ColumnTransformer(\n",
        "            transformers=[('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)],\n",
        "            remainder='passthrough')\n",
        "        X = transformer.fit_transform(data.drop(columns=[income_column]))\n",
        "    else:\n",
        "        X = transformer.transform(data.drop(columns=[income_column]))\n",
        "\n",
        "    # Now encode the 'income' column after categorical handling\n",
        "    y = LabelEncoder().fit_transform(data[income_column])\n",
        "    print(\"Encoded 'income':\", np.unique(y))  # Debug the output of the encoded income\n",
        "\n",
        "    return X, y, transformer\n",
        "\n",
        "\n",
        "# Function to train the Random Forest model with SMOTE\n",
        "def train_random_forest_with_smote(X, y):\n",
        "    # Apply SMOTE\n",
        "    smote = SMOTE(random_state=42)\n",
        "    X_smote, y_smote = smote.fit_resample(X, y)\n",
        "\n",
        "    # Train the Random Forest\n",
        "    model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "    model.fit(X_smote, y_smote)\n",
        "\n",
        "    return model\n",
        "\n",
        "# Evaluate the model\n",
        "def evaluate_model(model, X_test, y_test):\n",
        "    y_pred = model.predict(X_test)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    report = classification_report(y_test, y_pred)\n",
        "\n",
        "    return accuracy, report\n",
        "\n",
        "# Main execution function\n",
        "def main():\n",
        "    # Preprocess training data\n",
        "    X_train, y_train, transformer = preprocess_data(train_data, is_train=True)\n",
        "\n",
        "    # Train model with SMOTE\n",
        "    smote = SMOTE(random_state=42)\n",
        "    X_smote, y_smote = smote.fit_resample(X_train, y_train)\n",
        "    model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "    model.fit(X_smote, y_smote)\n",
        "\n",
        "    # Preprocess testing data using the same transformer\n",
        "    X_test, y_test, _ = preprocess_data(test_data, transformer, is_train=False)\n",
        "\n",
        "    # Evaluate the test model\n",
        "    accuracy, report = evaluate_model(model, X_test, y_test)\n",
        "    print(f'Accuracy test: {accuracy}')\n",
        "    print(f'Classification Report test:\\n{report}')\n",
        "\n",
        "    # Evaluate the test model\n",
        "    accuracy_train, report_train = evaluate_model(model, X_train, y_train)\n",
        "    print(f'Accuracy train: {accuracy_train}')\n",
        "    print(f'Classification Report train:\\n{report_train}')\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Initial columns: Index(['age', 'work-class', 'fnlwgt', 'education', 'education_num',\n",
        "       'marital-status', 'occupation', 'relationship', 'race', 'sex',\n",
        "       'capital-gain', 'capital-loss', 'hours-worked-per-week',\n",
        "       'native-country', 'income'],\n",
        "      dtype='object')\n",
        "Categorical features before encoding: []\n",
        "Encoded 'income': [0 1]\n",
        "Initial columns: Index(['age', 'work-class', 'fnlwgt', 'education', 'education_num',\n",
        "       'marital-status', 'occupation', 'relationship', 'race', 'sex',\n",
        "       'capital-gain', 'capital-loss', 'hours-worked-per-week',\n",
        "       'native-country', 'income'],\n",
        "      dtype='object')\n",
        "Adjusted 'income' for test data: ['<=50K' '>50K']\n",
        "Categorical features before encoding: []\n",
        "Encoded 'income': [0 1]\n",
        "Accuracy test: 0.8431914501566243\n",
        "Classification Report test:\n",
        "              precision    recall  f1-score   support\n",
        "\n",
        "           0       0.90      0.90      0.90     12435\n",
        "           1       0.67      0.67      0.67      3846\n",
        "\n",
        "    accuracy                           0.84     16281\n",
        "   macro avg       0.78      0.78      0.78     16281\n",
        "weighted avg       0.84      0.84      0.84     16281\n",
        "\n",
        "Accuracy train: 0.9999385768250361\n",
        "Classification Report train:\n",
        "              precision    recall  f1-score   support\n",
        "\n",
        "           0       1.00      1.00      1.00     24720\n",
        "           1       1.00      1.00      1.00      7841\n",
        "\n",
        "    accuracy                           1.00     32561\n",
        "   macro avg       1.00      1.00      1.00     32561\n",
        "weighted avg       1.00      1.00      1.00     32561"
      ],
      "metadata": {
        "id": "8DaHWsee-fLa"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yuDT5SIupHDp",
        "outputId": "e89f9d1f-be45-42c8-d3ea-e21d587b7263"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial columns: Index(['age', 'work-class', 'fnlwgt', 'education', 'education_num',\n",
            "       'marital-status', 'occupation', 'relationship', 'race', 'sex',\n",
            "       'capital-gain', 'capital-loss', 'hours-worked-per-week',\n",
            "       'native-country', 'income'],\n",
            "      dtype='object')\n",
            "'fnlwgt' column dropped.\n",
            "Categorical features before encoding: ['work-class', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'native-country']\n",
            "Encoded 'income': [0 1]\n",
            "Initial columns: Index(['age', 'work-class', 'fnlwgt', 'education', 'education_num',\n",
            "       'marital-status', 'occupation', 'relationship', 'race', 'sex',\n",
            "       'capital-gain', 'capital-loss', 'hours-worked-per-week',\n",
            "       'native-country', 'income'],\n",
            "      dtype='object')\n",
            "'fnlwgt' column dropped.\n",
            "Adjusted 'income' for test data: ['<=50K' '>50K']\n",
            "Categorical features before encoding: ['work-class', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'native-country']\n",
            "Encoded 'income': [0 1]\n",
            "Accuracy: 0.839690436705362\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      0.91      0.90     12435\n",
            "           1       0.68      0.62      0.65      3846\n",
            "\n",
            "    accuracy                           0.84     16281\n",
            "   macro avg       0.78      0.76      0.77     16281\n",
            "weighted avg       0.84      0.84      0.84     16281\n",
            "\n"
          ]
        }
      ],
      "source": [
        "'''\n",
        "One Hot Encoding Implementation # removing fnlweight column, version 2\n",
        "# Version 2\n",
        "\n",
        "Outcome: less precision\n",
        "'''\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "\n",
        "# Assuming train_data and test_data are already loaded as dataframes\n",
        "# train_data, test_data\n",
        "\n",
        "# Function to preprocess data\n",
        "\n",
        "def preprocess_data(data, transformer=None, is_train=True):\n",
        "    print(\"Initial columns:\", data.columns)  # Initial check of all columns in the dataset\n",
        "\n",
        "    income_column = 'income'\n",
        "    fnlwgt_column = 'fnlwgt'  # Define the column name to be dropped\n",
        "\n",
        "    if income_column not in data.columns:\n",
        "        raise ValueError(f\"The column '{income_column}' does not exist in the dataset.\")\n",
        "\n",
        "    # Drop the 'fnlwgt' column from the dataset\n",
        "    if fnlwgt_column in data.columns:\n",
        "        data = data.drop(columns=[fnlwgt_column])\n",
        "        print(f\"'{fnlwgt_column}' column dropped.\")\n",
        "    else:\n",
        "        print(f\"No '{fnlwgt_column}' column to drop.\")\n",
        "\n",
        "    # If it's test data, handle the period at the end\n",
        "    if not is_train:\n",
        "        data[income_column] = data[income_column].str.strip().str.replace('.', '')\n",
        "        print(\"Adjusted 'income' for test data:\", data[income_column].unique())  # Debug\n",
        "\n",
        "    # Identify and store categorical features excluding 'income'\n",
        "    categorical_features = data.select_dtypes(include=['object']).columns.tolist()\n",
        "    if income_column in categorical_features:\n",
        "        categorical_features.remove(income_column)\n",
        "    print(\"Categorical features before encoding:\", categorical_features)  # Debug statement\n",
        "\n",
        "    # Apply ColumnTransformer only to categorical features excluding 'income'\n",
        "    if transformer is None:\n",
        "        transformer = ColumnTransformer(\n",
        "            transformers=[('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)],\n",
        "            remainder='passthrough')\n",
        "        X = transformer.fit_transform(data.drop(columns=[income_column]))\n",
        "    else:\n",
        "        X = transformer.transform(data.drop(columns=[income_column]))\n",
        "\n",
        "    # Now encode the 'income' column after categorical handling\n",
        "    y = LabelEncoder().fit_transform(data[income_column])\n",
        "    print(\"Encoded 'income':\", np.unique(y))  # Debug the output of the encoded income\n",
        "\n",
        "    return X, y, transformer\n",
        "\n",
        "# Function to train the Random Forest model with SMOTE\n",
        "def train_random_forest_with_smote(X, y):\n",
        "    # Apply SMOTE\n",
        "    smote = SMOTE(random_state=42)\n",
        "    X_smote, y_smote = smote.fit_resample(X, y)\n",
        "\n",
        "    # Train the Random Forest\n",
        "    model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "    model.fit(X_smote, y_smote)\n",
        "\n",
        "    return model\n",
        "\n",
        "# Evaluate the model\n",
        "def evaluate_model(model, X_test, y_test):\n",
        "    y_pred = model.predict(X_test)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    report = classification_report(y_test, y_pred)\n",
        "\n",
        "    return accuracy, report\n",
        "\n",
        "# Main execution function\n",
        "def main():\n",
        "    # Preprocess training data\n",
        "    X_train, y_train, transformer = preprocess_data(train_data, is_train=True)\n",
        "\n",
        "    # Train model with SMOTE\n",
        "    smote = SMOTE(random_state=42)\n",
        "    X_smote, y_smote = smote.fit_resample(X_train, y_train)\n",
        "    model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "    model.fit(X_smote, y_smote)\n",
        "\n",
        "    # Preprocess testing data using the same transformer\n",
        "    X_test, y_test, _ = preprocess_data(test_data, transformer, is_train=False)\n",
        "\n",
        "    # Evaluate the model\n",
        "    accuracy, report = evaluate_model(model, X_test, y_test)\n",
        "    print(f'Accuracy: {accuracy}')\n",
        "    print(f'Classification Report:\\n{report}')\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Initial columns: Index(['age', 'work-class', 'fnlwgt', 'education', 'education_num',\n",
        "       'marital-status', 'occupation', 'relationship', 'race', 'sex',\n",
        "       'capital-gain', 'capital-loss', 'hours-worked-per-week',\n",
        "       'native-country', 'income'],\n",
        "      dtype='object')\n",
        "'fnlwgt' column dropped.\n",
        "Categorical features before encoding: ['work-class', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'native-country']\n",
        "Encoded 'income': [0 1]\n",
        "Initial columns: Index(['age', 'work-class', 'fnlwgt', 'education', 'education_num',\n",
        "       'marital-status', 'occupation', 'relationship', 'race', 'sex',\n",
        "       'capital-gain', 'capital-loss', 'hours-worked-per-week',\n",
        "       'native-country', 'income'],\n",
        "      dtype='object')\n",
        "'fnlwgt' column dropped.\n",
        "Adjusted 'income' for test data: ['<=50K' '>50K']\n",
        "Categorical features before encoding: ['work-class', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'native-country']\n",
        "Encoded 'income': [0 1]\n",
        "Accuracy: 0.839690436705362\n",
        "Classification Report:\n",
        "              precision    recall  f1-score   support\n",
        "\n",
        "           0       0.89      0.91      0.90     12435\n",
        "           1       0.68      0.62      0.65      3846\n",
        "\n",
        "    accuracy                           0.84     16281\n",
        "   macro avg       0.78      0.76      0.77     16281\n",
        "weighted avg       0.84      0.84      0.84     16281\n"
      ],
      "metadata": {
        "id": "8Fm_yNAz-xsm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WCVcvQIMpXfw",
        "outputId": "a0afb180-4109-457a-a422-6f2391a3b138"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Index(['age', 'work-class', 'fnlwgt', 'education', 'education_num',\n",
              "       'marital-status', 'occupation', 'relationship', 'race', 'sex',\n",
              "       'capital-gain', 'capital-loss', 'hours-worked-per-week',\n",
              "       'native-country', 'income'],\n",
              "      dtype='object')"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_data.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tMD5HMgW0FEO",
        "outputId": "c8c63318-45b9-4392-b96b-439d0da55a41"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial columns: Index(['age', 'work-class', 'fnlwgt', 'education', 'education_num',\n",
            "       'marital-status', 'occupation', 'relationship', 'race', 'sex',\n",
            "       'capital-gain', 'capital-loss', 'hours-worked-per-week',\n",
            "       'native-country', 'income'],\n",
            "      dtype='object')\n",
            "Encoded features: []\n",
            "Encoded 'income': [0 1]\n",
            "Initial columns: Index(['age', 'work-class', 'fnlwgt', 'education', 'education_num',\n",
            "       'marital-status', 'occupation', 'relationship', 'race', 'sex',\n",
            "       'capital-gain', 'capital-loss', 'hours-worked-per-week',\n",
            "       'native-country', 'income'],\n",
            "      dtype='object')\n",
            "Adjusted 'income' for test data: ['<=50K' '>50K']\n",
            "Encoded features: []\n",
            "Encoded 'income': [0 1]\n",
            "Accuracy: 0.8431914501566243\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      0.90      0.90     12435\n",
            "           1       0.67      0.67      0.67      3846\n",
            "\n",
            "    accuracy                           0.84     16281\n",
            "   macro avg       0.78      0.78      0.78     16281\n",
            "weighted avg       0.84      0.84      0.84     16281\n",
            "\n",
            "Accuracy: 0.9999385768250361\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00     24720\n",
            "           1       1.00      1.00      1.00      7841\n",
            "\n",
            "    accuracy                           1.00     32561\n",
            "   macro avg       1.00      1.00      1.00     32561\n",
            "weighted avg       1.00      1.00      1.00     32561\n",
            "\n"
          ]
        }
      ],
      "source": [
        "'''\n",
        "One Hot Encoding Implementation # default, version 3\n",
        "Using Label Encoding, Smote\n",
        "'''\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "# Function to preprocess data using label encoding\n",
        "def preprocess_data(data, encoders=None, is_train=True):\n",
        "    print(\"Initial columns:\", data.columns)  # Initial check of all columns in the dataset\n",
        "\n",
        "    income_column = 'income'\n",
        "    if income_column not in data.columns:\n",
        "        raise ValueError(f\"The column '{income_column}' does not exist in the dataset.\")\n",
        "\n",
        "    # If it's test data, handle the period at the end\n",
        "    if not is_train:\n",
        "        data[income_column] = data[income_column].str.strip().str.replace('.', '')\n",
        "        print(\"Adjusted 'income' for test data:\", data[income_column].unique())  # Debug\n",
        "\n",
        "    # Identify categorical features excluding 'income'\n",
        "    categorical_features = data.select_dtypes(include=['object']).columns.tolist()\n",
        "    if income_column in categorical_features:\n",
        "        categorical_features.remove(income_column)\n",
        "\n",
        "    # Initialize or apply existing label encoders\n",
        "    if encoders is None:\n",
        "        encoders = {}\n",
        "        for feature in categorical_features:\n",
        "            le = LabelEncoder()\n",
        "            data[feature] = le.fit_transform(data[feature])\n",
        "            encoders[feature] = le\n",
        "    else:\n",
        "        for feature, le in encoders.items():\n",
        "            data[feature] = le.transform(data[feature])\n",
        "\n",
        "    print(\"Encoded features:\", categorical_features)  # Debug statement\n",
        "\n",
        "    # Encode the target variable\n",
        "    y = LabelEncoder().fit_transform(data[income_column])\n",
        "    print(\"Encoded 'income':\", np.unique(y))  # Debug the output of the encoded income\n",
        "\n",
        "    # All features are now numeric, so return the numeric dataframe directly\n",
        "    X = data.drop(columns=[income_column]).values\n",
        "\n",
        "    return X, y, encoders\n",
        "\n",
        "# Function to train the Random Forest model with SMOTE\n",
        "def train_random_forest_with_smote(X, y):\n",
        "    # Apply SMOTE\n",
        "    smote = SMOTE(random_state=42)\n",
        "    X_smote, y_smote = smote.fit_resample(X, y)\n",
        "\n",
        "    # Train the Random Forest\n",
        "    model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "    model.fit(X_smote, y_smote)\n",
        "\n",
        "    return model\n",
        "\n",
        "# Evaluate the model\n",
        "def evaluate_model(model, X_test, y_test):\n",
        "    y_pred = model.predict(X_test)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    report = classification_report(y_test, y_pred)\n",
        "\n",
        "    return accuracy, report\n",
        "\n",
        "# Main execution function\n",
        "def main():\n",
        "    # Preprocess training data with Label Encoding\n",
        "    X_train, y_train, encoders = preprocess_data(train_data, is_train=True)\n",
        "\n",
        "    # Train model with SMOTE\n",
        "    smote = SMOTE(random_state=42)\n",
        "    X_smote, y_smote = smote.fit_resample(X_train, y_train)\n",
        "    model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "    model.fit(X_smote, y_smote)\n",
        "\n",
        "    # Preprocess testing data using the same encoders\n",
        "    X_test, y_test, _ = preprocess_data(test_data, encoders, is_train=False)\n",
        "\n",
        "    # Evaluate the model\n",
        "    accuracy, report = evaluate_model(model, X_test, y_test)\n",
        "    print(f'Accuracy: {accuracy}')\n",
        "    print(f'Classification Report:\\n{report}')\n",
        "\n",
        "    # Evaluate the model\n",
        "    accuracy1, report1 = evaluate_model(model, X_train, y_train)\n",
        "    print(f'Accuracy: {accuracy1}')\n",
        "    print(f'Classification Report:\\n{report1}')\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Initial columns: Index(['age', 'work-class', 'fnlwgt', 'education', 'education_num',\n",
        "       'marital-status', 'occupation', 'relationship', 'race', 'sex',\n",
        "       'capital-gain', 'capital-loss', 'hours-worked-per-week',\n",
        "       'native-country', 'income'],\n",
        "      dtype='object')\n",
        "Encoded features: []\n",
        "Encoded 'income': [0 1]\n",
        "Initial columns: Index(['age', 'work-class', 'fnlwgt', 'education', 'education_num',\n",
        "       'marital-status', 'occupation', 'relationship', 'race', 'sex',\n",
        "       'capital-gain', 'capital-loss', 'hours-worked-per-week',\n",
        "       'native-country', 'income'],\n",
        "      dtype='object')\n",
        "Adjusted 'income' for test data: ['<=50K' '>50K']\n",
        "Encoded features: []\n",
        "Encoded 'income': [0 1]\n",
        "Accuracy: 0.8431914501566243\n",
        "Classification Report:\n",
        "              precision    recall  f1-score   support\n",
        "\n",
        "           0       0.90      0.90      0.90     12435\n",
        "           1       0.67      0.67      0.67      3846\n",
        "\n",
        "    accuracy                           0.84     16281\n",
        "   macro avg       0.78      0.78      0.78     16281\n",
        "weighted avg       0.84      0.84      0.84     16281\n",
        "\n",
        "Accuracy: 0.9999385768250361\n",
        "Classification Report:\n",
        "              precision    recall  f1-score   support\n",
        "\n",
        "           0       1.00      1.00      1.00     24720\n",
        "           1       1.00      1.00      1.00      7841\n",
        "\n",
        "    accuracy                           1.00     32561\n",
        "   macro avg       1.00      1.00      1.00     32561\n",
        "weighted avg       1.00      1.00      1.00     32561"
      ],
      "metadata": {
        "id": "0bc0Y3fM-5D2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6JR62yza52JX",
        "outputId": "8b60751f-566c-4e5a-b4e9-7b45fef09015"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial columns: Index(['age', 'work-class', 'fnlwgt', 'education', 'education_num',\n",
            "       'marital-status', 'occupation', 'relationship', 'race', 'sex',\n",
            "       'capital-gain', 'capital-loss', 'hours-worked-per-week',\n",
            "       'native-country', 'income'],\n",
            "      dtype='object')\n",
            "Encoded features: []\n",
            "Encoded 'income': [0 1]\n",
            "Initial columns: Index(['age', 'work-class', 'fnlwgt', 'education', 'education_num',\n",
            "       'marital-status', 'occupation', 'relationship', 'race', 'sex',\n",
            "       'capital-gain', 'capital-loss', 'hours-worked-per-week',\n",
            "       'native-country', 'income'],\n",
            "      dtype='object')\n",
            "Adjusted 'income' for test data: ['<=50K' '>50K']\n",
            "Encoded features: []\n",
            "Encoded 'income': [0 1]\n",
            "Accuracy: 0.8534488053559364\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.93      0.91     12435\n",
            "           1       0.73      0.61      0.66      3846\n",
            "\n",
            "    accuracy                           0.85     16281\n",
            "   macro avg       0.81      0.77      0.78     16281\n",
            "weighted avg       0.85      0.85      0.85     16281\n",
            "\n"
          ]
        }
      ],
      "source": [
        "'''\n",
        "# version 4\n",
        "Using Label Encoding, Without Smote\n",
        "'''\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# Function to preprocess data using label encoding\n",
        "def preprocess_data(data, encoders=None, is_train=True):\n",
        "    print(\"Initial columns:\", data.columns)  # Initial check of all columns in the dataset\n",
        "\n",
        "    income_column = 'income'\n",
        "    if income_column not in data.columns:\n",
        "        raise ValueError(f\"The column '{income_column}' does not exist in the dataset.\")\n",
        "\n",
        "    # If it's test data, handle the period at the end\n",
        "    if not is_train:\n",
        "        data[income_column] = data[income_column].str.strip().str.replace('.', '')\n",
        "        print(\"Adjusted 'income' for test data:\", data[income_column].unique())  # Debug\n",
        "\n",
        "    # Identify categorical features excluding 'income'\n",
        "    categorical_features = data.select_dtypes(include=['object']).columns.tolist()\n",
        "    if income_column in categorical_features:\n",
        "        categorical_features.remove(income_column)\n",
        "\n",
        "    # Initialize or apply existing label encoders\n",
        "    if encoders is None:\n",
        "        encoders = {}\n",
        "        for feature in categorical_features:\n",
        "            le = LabelEncoder()\n",
        "            data[feature] = le.fit_transform(data[feature])\n",
        "            encoders[feature] = le\n",
        "    else:\n",
        "        for feature, le in encoders.items():\n",
        "            data[feature] = le.transform(data[feature])\n",
        "\n",
        "    print(\"Encoded features:\", categorical_features)  # Debug statement\n",
        "\n",
        "    # Encode the target variable\n",
        "    y = LabelEncoder().fit_transform(data[income_column])\n",
        "    print(\"Encoded 'income':\", np.unique(y))  # Debug the output of the encoded income\n",
        "\n",
        "    # All features are now numeric, so return the numeric dataframe directly\n",
        "    X = data.drop(columns=[income_column]).values\n",
        "\n",
        "    return X, y, encoders\n",
        "\n",
        "# Function to train the Random Forest model without SMOTE\n",
        "def train_random_forest(X, y):\n",
        "    # Train the Random Forest without SMOTE\n",
        "    model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "    model.fit(X, y)\n",
        "\n",
        "    return model\n",
        "\n",
        "# Evaluate the model\n",
        "def evaluate_model(model, X_test, y_test):\n",
        "    y_pred = model.predict(X_test)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    report = classification_report(y_test, y_pred)\n",
        "\n",
        "    return accuracy, report\n",
        "\n",
        "# Main execution function\n",
        "def main():\n",
        "    # Preprocess training data with Label Encoding\n",
        "    X_train, y_train, encoders = preprocess_data(train_data, is_train=True)\n",
        "\n",
        "    # Train the Random Forest without SMOTE\n",
        "    model = train_random_forest(X_train, y_train)\n",
        "\n",
        "    # Preprocess testing data using the same encoders\n",
        "    X_test, y_test, _ = preprocess_data(test_data, encoders, is_train=False)\n",
        "\n",
        "    # Evaluate the model\n",
        "    accuracy, report = evaluate_model(model, X_test, y_test)\n",
        "    print(f'Accuracy: {accuracy}')\n",
        "    print(f'Classification Report:\\n{report}')\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Initial columns: Index(['age', 'work-class', 'fnlwgt', 'education', 'education_num',\n",
        "       'marital-status', 'occupation', 'relationship', 'race', 'sex',\n",
        "       'capital-gain', 'capital-loss', 'hours-worked-per-week',\n",
        "       'native-country', 'income'],\n",
        "      dtype='object')\n",
        "Encoded features: []\n",
        "Encoded 'income': [0 1]\n",
        "Initial columns: Index(['age', 'work-class', 'fnlwgt', 'education', 'education_num',\n",
        "       'marital-status', 'occupation', 'relationship', 'race', 'sex',\n",
        "       'capital-gain', 'capital-loss', 'hours-worked-per-week',\n",
        "       'native-country', 'income'],\n",
        "      dtype='object')\n",
        "Adjusted 'income' for test data: ['<=50K' '>50K']\n",
        "Encoded features: []\n",
        "Encoded 'income': [0 1]\n",
        "Accuracy: 0.8534488053559364\n",
        "Classification Report:\n",
        "              precision    recall  f1-score   support\n",
        "\n",
        "           0       0.88      0.93      0.91     12435\n",
        "           1       0.73      0.61      0.66      3846\n",
        "\n",
        "    accuracy                           0.85     16281\n",
        "   macro avg       0.81      0.77      0.78     16281\n",
        "weighted avg       0.85      0.85      0.85     16281\n"
      ],
      "metadata": {
        "id": "ljvmrP0J-9C-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iIqk2ZfsAM2j",
        "outputId": "905189fc-e22e-49b8-9fe6-dcdba753c761"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial columns: Index(['age', 'work-class', 'fnlwgt', 'education', 'education_num',\n",
            "       'marital-status', 'occupation', 'relationship', 'race', 'sex',\n",
            "       'capital-gain', 'capital-loss', 'hours-worked-per-week',\n",
            "       'native-country', 'income'],\n",
            "      dtype='object')\n",
            "Encoded features: ['work-class', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'native-country']\n",
            "Encoded 'income': [0 1]\n",
            "Best Parameters: {'max_depth': 20, 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 100}\n",
            "Initial columns: Index(['age', 'work-class', 'fnlwgt', 'education', 'education_num',\n",
            "       'marital-status', 'occupation', 'relationship', 'race', 'sex',\n",
            "       'capital-gain', 'capital-loss', 'hours-worked-per-week',\n",
            "       'native-country', 'income'],\n",
            "      dtype='object')\n",
            "Adjusted 'income' for test data: ['<=50K' '>50K']\n",
            "Encoded features: ['work-class', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'native-country']\n",
            "Encoded 'income': [0 1]\n",
            "Accuracy: 0.864443216018672\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      0.94      0.91     12435\n",
            "           1       0.77      0.61      0.68      3846\n",
            "\n",
            "    accuracy                           0.86     16281\n",
            "   macro avg       0.83      0.78      0.80     16281\n",
            "weighted avg       0.86      0.86      0.86     16281\n",
            "\n"
          ]
        }
      ],
      "source": [
        "'''\n",
        " # version 5\n",
        "Using Label Encoding, Without Smote\n",
        "Using hyperparameter tuning (gridsearchcv)\n",
        "'''\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Function to preprocess data using label encoding\n",
        "def preprocess_data(data, encoders=None, is_train=True):\n",
        "    print(\"Initial columns:\", data.columns)  # Initial check of all columns in the dataset\n",
        "\n",
        "    income_column = 'income'\n",
        "    if income_column not in data.columns:\n",
        "        raise ValueError(f\"The column '{income_column}' does not exist in the dataset.\")\n",
        "\n",
        "    # If it's test data, handle the period at the end\n",
        "    if not is_train:\n",
        "        data[income_column] = data[income_column].str.strip().str.replace('.', '')\n",
        "        print(\"Adjusted 'income' for test data:\", data[income_column].unique())  # Debug\n",
        "\n",
        "    # Identify categorical features excluding 'income'\n",
        "    categorical_features = data.select_dtypes(include=['object']).columns.tolist()\n",
        "    if income_column in categorical_features:\n",
        "        categorical_features.remove(income_column)\n",
        "\n",
        "    # Initialize or apply existing label encoders\n",
        "    if encoders is None:\n",
        "        encoders = {}\n",
        "        for feature in categorical_features:\n",
        "            le = LabelEncoder()\n",
        "            data[feature] = le.fit_transform(data[feature])\n",
        "            encoders[feature] = le\n",
        "    else:\n",
        "        for feature, le in encoders.items():\n",
        "            data[feature] = le.transform(data[feature])\n",
        "\n",
        "    print(\"Encoded features:\", categorical_features)  # Debug statement\n",
        "\n",
        "    # Encode the target variable\n",
        "    y = LabelEncoder().fit_transform(data[income_column])\n",
        "    print(\"Encoded 'income':\", np.unique(y))  # Debug the output of the encoded income\n",
        "\n",
        "    # All features are now numeric, so return the numeric dataframe directly\n",
        "    X = data.drop(columns=[income_column]).values\n",
        "\n",
        "    return X, y, encoders\n",
        "\n",
        "# Function to perform hyperparameter tuning with RandomForestClassifier\n",
        "def train_random_forest_with_tuning(X, y):\n",
        "    # Define parameter grid for hyperparameter tuning\n",
        "    param_grid = {\n",
        "        'n_estimators': [50, 100, 200],\n",
        "        'max_depth': [5, 10, 20, None],\n",
        "        'min_samples_split': [2, 5, 10],\n",
        "        'min_samples_leaf': [1, 2, 4]\n",
        "    }\n",
        "\n",
        "    # Initialize RandomForestClassifier\n",
        "    rf = RandomForestClassifier(random_state=42)\n",
        "\n",
        "    # Use GridSearchCV for hyperparameter tuning\n",
        "    grid_search = GridSearchCV(estimator=rf, param_grid=param_grid, cv=5, n_jobs=-1, scoring='accuracy')\n",
        "    grid_search.fit(X, y)\n",
        "\n",
        "    # Return the best model\n",
        "    print(f\"Best Parameters: {grid_search.best_params_}\")\n",
        "    return grid_search.best_estimator_\n",
        "\n",
        "# Evaluate the model\n",
        "def evaluate_model(model, X_test, y_test):\n",
        "    y_pred = model.predict(X_test)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    report = classification_report(y_test, y_pred)\n",
        "\n",
        "    return accuracy, report\n",
        "\n",
        "# Main execution function\n",
        "def main():\n",
        "    # Preprocess training data with Label Encoding\n",
        "    X_train, y_train, encoders = preprocess_data(train_data, is_train=True)\n",
        "\n",
        "    # Train the Random Forest with hyperparameter tuning\n",
        "    model = train_random_forest_with_tuning(X_train, y_train)\n",
        "\n",
        "    # Preprocess testing data using the same encoders\n",
        "    X_test, y_test, _ = preprocess_data(test_data, encoders, is_train=False)\n",
        "\n",
        "    # Evaluate the model\n",
        "    accuracy, report = evaluate_model(model, X_test, y_test)\n",
        "    print(f'Accuracy: {accuracy}')\n",
        "    print(f'Classification Report:\\n{report}')\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Version 7: no smote, OHE, using parameters\n",
        "'''\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "\n",
        "# Assuming train_data and test_data are already loaded as dataframes\n",
        "# train_data, test_data\n",
        "\n",
        "# Function to preprocess data\n",
        "def preprocess_data(data, transformer=None, is_train=True):\n",
        "    print(\"Initial columns:\", data.columns)  # Initial check of all columns in the dataset\n",
        "\n",
        "    income_column = 'income'\n",
        "    if income_column not in data.columns:\n",
        "        raise ValueError(f\"The column '{income_column}' does not exist in the dataset.\")\n",
        "\n",
        "    # If it's test data, handle the period at the end\n",
        "    if not is_train:\n",
        "        data[income_column] = data[income_column].str.strip().str.replace('.', '')\n",
        "        print(\"Adjusted 'income' for test data:\", data[income_column].unique())  # Debug\n",
        "\n",
        "    # Identify and store categorical features excluding 'income'\n",
        "    categorical_features = data.select_dtypes(include=['object']).columns.tolist()\n",
        "    if income_column in categorical_features:\n",
        "        categorical_features.remove(income_column)\n",
        "    print(\"Categorical features before encoding:\", categorical_features)  # Debug statement\n",
        "\n",
        "    # Apply ColumnTransformer only to categorical features excluding 'income'\n",
        "    if transformer is None:\n",
        "        transformer = ColumnTransformer(\n",
        "            transformers=[('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)],\n",
        "            remainder='passthrough')\n",
        "        X = transformer.fit_transform(data.drop(columns=[income_column]))\n",
        "    else:\n",
        "        X = transformer.transform(data.drop(columns=[income_column]))\n",
        "\n",
        "    # Now encode the 'income' column after categorical handling\n",
        "    y = LabelEncoder().fit_transform(data[income_column])\n",
        "    print(\"Encoded 'income':\", np.unique(y))  # Debug the output of the encoded income\n",
        "\n",
        "    return X, y, transformer\n",
        "\n",
        "# Function to train the Random Forest model with specified hyperparameters\n",
        "def train_random_forest(X, y):\n",
        "    # Initialize the RandomForestClassifier with the desired hyperparameters\n",
        "    model = RandomForestClassifier(\n",
        "        n_estimators=100,\n",
        "        max_depth=10,\n",
        "        min_samples_leaf=1,\n",
        "        min_samples_split=2,\n",
        "        bootstrap=True,\n",
        "        random_state=42\n",
        "    )\n",
        "    model.fit(X, y)\n",
        "\n",
        "    return model\n",
        "\n",
        "# Evaluate the model\n",
        "def evaluate_model(model, X_test, y_test):\n",
        "    y_pred = model.predict(X_test)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    report = classification_report(y_test, y_pred)\n",
        "\n",
        "    return accuracy, report\n",
        "\n",
        "# Main execution function\n",
        "def main():\n",
        "    # Preprocess training data\n",
        "    X_train, y_train, transformer = preprocess_data(train_data, is_train=True)\n",
        "\n",
        "    # Train model using specified hyperparameters\n",
        "    model = train_random_forest(X_train, y_train)\n",
        "\n",
        "    # Preprocess testing data using the same transformer\n",
        "    X_test, y_test, _ = preprocess_data(test_data, transformer, is_train=False)\n",
        "\n",
        "    # Evaluate the model on the test data\n",
        "    accuracy, report = evaluate_model(model, X_test, y_test)\n",
        "    print(f'Accuracy (Test Data): {accuracy}')\n",
        "    print(f'Classification Report (Test Data):\\n{report}')\n",
        "\n",
        "    # Evaluate the model on the training data\n",
        "    accuracy_train, report_train = evaluate_model(model, X_train, y_train)\n",
        "    print(f'Accuracy (Training Data): {accuracy_train}')\n",
        "    print(f'Classification Report (Training Data):\\n{report_train}')\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    # Load your datasets (replace with actual file paths)\n",
        "    # train_data = pd.read_csv('./census-income.data (3).csv')\n",
        "    # test_data = pd.read_csv('./census-income.test (2).csv')\n",
        "\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z9rRIQM5oOMF",
        "outputId": "6c16385d-f73a-4682-9d4e-f1a918f8a235"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial columns: Index(['age', 'work-class', 'fnlwgt', 'education', 'education_num',\n",
            "       'marital-status', 'occupation', 'relationship', 'race', 'sex',\n",
            "       'capital-gain', 'capital-loss', 'hours-worked-per-week',\n",
            "       'native-country', 'income'],\n",
            "      dtype='object')\n",
            "Categorical features before encoding: ['work-class', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'native-country']\n",
            "Encoded 'income': [0 1]\n",
            "Initial columns: Index(['age', 'work-class', 'fnlwgt', 'education', 'education_num',\n",
            "       'marital-status', 'occupation', 'relationship', 'race', 'sex',\n",
            "       'capital-gain', 'capital-loss', 'hours-worked-per-week',\n",
            "       'native-country', 'income'],\n",
            "      dtype='object')\n",
            "Adjusted 'income' for test data: ['<=50K' '>50K']\n",
            "Categorical features before encoding: ['work-class', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'native-country']\n",
            "Encoded 'income': [0 1]\n",
            "Accuracy (Test Data): 0.8579325594250967\n",
            "Classification Report (Test Data):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.96      0.91     12435\n",
            "           1       0.79      0.54      0.64      3846\n",
            "\n",
            "    accuracy                           0.86     16281\n",
            "   macro avg       0.83      0.75      0.78     16281\n",
            "weighted avg       0.85      0.86      0.85     16281\n",
            "\n",
            "Accuracy (Training Data): 0.8641012253923406\n",
            "Classification Report (Training Data):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.96      0.91     24720\n",
            "           1       0.82      0.56      0.66      7841\n",
            "\n",
            "    accuracy                           0.86     32561\n",
            "   macro avg       0.85      0.76      0.79     32561\n",
            "weighted avg       0.86      0.86      0.85     32561\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "V8: smote, OHE, hyperparameters applied\n",
        "Best hyperparameters as determined in the Hyperparameter Tuning option\n",
        "Using: ACCURACY focused prediction\n",
        "'''\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "# Assuming train_data and test_data are already loaded as dataframes\n",
        "# train_data, test_data\n",
        "\n",
        "# Function to preprocess data\n",
        "# Function to preprocess data\n",
        "def preprocess_data(data, transformer=None, is_train=True):\n",
        "    print(\"Initial columns:\", data.columns)  # Initial check of all columns in the dataset\n",
        "\n",
        "    income_column = 'income'\n",
        "    if income_column not in data.columns:\n",
        "        raise ValueError(f\"The column '{income_column}' does not exist in the dataset.\")\n",
        "\n",
        "    # Convert 'income' to string explicitly to avoid AttributeError\n",
        "    data[income_column] = data[income_column].astype(str)\n",
        "\n",
        "    # If it's test data, handle the period at the end\n",
        "    if not is_train:\n",
        "        data[income_column] = data[income_column].str.strip().str.replace('.', '', regex=False)\n",
        "        print(\"Adjusted 'income' for test data:\", data[income_column].unique())  # Debug\n",
        "\n",
        "    # Identify and store categorical features excluding 'income'\n",
        "    categorical_features = data.select_dtypes(include=['object']).columns.tolist()\n",
        "    if income_column in categorical_features:\n",
        "        categorical_features.remove(income_column)\n",
        "    print(\"Categorical features before encoding:\", categorical_features)  # Debug statement\n",
        "\n",
        "    # Apply ColumnTransformer only to categorical features excluding 'income'\n",
        "    if transformer is None:\n",
        "        transformer = ColumnTransformer(\n",
        "            transformers=[('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)],\n",
        "            remainder='passthrough')\n",
        "        X = transformer.fit_transform(data.drop(columns=[income_column]))\n",
        "    else:\n",
        "        X = transformer.transform(data.drop(columns=[income_column]))\n",
        "\n",
        "    # Now encode the 'income' column after categorical handling\n",
        "    y = LabelEncoder().fit_transform(data[income_column])\n",
        "    print(\"Encoded 'income':\", np.unique(y))  # Debug the output of the encoded income\n",
        "\n",
        "    return X, y, transformer\n",
        "\n",
        "\n",
        "# Function to train the Random Forest model with SMOTE\n",
        "def train_random_forest_with_smote(X, y):\n",
        "    # Apply SMOTE\n",
        "    smote = SMOTE(random_state=42)\n",
        "    X_smote, y_smote = smote.fit_resample(X, y)\n",
        "\n",
        "    # Define the Random Forest model with specified hyperparameters\n",
        "    model = RandomForestClassifier(\n",
        "        n_estimators=100,\n",
        "        max_depth=20,\n",
        "        min_samples_leaf=1,\n",
        "        min_samples_split=10,\n",
        "        bootstrap=False,\n",
        "        random_state=42\n",
        "    )\n",
        "\n",
        "    # Train (fit) the model using the resampled data\n",
        "    model.fit(X_smote, y_smote)\n",
        "\n",
        "    return model\n",
        "\n",
        "# Function to evaluate the model\n",
        "def evaluate_model(model, X_test, y_test):\n",
        "    y_pred = model.predict(X_test)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    report = classification_report(y_test, y_pred)\n",
        "\n",
        "    return accuracy, report\n",
        "\n",
        "# Main execution function\n",
        "def main():\n",
        "    # Preprocess training data\n",
        "    X_train, y_train, transformer = preprocess_data(train_data, is_train=True)\n",
        "\n",
        "    # Train model with SMOTE and specified hyperparameters\n",
        "    model = train_random_forest_with_smote(X_train, y_train)\n",
        "\n",
        "    # Preprocess testing data using the same transformer\n",
        "    X_test, y_test, _ = preprocess_data(test_data, transformer, is_train=False)\n",
        "\n",
        "    # Evaluate the test model\n",
        "    accuracy, report = evaluate_model(model, X_test, y_test)\n",
        "    print(f'Accuracy test: {accuracy}')\n",
        "    print(f'Classification Report test:\\n{report}')\n",
        "\n",
        "    # Evaluate the training model\n",
        "    accuracy_train, report_train = evaluate_model(model, X_train, y_train)\n",
        "    print(f'Accuracy train: {accuracy_train}')\n",
        "    print(f'Classification Report train:\\n{report_train}')\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Trar2XqZihM-",
        "outputId": "4cba2375-3b64-4134-94fc-48e1f86bce15"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial columns: Index(['Unnamed: 0', 'age', 'work-class', 'fnlwgt', 'education_num',\n",
            "       'marital-status', 'relationship', 'race', 'sex', 'capital-gain',\n",
            "       'capital-loss', 'hours-worked-per-week', 'native-country', 'occupation',\n",
            "       'income'],\n",
            "      dtype='object')\n",
            "Categorical features before encoding: []\n",
            "Encoded 'income': [0 1]\n",
            "Initial columns: Index(['Unnamed: 0', 'age', 'work-class', 'fnlwgt', 'education_num',\n",
            "       'marital-status', 'relationship', 'race', 'sex', 'capital-gain',\n",
            "       'capital-loss', 'hours-worked-per-week', 'native-country', 'occupation',\n",
            "       'income'],\n",
            "      dtype='object')\n",
            "Adjusted 'income' for test data: ['0' '1']\n",
            "Categorical features before encoding: []\n",
            "Encoded 'income': [0 1]\n",
            "Accuracy test: 0.8544315459738345\n",
            "Classification Report test:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      0.91      0.91     12435\n",
            "           1       0.70      0.67      0.69      3846\n",
            "\n",
            "    accuracy                           0.85     16281\n",
            "   macro avg       0.80      0.79      0.80     16281\n",
            "weighted avg       0.85      0.85      0.85     16281\n",
            "\n",
            "Accuracy train: 0.9324345075396947\n",
            "Classification Report train:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.96      0.96     24720\n",
            "           1       0.87      0.85      0.86      7841\n",
            "\n",
            "    accuracy                           0.93     32561\n",
            "   macro avg       0.91      0.91      0.91     32561\n",
            "weighted avg       0.93      0.93      0.93     32561\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "V9: smote, OHE, hyperparameters applied\n",
        "Best hyperparameters as determined in the Hyperparameter Tuning option\n",
        "Using: BALANCED focused prediction\n",
        "'''\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "# Assuming train_data and test_data are already loaded as dataframes\n",
        "# train_data, test_data\n",
        "\n",
        "# Function to preprocess data\n",
        "# Function to preprocess data\n",
        "def preprocess_data(data, transformer=None, is_train=True):\n",
        "    print(\"Initial columns:\", data.columns)  # Initial check of all columns in the dataset\n",
        "\n",
        "    income_column = 'income'\n",
        "    if income_column not in data.columns:\n",
        "        raise ValueError(f\"The column '{income_column}' does not exist in the dataset.\")\n",
        "\n",
        "    # Convert 'income' to string explicitly to avoid AttributeError\n",
        "    data[income_column] = data[income_column].astype(str)\n",
        "\n",
        "    # If it's test data, handle the period at the end\n",
        "    if not is_train:\n",
        "        data[income_column] = data[income_column].str.strip().str.replace('.', '', regex=False)\n",
        "        print(\"Adjusted 'income' for test data:\", data[income_column].unique())  # Debug\n",
        "\n",
        "    # Identify and store categorical features excluding 'income'\n",
        "    categorical_features = data.select_dtypes(include=['object']).columns.tolist()\n",
        "    if income_column in categorical_features:\n",
        "        categorical_features.remove(income_column)\n",
        "    print(\"Categorical features before encoding:\", categorical_features)  # Debug statement\n",
        "\n",
        "    # Apply ColumnTransformer only to categorical features excluding 'income'\n",
        "    if transformer is None:\n",
        "        transformer = ColumnTransformer(\n",
        "            transformers=[('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)],\n",
        "            remainder='passthrough')\n",
        "        X = transformer.fit_transform(data.drop(columns=[income_column]))\n",
        "    else:\n",
        "        X = transformer.transform(data.drop(columns=[income_column]))\n",
        "\n",
        "    # Now encode the 'income' column after categorical handling\n",
        "    y = LabelEncoder().fit_transform(data[income_column])\n",
        "    print(\"Encoded 'income':\", np.unique(y))  # Debug the output of the encoded income\n",
        "\n",
        "    return X, y, transformer\n",
        "\n",
        "\n",
        "# Function to train the Random Forest model with SMOTE\n",
        "def train_random_forest_with_smote(X, y):\n",
        "    # Apply SMOTE\n",
        "    smote = SMOTE(random_state=42)\n",
        "    X_smote, y_smote = smote.fit_resample(X, y)\n",
        "\n",
        "    # Define the Random Forest model with specified hyperparameters\n",
        "    model = RandomForestClassifier(\n",
        "        n_estimators=100,\n",
        "        max_depth=10,\n",
        "        min_samples_leaf=1,\n",
        "        min_samples_split=2,\n",
        "        bootstrap=False,\n",
        "        random_state=42\n",
        "    )\n",
        "\n",
        "    # Train (fit) the model using the resampled data\n",
        "    model.fit(X_smote, y_smote)\n",
        "\n",
        "    return model\n",
        "\n",
        "# Function to evaluate the model\n",
        "def evaluate_model(model, X_test, y_test):\n",
        "    y_pred = model.predict(X_test)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    report = classification_report(y_test, y_pred)\n",
        "\n",
        "    return accuracy, report\n",
        "\n",
        "# Main execution function\n",
        "def main():\n",
        "    # Preprocess training data\n",
        "    X_train, y_train, transformer = preprocess_data(train_data, is_train=True)\n",
        "\n",
        "    # Train model with SMOTE and specified hyperparameters\n",
        "    model = train_random_forest_with_smote(X_train, y_train)\n",
        "\n",
        "    # Preprocess testing data using the same transformer\n",
        "    X_test, y_test, _ = preprocess_data(test_data, transformer, is_train=False)\n",
        "\n",
        "    # Evaluate the test model\n",
        "    accuracy, report = evaluate_model(model, X_test, y_test)\n",
        "    print(f'Accuracy test: {accuracy}')\n",
        "    print(f'Classification Report test:\\n{report}')\n",
        "\n",
        "    # Evaluate the training model\n",
        "    accuracy_train, report_train = evaluate_model(model, X_train, y_train)\n",
        "    print(f'Accuracy train: {accuracy_train}')\n",
        "    print(f'Classification Report train:\\n{report_train}')\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GqhnA20jlQpD",
        "outputId": "41000351-ad10-41e1-827e-4c8e77e82735"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial columns: Index(['Unnamed: 0', 'age', 'work-class', 'fnlwgt', 'education_num',\n",
            "       'marital-status', 'relationship', 'race', 'sex', 'capital-gain',\n",
            "       'capital-loss', 'hours-worked-per-week', 'native-country', 'occupation',\n",
            "       'income'],\n",
            "      dtype='object')\n",
            "Categorical features before encoding: []\n",
            "Encoded 'income': [0 1]\n",
            "Initial columns: Index(['Unnamed: 0', 'age', 'work-class', 'fnlwgt', 'education_num',\n",
            "       'marital-status', 'relationship', 'race', 'sex', 'capital-gain',\n",
            "       'capital-loss', 'hours-worked-per-week', 'native-country', 'occupation',\n",
            "       'income'],\n",
            "      dtype='object')\n",
            "Adjusted 'income' for test data: ['0' '1']\n",
            "Categorical features before encoding: []\n",
            "Encoded 'income': [0 1]\n",
            "Accuracy test: 0.8414102327866838\n",
            "Classification Report test:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.91      0.88      0.89     12435\n",
            "           1       0.65      0.72      0.68      3846\n",
            "\n",
            "    accuracy                           0.84     16281\n",
            "   macro avg       0.78      0.80      0.79     16281\n",
            "weighted avg       0.85      0.84      0.84     16281\n",
            "\n",
            "Accuracy train: 0.8510488007125089\n",
            "Classification Report train:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.88      0.90     24720\n",
            "           1       0.67      0.75      0.71      7841\n",
            "\n",
            "    accuracy                           0.85     32561\n",
            "   macro avg       0.79      0.82      0.80     32561\n",
            "weighted avg       0.86      0.85      0.85     32561\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Initial columns: Index(['age', 'work-class', 'fnlwgt', 'education', 'education_num',\n",
        "       'marital-status', 'occupation', 'relationship', 'race', 'sex',\n",
        "       'capital-gain', 'capital-loss', 'hours-worked-per-week',\n",
        "       'native-country', 'income'],\n",
        "      dtype='object')\n",
        "Encoded features: ['work-class', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'native-country']\n",
        "Encoded 'income': [0 1]\n",
        "Best Parameters: {'max_depth': 20, 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 100}\n",
        "Initial columns: Index(['age', 'work-class', 'fnlwgt', 'education', 'education_num',\n",
        "       'marital-status', 'occupation', 'relationship', 'race', 'sex',\n",
        "       'capital-gain', 'capital-loss', 'hours-worked-per-week',\n",
        "       'native-country', 'income'],\n",
        "      dtype='object')\n",
        "Adjusted 'income' for test data: ['<=50K' '>50K']\n",
        "Encoded features: ['work-class', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'native-country']\n",
        "Encoded 'income': [0 1]\n",
        "Accuracy: 0.864443216018672\n",
        "Classification Report:\n",
        "              precision    recall  f1-score   support\n",
        "\n",
        "           0       0.89      0.94      0.91     12435\n",
        "           1       0.77      0.61      0.68      3846\n",
        "\n",
        "    accuracy                           0.86     16281\n",
        "   macro avg       0.83      0.78      0.80     16281\n",
        "weighted avg       0.86      0.86      0.86     16281\n",
        "\n"
      ],
      "metadata": {
        "id": "wjrqe2lN_BEG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "V10: smote, OHE, hyperparameters applied\n",
        "Best hyperparameters as determined in the Hyperparameter Tuning option\n",
        "Using: BALANCED focused prediction\n",
        "Plotting results\n",
        "'''\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from imblearn.over_sampling import SMOTE\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Assuming train_data and test_data are already loaded as dataframes\n",
        "# train_data, test_data\n",
        "\n",
        "# Function to preprocess data\n",
        "# Function to preprocess data\n",
        "def preprocess_data(data, transformer=None, is_train=True):\n",
        "    print(\"Initial columns:\", data.columns)  # Initial check of all columns in the dataset\n",
        "\n",
        "    income_column = 'income'\n",
        "    if income_column not in data.columns:\n",
        "        raise ValueError(f\"The column '{income_column}' does not exist in the dataset.\")\n",
        "\n",
        "    # Convert 'income' to string explicitly to avoid AttributeError\n",
        "    data[income_column] = data[income_column].astype(str)\n",
        "\n",
        "    # If it's test data, handle the period at the end\n",
        "    if not is_train:\n",
        "        data[income_column] = data[income_column].str.strip().str.replace('.', '', regex=False)\n",
        "        print(\"Adjusted 'income' for test data:\", data[income_column].unique())  # Debug\n",
        "\n",
        "    # Identify and store categorical features excluding 'income'\n",
        "    categorical_features = data.select_dtypes(include=['object']).columns.tolist()\n",
        "    if income_column in categorical_features:\n",
        "        categorical_features.remove(income_column)\n",
        "    print(\"Categorical features before encoding:\", categorical_features)  # Debug statement\n",
        "\n",
        "    # Apply ColumnTransformer only to categorical features excluding 'income'\n",
        "    if transformer is None:\n",
        "        transformer = ColumnTransformer(\n",
        "            transformers=[('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)],\n",
        "            remainder='passthrough')\n",
        "        X = transformer.fit_transform(data.drop(columns=[income_column]))\n",
        "    else:\n",
        "        X = transformer.transform(data.drop(columns=[income_column]))\n",
        "\n",
        "    # Now encode the 'income' column after categorical handling\n",
        "    y = LabelEncoder().fit_transform(data[income_column])\n",
        "    print(\"Encoded 'income':\", np.unique(y))  # Debug the output of the encoded income\n",
        "\n",
        "    return X, y, transformer\n",
        "\n",
        "\n",
        "# Function to train the Random Forest model with SMOTE\n",
        "def train_random_forest_with_smote(X, y):\n",
        "    # Apply SMOTE\n",
        "    smote = SMOTE(random_state=42)\n",
        "    X_smote, y_smote = smote.fit_resample(X, y)\n",
        "\n",
        "    # Define the Random Forest model with specified hyperparameters\n",
        "    model = RandomForestClassifier(\n",
        "        n_estimators=100,\n",
        "        max_depth=10,\n",
        "        min_samples_leaf=1,\n",
        "        min_samples_split=2,\n",
        "        bootstrap=False,\n",
        "        random_state=42\n",
        "    )\n",
        "\n",
        "    # Train (fit) the model using the resampled data\n",
        "    model.fit(X_smote, y_smote)\n",
        "\n",
        "    return model\n",
        "\n",
        "# Function to evaluate the model\n",
        "def evaluate_model(model, X_test, y_test):\n",
        "    y_pred = model.predict(X_test)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    report = classification_report(y_test, y_pred)\n",
        "\n",
        "    return accuracy, report\n",
        "\n",
        "# Function to plot bar chart of predictions\n",
        "def plot_predictions(y_true, y_pred):\n",
        "    unique_labels = np.unique(y_true)\n",
        "    true_counts = [np.sum(y_true == label) for label in unique_labels]\n",
        "    pred_counts = [np.sum(y_pred == label) for label in unique_labels]\n",
        "\n",
        "    fig, ax = plt.subplots()\n",
        "    width = 0.35\n",
        "    ind = np.arange(len(unique_labels))\n",
        "    ax.bar(ind, true_counts, width, label='True')\n",
        "    ax.bar(ind + width, pred_counts, width, label='Predicted')\n",
        "\n",
        "    ax.set_xlabel('Labels')\n",
        "    ax.set_ylabel('Counts')\n",
        "    ax.set_title('True vs Predicted Counts')\n",
        "    ax.set_xticks(ind + width / 2)\n",
        "    ax.set_xticklabels(unique_labels)\n",
        "    ax.legend()\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "# Main execution function\n",
        "def main():\n",
        "    # Preprocess training data\n",
        "    X_train, y_train, transformer = preprocess_data(train_data, is_train=True)\n",
        "\n",
        "    # Train model with SMOTE and specified hyperparameters\n",
        "    model = train_random_forest_with_smote(X_train, y_train)\n",
        "\n",
        "    # Preprocess testing data using the same transformer\n",
        "    X_test, y_test, _ = preprocess_data(test_data, transformer, is_train=False)\n",
        "\n",
        "    # Evaluate the test model\n",
        "    accuracy, report = evaluate_model(model, X_test, y_test)\n",
        "    print(f'Accuracy test: {accuracy}')\n",
        "    print(f'Classification Report test:\\n{report}')\n",
        "\n",
        "    # Evaluate the training model\n",
        "    accuracy_train, report_train = evaluate_model(model, X_train, y_train)\n",
        "    print(f'Accuracy train: {accuracy_train}')\n",
        "    print(f'Classification Report train:\\n{report_train}')\n",
        "\n",
        "    # Plot predictions\n",
        "    y_pred_test = model.predict(X_test)\n",
        "    plot_predictions(y_test, y_pred_test)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "sfueMakL6YEN",
        "outputId": "e9c52e49-6064-4735-923f-593353ea6b24"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial columns: Index(['Unnamed: 0', 'age', 'work-class', 'fnlwgt', 'education_num',\n",
            "       'marital-status', 'relationship', 'race', 'sex', 'capital-gain',\n",
            "       'capital-loss', 'hours-worked-per-week', 'native-country', 'occupation',\n",
            "       'income'],\n",
            "      dtype='object')\n",
            "Categorical features before encoding: []\n",
            "Encoded 'income': [0 1]\n",
            "Initial columns: Index(['Unnamed: 0', 'age', 'work-class', 'fnlwgt', 'education_num',\n",
            "       'marital-status', 'relationship', 'race', 'sex', 'capital-gain',\n",
            "       'capital-loss', 'hours-worked-per-week', 'native-country', 'occupation',\n",
            "       'income'],\n",
            "      dtype='object')\n",
            "Adjusted 'income' for test data: ['0' '1']\n",
            "Categorical features before encoding: []\n",
            "Encoded 'income': [0 1]\n",
            "Accuracy test: 0.8414102327866838\n",
            "Classification Report test:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.91      0.88      0.89     12435\n",
            "           1       0.65      0.72      0.68      3846\n",
            "\n",
            "    accuracy                           0.84     16281\n",
            "   macro avg       0.78      0.80      0.79     16281\n",
            "weighted avg       0.85      0.84      0.84     16281\n",
            "\n",
            "Accuracy train: 0.8510488007125089\n",
            "Classification Report train:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.88      0.90     24720\n",
            "           1       0.67      0.75      0.71      7841\n",
            "\n",
            "    accuracy                           0.85     32561\n",
            "   macro avg       0.79      0.82      0.80     32561\n",
            "weighted avg       0.86      0.85      0.85     32561\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Ur7xY-Iynum",
        "outputId": "a1351aab-cec5-4f00-dac2-3c4d1b2beb8b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Predictions in training \n",
            "\n",
            "[' <=50K' ' <=50K' ' <=50K' ... ' <=50K' ' <=50K' ' >50K']\n",
            "Predictions in TESTING \n",
            "\n",
            "[' <=50K.' ' <=50K.' ' >50K.' ... ' <=50K.' ' <=50K.' ' >50K.']\n"
          ]
        }
      ],
      "source": [
        "'''\n",
        "Random Forest implementation\n",
        "'''\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "\n",
        "# Step 1 - declaring x and y values for random forests\n",
        "\n",
        "x_train_rf = train_data.drop('income', axis=1)  # Features\n",
        "y_train_rf = train_data['income']               # Target variable\n",
        "\n",
        "x_test_rf = test_data.drop('income', axis=1)  # Features\n",
        "y_test_rf = test_data['income']               # Target variable\n",
        "\n",
        "# Step 2:\n",
        "# Perform one-hot encoding if there are categorical variables\n",
        "# Example:\n",
        "\n",
        "'''\n",
        "OHE = One Hot Encoding. It's required to run the Random Forest Classifier from SKLEARN\n",
        "'''\n",
        "\n",
        "x_train_rf_ohe = pd.get_dummies(x_train_rf)\n",
        "x_test_rf_ohe = pd.get_dummies(x_test_rf)\n",
        "\n",
        "# Step 3: Instantiate the Random Forest Classifier\n",
        "# You can specify hyperparameters such as n_estimators, max_depth, etc.\n",
        "# Example:\n",
        "# rf_classifier = RandomForestClassifier(n_estimators=100, max_depth=10, random_state=42)\n",
        "rf_classifier_train = RandomForestClassifier(random_state=42)\n",
        "rf_classifier_test = RandomForestClassifier(random_state=42)\n",
        "\n",
        "# Step 4: Train the models\n",
        "rf_classifier_train.fit(x_train_rf_ohe, y_train_rf)\n",
        "rf_classifier_test.fit(x_test_rf_ohe, y_test_rf)\n",
        "\n",
        "# Step 5: Making predictions - Assuming 'new_data' is the new DataFrame\n",
        "# we want to check containing features (excluding the income column)\n",
        "\n",
        "# x_train_rf = train_data.drop('income', axis=1)  # Features\n",
        "# y_train_rf = train_data['income']               # Target variable\n",
        "predictions_train_rf = rf_classifier_train.predict(x_train_rf_ohe)\n",
        "\n",
        "predictions_test_rf = rf_classifier_test.predict(x_test_rf_ohe)\n",
        "\n",
        "print(\"Predictions in training \\n\")\n",
        "print(predictions_train_rf)\n",
        "\n",
        "print(\"Predictions in TESTING \\n\")\n",
        "print(predictions_test_rf)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mu-dDj1J6W4K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# V9\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Assuming train_data and test_data are already loaded as dataframes\n",
        "# train_data, test_data\n",
        "\n",
        "# Function to preprocess data\n",
        "def preprocess_data(data, transformer=None, is_train=True):\n",
        "    print(\"Initial columns:\", data.columns)  # Initial check of all columns in the dataset\n",
        "\n",
        "    income_column = 'income'\n",
        "    if income_column not in data.columns:\n",
        "        raise ValueError(f\"The column '{income_column}' does not exist in the dataset.\")\n",
        "\n",
        "    # If it's test data, handle the period at the end\n",
        "    if not is_train:\n",
        "        data[income_column] = data[income_column].str.strip().str.replace('.', '')\n",
        "        print(\"Adjusted 'income' for test data:\", data[income_column].unique())  # Debug\n",
        "\n",
        "    # Identify and store categorical features excluding 'income'\n",
        "    categorical_features = data.select_dtypes(include=['object']).columns.tolist()\n",
        "    if income_column in categorical_features:\n",
        "        categorical_features.remove(income_column)\n",
        "    print(\"Categorical features before encoding:\", categorical_features)  # Debug statement\n",
        "\n",
        "    # Apply ColumnTransformer only to categorical features excluding 'income'\n",
        "    if transformer is None:\n",
        "        transformer = ColumnTransformer(\n",
        "            transformers=[('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)],\n",
        "            remainder='passthrough')\n",
        "        X = transformer.fit_transform(data.drop(columns=[income_column]))\n",
        "    else:\n",
        "        X = transformer.transform(data.drop(columns=[income_column]))\n",
        "\n",
        "    # Now encode the 'income' column after categorical handling\n",
        "    y = LabelEncoder().fit_transform(data[income_column])\n",
        "    print(\"Encoded 'income':\", np.unique(y))  # Debug the output of the encoded income\n",
        "\n",
        "    return X, y, transformer\n",
        "\n",
        "# Function to train the best Random Forest model using Grid Search and SMOTE\n",
        "def train_best_random_forest_with_smote(X, y):\n",
        "    # Apply SMOTE\n",
        "    smote = SMOTE(random_state=42)\n",
        "    X_smote, y_smote = smote.fit_resample(X, y)\n",
        "\n",
        "    # Define the parameter grid\n",
        "    param_grid = {\n",
        "        'n_estimators': [50, 100, 200],\n",
        "        'max_depth': [5, 10, 20, None],\n",
        "        'min_samples_split': [2, 5, 10],\n",
        "        'min_samples_leaf': [1, 2, 4],\n",
        "        'bootstrap': [True, False]\n",
        "    }\n",
        "\n",
        "    # Initialize the Random Forest Classifier\n",
        "    rf = RandomForestClassifier(random_state=42)\n",
        "\n",
        "    # Apply Grid Search with cross-validation\n",
        "    grid_search = GridSearchCV(estimator=rf, param_grid=param_grid, scoring='accuracy', cv=5, n_jobs=-1, verbose=2)\n",
        "    grid_search.fit(X_smote, y_smote)\n",
        "\n",
        "    print(f'Best Hyperparameters: {grid_search.best_params_}')\n",
        "    print(f'Best Training Accuracy: {grid_search.best_score_}')\n",
        "\n",
        "    # Return the best model found by Grid Search\n",
        "    return grid_search.best_estimator_\n",
        "\n",
        "# Function to evaluate the model\n",
        "def evaluate_model(model, X_test, y_test):\n",
        "    y_pred = model.predict(X_test)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    report = classification_report(y_test, y_pred)\n",
        "\n",
        "    return accuracy, report\n",
        "\n",
        "# Main execution function\n",
        "def main():\n",
        "    # Preprocess training data\n",
        "    X_train, y_train, transformer = preprocess_data(train_data, is_train=True)\n",
        "\n",
        "    # Train the best model using Grid Search and SMOTE\n",
        "    best_model = train_best_random_forest_with_smote(X_train, y_train)\n",
        "\n",
        "    # Preprocess testing data using the same transformer\n",
        "    X_test, y_test, _ = preprocess_data(test_data, transformer, is_train=False)\n",
        "\n",
        "    # Evaluate the test model\n",
        "    accuracy, report = evaluate_model(best_model, X_test, y_test)\n",
        "    print(f'Accuracy test: {accuracy}')\n",
        "    print(f'Classification Report test:\\n{report}')\n",
        "\n",
        "    # Evaluate the training model\n",
        "    accuracy_train, report_train = evaluate_model(best_model, X_train, y_train)\n",
        "    print(f'Accuracy train: {accuracy_train}')\n",
        "    print(f'Classification Report train:\\n{report_train}')\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        },
        "id": "biWgDvcfnwe3",
        "outputId": "34674551-2cb0-4fe3-ea5f-ccd1771d529d"
      },
      "execution_count": 8,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Initial columns: Index(['age', 'work-class', 'fnlwgt', 'education', 'education_num',\n",
            "       'marital-status', 'occupation', 'relationship', 'race', 'sex',\n",
            "       'capital-gain', 'capital-loss', 'hours-worked-per-week',\n",
            "       'native-country', 'income'],\n",
            "      dtype='object')\n",
            "Categorical features before encoding: ['work-class', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'native-country']\n",
            "Encoded 'income': [0 1]\n",
            "Fitting 5 folds for each of 216 candidates, totalling 1080 fits\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-1dc259e6cdf7>\u001b[0m in \u001b[0;36m<cell line: 106>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-8-1dc259e6cdf7>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;31m# Train the best model using Grid Search and SMOTE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m     \u001b[0mbest_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_best_random_forest_with_smote\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;31m# Preprocess testing data using the same transformer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-8-1dc259e6cdf7>\u001b[0m in \u001b[0;36mtrain_best_random_forest_with_smote\u001b[0;34m(X, y)\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0;31m# Apply Grid Search with cross-validation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0mgrid_search\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m     \u001b[0mgrid_search\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_smote\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_smote\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Best Hyperparameters: {grid_search.best_params_}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    872\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    873\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 874\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    875\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    876\u001b[0m             \u001b[0;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1386\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1387\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1388\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1389\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1390\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    819\u001b[0m                     )\n\u001b[1;32m    820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 821\u001b[0;31m                 out = parallel(\n\u001b[0m\u001b[1;32m    822\u001b[0m                     delayed(_fit_and_score)(\n\u001b[1;32m    823\u001b[0m                         \u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_estimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mdelayed_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         )\n\u001b[0;32m---> 63\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable_with_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   2005\u001b[0m         \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2006\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2007\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturn_generator\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2008\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2009\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_get_outputs\u001b[0;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[1;32m   1648\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1649\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1650\u001b[0;31m                 \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_retrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1651\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1652\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mGeneratorExit\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1760\u001b[0m                 (self._jobs[0].get_status(\n\u001b[1;32m   1761\u001b[0m                     timeout=self.timeout) == TASK_PENDING)):\n\u001b[0;32m-> 1762\u001b[0;31m                 \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1763\u001b[0m                 \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1764\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "# Assuming train_data and test_data are already loaded as dataframes\n",
        "# train_data, test_data\n",
        "\n",
        "# Function to preprocess data\n",
        "def preprocess_data(data, transformer=None, is_train=True):\n",
        "    print(\"Initial columns:\", data.columns)  # Initial check of all columns in the dataset\n",
        "\n",
        "    income_column = 'income'\n",
        "    if income_column not in data.columns:\n",
        "        raise ValueError(f\"The column '{income_column}' does not exist in the dataset.\")\n",
        "\n",
        "    # If it's test data, handle the period at the end\n",
        "    if not is_train:\n",
        "        data[income_column] = data[income_column].str.strip().str.replace('.', '')\n",
        "        print(\"Adjusted 'income' for test data:\", data[income_column].unique())  # Debug\n",
        "\n",
        "    # Identify and store categorical features excluding 'income'\n",
        "    categorical_features = data.select_dtypes(include=['object']).columns.tolist()\n",
        "    if income_column in categorical_features:\n",
        "        categorical_features.remove(income_column)\n",
        "    print(\"Categorical features before encoding:\", categorical_features)  # Debug statement\n",
        "\n",
        "    # Apply ColumnTransformer only to categorical features excluding 'income'\n",
        "    if transformer is None:\n",
        "        transformer = ColumnTransformer(\n",
        "            transformers=[('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)],\n",
        "            remainder='passthrough')\n",
        "        X = transformer.fit_transform(data.drop(columns=[income_column]))\n",
        "    else:\n",
        "        X = transformer.transform(data.drop(columns=[income_column]))\n",
        "\n",
        "    # Now encode the 'income' column after categorical handling\n",
        "    y = LabelEncoder().fit_transform(data[income_column])\n",
        "    print(\"Encoded 'income':\", np.unique(y))  # Debug the output of the encoded income\n",
        "\n",
        "    return X, y, transformer\n",
        "\n",
        "# Function to train the Random Forest model with SMOTE\n",
        "def train_random_forest_with_smote(X, y):\n",
        "    # Apply SMOTE\n",
        "    smote = SMOTE(random_state=42)\n",
        "    X_smote, y_smote = smote.fit_resample(X, y)\n",
        "\n",
        "    # Train the Random Forest model using default hyperparameters\n",
        "    model = RandomForestClassifier(random_state=42)\n",
        "    model.fit(X_smote, y_smote)\n",
        "\n",
        "    return model\n",
        "\n",
        "# Function to evaluate the model\n",
        "def evaluate_model(model, X_test, y_test):\n",
        "    y_pred = model.predict(X_test)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    report = classification_report(y_test, y_pred)\n",
        "\n",
        "    return accuracy, report\n",
        "\n",
        "# Main execution function\n",
        "def main():\n",
        "    # Preprocess training data\n",
        "    X_train, y_train, transformer = preprocess_data(train_data, is_train=True)\n",
        "\n",
        "    # Train model with SMOTE using default hyperparameters\n",
        "    model = train_random_forest_with_smote(X_train, y_train)\n",
        "\n",
        "    # Preprocess testing data using the same transformer\n",
        "    X_test, y_test, _ = preprocess_data(test_data, transformer, is_train=False)\n",
        "\n",
        "    # Evaluate the test model\n",
        "    accuracy, report = evaluate_model(model, X_test, y_test)\n",
        "    print(f'Accuracy test: {accuracy}')\n",
        "    print(f'Classification Report test:\\n{report}')\n",
        "\n",
        "    # Evaluate the training model\n",
        "    accuracy_train, report_train = evaluate_model(model, X_train, y_train)\n",
        "    print(f'Accuracy train: {accuracy_train}')\n",
        "    print(f'Classification Report train:\\n{report_train}')\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wRIBZUvdltil",
        "outputId": "8f23dcc1-15ce-4b2d-d635-acc27ca58f20"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial columns: Index(['age', 'work-class', 'fnlwgt', 'education', 'education_num',\n",
            "       'marital-status', 'occupation', 'relationship', 'race', 'sex',\n",
            "       'capital-gain', 'capital-loss', 'hours-worked-per-week',\n",
            "       'native-country', 'income'],\n",
            "      dtype='object')\n",
            "Categorical features before encoding: ['work-class', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'native-country']\n",
            "Encoded 'income': [0 1]\n",
            "Initial columns: Index(['age', 'work-class', 'fnlwgt', 'education', 'education_num',\n",
            "       'marital-status', 'occupation', 'relationship', 'race', 'sex',\n",
            "       'capital-gain', 'capital-loss', 'hours-worked-per-week',\n",
            "       'native-country', 'income'],\n",
            "      dtype='object')\n",
            "Adjusted 'income' for test data: ['<=50K' '>50K']\n",
            "Categorical features before encoding: ['work-class', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'native-country']\n",
            "Encoded 'income': [0 1]\n",
            "Accuracy test: 0.8487193661323015\n",
            "Classification Report test:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      0.92      0.90     12435\n",
            "           1       0.70      0.62      0.66      3846\n",
            "\n",
            "    accuracy                           0.85     16281\n",
            "   macro avg       0.80      0.77      0.78     16281\n",
            "weighted avg       0.84      0.85      0.85     16281\n",
            "\n",
            "Accuracy train: 0.9998771536500721\n",
            "Classification Report train:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00     24720\n",
            "           1       1.00      1.00      1.00      7841\n",
            "\n",
            "    accuracy                           1.00     32561\n",
            "   macro avg       1.00      1.00      1.00     32561\n",
            "weighted avg       1.00      1.00      1.00     32561\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kJoAT7bgoMcK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mYQimk567Eh-",
        "outputId": "dc8d6ab8-0770-4aab-bbeb-d79aa0447f92"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Confusion Matrix:\n",
            "[[12435     0]\n",
            " [    1  3845]]\n",
            "Accuracy: 0.9999385787113814\n"
          ]
        }
      ],
      "source": [
        "'''\n",
        "Confusion matrix for Random Forests\n",
        "'''\n",
        "\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "\n",
        "# Calculate confusion matrix\n",
        "conf_matrix_rf = confusion_matrix(y_test_rf, predictions_test_rf)\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy_rf = accuracy_score(y_test_rf, predictions_test_rf)\n",
        "\n",
        "print(\"Confusion Matrix:\")\n",
        "print(conf_matrix_rf)\n",
        "print(\"Accuracy:\", accuracy_rf)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HB8i-cac7Exh"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "Code block to replace missing values with mode\n",
        "'''\n",
        "\n",
        "# This function takes a dataframe and returns * A MODIFIED COPY *. Doesn't change the original\n",
        "def replace_question_marks(df, columns_to_replace):\n",
        "    most_common_elements = {}\n",
        "    most_common_counts = {}\n",
        "    df_copy = df.copy()  # Create a copy of the original DataFrame\n",
        "\n",
        "    for col in columns_to_replace:\n",
        "        # Find the most common element and its count in the column\n",
        "        value_counts = df[col].value_counts()\n",
        "        most_common = value_counts.idxmax()\n",
        "        most_common_count = value_counts.max()\n",
        "\n",
        "        most_common_elements[col] = most_common\n",
        "        most_common_counts[col] = most_common_count\n",
        "\n",
        "        # Replace ' ?' with the most common element in the column\n",
        "        df_copy[col] = df_copy[col].replace(' ?', most_common)\n",
        "\n",
        "    return df_copy, most_common_elements, most_common_counts\n",
        "\n",
        "columns_to_replace = ['work-class', 'occupation', 'native-country']\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U0uaprJC7DcR"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AQrJenVdKWTE",
        "outputId": "d1fcf5ef-26c3-4c6a-a6a7-0df31687d865"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Predictions in training \n",
            "\n",
            "[' <=50K' ' <=50K' ' <=50K' ... ' <=50K' ' <=50K' ' >50K']\n",
            "Predictions in TESTING \n",
            "\n",
            "[' <=50K.' ' <=50K.' ' >50K.' ... ' <=50K.' ' <=50K.' ' >50K.']\n"
          ]
        }
      ],
      "source": [
        "'''\n",
        "Testing without missing values\n",
        "'''\n",
        "data_train_modified_rf, most_common_elements_data_train_rf, most_common_counts_data_train_rf = replace_question_marks(train_data, columns_to_replace)\n",
        "data_test_modified_rf, most_common_elements_data_test_rf, most_common_counts_data_test_rf = replace_question_marks(test_data, columns_to_replace)\n",
        "\n",
        "# Step 1 - declaring x and y values for random forests\n",
        "\n",
        "x_train_rf_modified = data_train_modified_rf.drop('income', axis=1)  # Features\n",
        "y_train_rf_modified = data_train_modified_rf['income']               # Target variable\n",
        "\n",
        "x_test_rf_modified = data_test_modified_rf.drop('income', axis=1)  # Features\n",
        "y_test_rf_modified = data_test_modified_rf['income']               # Target variable\n",
        "\n",
        "# Step 2:\n",
        "# Perform one-hot encoding if there are categorical variables\n",
        "# Example:\n",
        "\n",
        "'''\n",
        "OHE = One Hot Encoding. It's required to run the Random Forest Classifier from SKLEARN\n",
        "'''\n",
        "\n",
        "x_train_rf_ohe_modified = pd.get_dummies(x_train_rf_modified)\n",
        "x_test_rf_ohe_modified = pd.get_dummies(x_test_rf_modified)\n",
        "\n",
        "# Step 3: Instantiate the Random Forest Classifier\n",
        "# You can specify hyperparameters such as n_estimators, max_depth, etc.\n",
        "# Example:\n",
        "# rf_classifier = RandomForestClassifier(n_estimators=100, max_depth=10, random_state=42)\n",
        "rf_classifier_train1 = RandomForestClassifier(random_state=42)\n",
        "rf_classifier_test1 = RandomForestClassifier(random_state=42)\n",
        "\n",
        "# Step 4: Train the models\n",
        "rf_classifier_train1.fit(x_train_rf_ohe_modified, y_train_rf_modified)\n",
        "rf_classifier_test1.fit(x_test_rf_ohe_modified, y_test_rf_modified)\n",
        "\n",
        "# Step 5: Making predictions - Assuming 'new_data' is the new DataFrame\n",
        "# we want to check containing features (excluding the income column)\n",
        "\n",
        "# x_train_rf = train_data.drop('income', axis=1)  # Features\n",
        "# y_train_rf = train_data['income']               # Target variable\n",
        "predictions_train_rf1 = rf_classifier_train1.predict(x_train_rf_ohe_modified)\n",
        "\n",
        "predictions_test_rf1 = rf_classifier_test1.predict(x_test_rf_ohe_modified)\n",
        "\n",
        "print(\"Predictions in training \\n\")\n",
        "print(predictions_train_rf1)\n",
        "\n",
        "print(\"Predictions in TESTING \\n\")\n",
        "print(predictions_test_rf1)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jinjVxnMMYJ4",
        "outputId": "9488ba99-c3e0-479d-debb-4aeb3347b1f2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Confusion Matrix new:\n",
            "[[12435     0]\n",
            " [    1  3845]]\n",
            "Accuracy new: 0.9999385787113814\n"
          ]
        }
      ],
      "source": [
        "'''\n",
        "Confusion matrix for Random Forests # Without missing\n",
        "'''\n",
        "\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "\n",
        "# Calculate confusion matrix\n",
        "conf_matrix_rf1 = confusion_matrix(y_test_rf_modified, predictions_test_rf1)\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy_rf1 = accuracy_score(y_test_rf_modified, predictions_test_rf1)\n",
        "\n",
        "print(\"Confusion Matrix new:\")\n",
        "print(conf_matrix_rf1)\n",
        "print(\"Accuracy new:\", accuracy_rf1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U7SzXt03ZUBk"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPdM+/8lPbPTp37F7Ke8OLK",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}