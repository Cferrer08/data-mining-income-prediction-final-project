{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/albertbaezd/data-mining-final-project/blob/develop/Data_Mining_project_code_Albert_Random.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "c-24Su6VnRt3"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from google.colab import drive\n",
        "from sklearn.utils import resample\n",
        "import matplotlib.pyplot as plt\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "\n",
        "# import the datasets: -  - Albert: remove comment if you want to manually place the files here. If not, it's going to use a Google Drive folder\n",
        "# train_data = pd.read_csv(\"census-income.data.csv\") - Albert: remove comment if you want to manually place the files here. If not, it's going to use a Google Drive folder\n",
        "# test_data = pd.read_csv(\"census-income.test.csv\")  - Albert: remove comment if you want to manually place the files here. If not, it's going to use a Google Drive folder\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QmTZkEWhn0w0",
        "outputId": "d23eb133-1442-4577-f298-65feb2eaad99"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "       age         work-class  fnlwgt    education  education_num  \\\n",
            "0       39          State-gov   77516    Bachelors             13   \n",
            "1       50   Self-emp-not-inc   83311    Bachelors             13   \n",
            "2       38            Private  215646      HS-grad              9   \n",
            "3       53            Private  234721         11th              7   \n",
            "4       28            Private  338409    Bachelors             13   \n",
            "...    ...                ...     ...          ...            ...   \n",
            "32556   27            Private  257302   Assoc-acdm             12   \n",
            "32557   40            Private  154374      HS-grad              9   \n",
            "32558   58            Private  151910      HS-grad              9   \n",
            "32559   22            Private  201490      HS-grad              9   \n",
            "32560   52       Self-emp-inc  287927      HS-grad              9   \n",
            "\n",
            "            marital-status          occupation    relationship    race  \\\n",
            "0            Never-married        Adm-clerical   Not-in-family   White   \n",
            "1       Married-civ-spouse     Exec-managerial         Husband   White   \n",
            "2                 Divorced   Handlers-cleaners   Not-in-family   White   \n",
            "3       Married-civ-spouse   Handlers-cleaners         Husband   Black   \n",
            "4       Married-civ-spouse      Prof-specialty            Wife   Black   \n",
            "...                    ...                 ...             ...     ...   \n",
            "32556   Married-civ-spouse        Tech-support            Wife   White   \n",
            "32557   Married-civ-spouse   Machine-op-inspct         Husband   White   \n",
            "32558              Widowed        Adm-clerical       Unmarried   White   \n",
            "32559        Never-married        Adm-clerical       Own-child   White   \n",
            "32560   Married-civ-spouse     Exec-managerial            Wife   White   \n",
            "\n",
            "           sex  capital-gain  capital-loss  hours-worked-per-week  \\\n",
            "0         Male          2174             0                     40   \n",
            "1         Male             0             0                     13   \n",
            "2         Male             0             0                     40   \n",
            "3         Male             0             0                     40   \n",
            "4       Female             0             0                     40   \n",
            "...        ...           ...           ...                    ...   \n",
            "32556   Female             0             0                     38   \n",
            "32557     Male             0             0                     40   \n",
            "32558   Female             0             0                     40   \n",
            "32559     Male             0             0                     20   \n",
            "32560   Female         15024             0                     40   \n",
            "\n",
            "       native-country  income  \n",
            "0       United-States   <=50K  \n",
            "1       United-States   <=50K  \n",
            "2       United-States   <=50K  \n",
            "3       United-States   <=50K  \n",
            "4                Cuba   <=50K  \n",
            "...               ...     ...  \n",
            "32556   United-States   <=50K  \n",
            "32557   United-States    >50K  \n",
            "32558   United-States   <=50K  \n",
            "32559   United-States   <=50K  \n",
            "32560   United-States    >50K  \n",
            "\n",
            "[32561 rows x 15 columns]\n",
            "       age     work-class  fnlwgt      education  education_num  \\\n",
            "0       25        Private  226802           11th              7   \n",
            "1       38        Private   89814        HS-grad              9   \n",
            "2       28      Local-gov  336951     Assoc-acdm             12   \n",
            "3       44        Private  160323   Some-college             10   \n",
            "4       18              ?  103497   Some-college             10   \n",
            "...    ...            ...     ...            ...            ...   \n",
            "16276   39        Private  215419      Bachelors             13   \n",
            "16277   64              ?  321403        HS-grad              9   \n",
            "16278   38        Private  374983      Bachelors             13   \n",
            "16279   44        Private   83891      Bachelors             13   \n",
            "16280   35   Self-emp-inc  182148      Bachelors             13   \n",
            "\n",
            "            marital-status          occupation     relationship  \\\n",
            "0            Never-married   Machine-op-inspct        Own-child   \n",
            "1       Married-civ-spouse     Farming-fishing          Husband   \n",
            "2       Married-civ-spouse     Protective-serv          Husband   \n",
            "3       Married-civ-spouse   Machine-op-inspct          Husband   \n",
            "4            Never-married                   ?        Own-child   \n",
            "...                    ...                 ...              ...   \n",
            "16276             Divorced      Prof-specialty    Not-in-family   \n",
            "16277              Widowed                   ?   Other-relative   \n",
            "16278   Married-civ-spouse      Prof-specialty          Husband   \n",
            "16279             Divorced        Adm-clerical        Own-child   \n",
            "16280   Married-civ-spouse     Exec-managerial          Husband   \n",
            "\n",
            "                      race      sex  capital-gain  capital-loss  \\\n",
            "0                    Black     Male             0             0   \n",
            "1                    White     Male             0             0   \n",
            "2                    White     Male             0             0   \n",
            "3                    Black     Male          7688             0   \n",
            "4                    White   Female             0             0   \n",
            "...                    ...      ...           ...           ...   \n",
            "16276                White   Female             0             0   \n",
            "16277                Black     Male             0             0   \n",
            "16278                White     Male             0             0   \n",
            "16279   Asian-Pac-Islander     Male          5455             0   \n",
            "16280                White     Male             0             0   \n",
            "\n",
            "       hours-worked-per-week  native-country   income  \n",
            "0                         40   United-States   <=50K.  \n",
            "1                         50   United-States   <=50K.  \n",
            "2                         40   United-States    >50K.  \n",
            "3                         40   United-States    >50K.  \n",
            "4                         30   United-States   <=50K.  \n",
            "...                      ...             ...      ...  \n",
            "16276                     36   United-States   <=50K.  \n",
            "16277                     40   United-States   <=50K.  \n",
            "16278                     50   United-States   <=50K.  \n",
            "16279                     40   United-States   <=50K.  \n",
            "16280                     60   United-States    >50K.  \n",
            "\n",
            "[16281 rows x 15 columns]\n"
          ]
        }
      ],
      "source": [
        "'''\n",
        "Here, we authenticate with Google Drive to add the datafiles from a Drive folder\n",
        "\n",
        "Instructions:\n",
        "\n",
        "1. Create a folder in your Google Drive, called data-mining-csv-files\n",
        "2. Insert both csv files (test and train) with the original names there.\n",
        "3. Just run this cell to import the code\n",
        "'''\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "train_data = pd.read_csv(\"/content/drive/My Drive/data-mining-csv-files/census-income.data.csv\") #- Albert: remove comment if you want to manually place the files here. If not, it's going to use a Google Drive folder\n",
        "test_data = pd.read_csv(\"/content/drive/My Drive/data-mining-csv-files/census-income.test.csv\")  #- Albert: remove comment if you want to manually place the files here. If not, it's going to use a Google Drive folder\n",
        "\n",
        "# Displaying results:\n",
        "\n",
        "print(train_data)\n",
        "print(test_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DMxm_vjjcTWh",
        "outputId": "b489b58c-778d-4f90-ae60-a32168a8ca57"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial columns: Index(['age', 'work-class', 'fnlwgt', 'education', 'education_num',\n",
            "       'marital-status', 'occupation', 'relationship', 'race', 'sex',\n",
            "       'capital-gain', 'capital-loss', 'hours-worked-per-week',\n",
            "       'native-country', 'income'],\n",
            "      dtype='object')\n",
            "Categorical features before encoding: ['work-class', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'native-country']\n",
            "Encoded 'income': [0 1]\n",
            "Initial columns: Index(['age', 'work-class', 'fnlwgt', 'education', 'education_num',\n",
            "       'marital-status', 'occupation', 'relationship', 'race', 'sex',\n",
            "       'capital-gain', 'capital-loss', 'hours-worked-per-week',\n",
            "       'native-country', 'income'],\n",
            "      dtype='object')\n",
            "Adjusted 'income' for test data: ['<=50K' '>50K']\n",
            "Categorical features before encoding: ['work-class', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'native-country']\n",
            "Encoded 'income': [0 1]\n",
            "Accuracy test: 0.8487193661323015\n",
            "Classification Report test:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      0.92      0.90     12435\n",
            "           1       0.70      0.62      0.66      3846\n",
            "\n",
            "    accuracy                           0.85     16281\n",
            "   macro avg       0.80      0.77      0.78     16281\n",
            "weighted avg       0.84      0.85      0.85     16281\n",
            "\n",
            "Accuracy train: 0.9998771536500721\n",
            "Classification Report train:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00     24720\n",
            "           1       1.00      1.00      1.00      7841\n",
            "\n",
            "    accuracy                           1.00     32561\n",
            "   macro avg       1.00      1.00      1.00     32561\n",
            "weighted avg       1.00      1.00      1.00     32561\n",
            "\n"
          ]
        }
      ],
      "source": [
        "'''\n",
        "One Hot Encoding Implementation # default, version 1\n",
        "'''\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "\n",
        "# Assuming train_data and test_data are already loaded as dataframes\n",
        "# train_data, test_data\n",
        "\n",
        "# Function to preprocess data\n",
        "\n",
        "def preprocess_data(data, transformer=None, is_train=True):\n",
        "    print(\"Initial columns:\", data.columns)  # Initial check of all columns in the dataset\n",
        "\n",
        "    income_column = 'income'\n",
        "    if income_column not in data.columns:\n",
        "        raise ValueError(f\"The column '{income_column}' does not exist in the dataset.\")\n",
        "\n",
        "    # If it's test data, handle the period at the end\n",
        "    if not is_train:\n",
        "        data[income_column] = data[income_column].str.strip().str.replace('.', '')\n",
        "        print(\"Adjusted 'income' for test data:\", data[income_column].unique())  # Debug\n",
        "\n",
        "    # Identify and store categorical features excluding 'income'\n",
        "    categorical_features = data.select_dtypes(include=['object']).columns.tolist()\n",
        "    if income_column in categorical_features:\n",
        "        categorical_features.remove(income_column)\n",
        "    print(\"Categorical features before encoding:\", categorical_features)  # Debug statement\n",
        "\n",
        "    # Apply ColumnTransformer only to categorical features excluding 'income'\n",
        "    if transformer is None:\n",
        "        transformer = ColumnTransformer(\n",
        "            transformers=[('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)],\n",
        "            remainder='passthrough')\n",
        "        X = transformer.fit_transform(data.drop(columns=[income_column]))\n",
        "    else:\n",
        "        X = transformer.transform(data.drop(columns=[income_column]))\n",
        "\n",
        "    # Now encode the 'income' column after categorical handling\n",
        "    y = LabelEncoder().fit_transform(data[income_column])\n",
        "    print(\"Encoded 'income':\", np.unique(y))  # Debug the output of the encoded income\n",
        "\n",
        "    return X, y, transformer\n",
        "\n",
        "\n",
        "# Function to train the Random Forest model with SMOTE\n",
        "def train_random_forest_with_smote(X, y):\n",
        "    # Apply SMOTE\n",
        "    smote = SMOTE(random_state=42)\n",
        "    X_smote, y_smote = smote.fit_resample(X, y)\n",
        "\n",
        "    # Train the Random Forest\n",
        "    model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "    model.fit(X_smote, y_smote)\n",
        "\n",
        "    return model\n",
        "\n",
        "# Evaluate the model\n",
        "def evaluate_model(model, X_test, y_test):\n",
        "    y_pred = model.predict(X_test)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    report = classification_report(y_test, y_pred)\n",
        "\n",
        "    return accuracy, report\n",
        "\n",
        "# Main execution function\n",
        "def main():\n",
        "    # Preprocess training data\n",
        "    X_train, y_train, transformer = preprocess_data(train_data, is_train=True)\n",
        "\n",
        "    # Train model with SMOTE\n",
        "    smote = SMOTE(random_state=42)\n",
        "    X_smote, y_smote = smote.fit_resample(X_train, y_train)\n",
        "    model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "    model.fit(X_smote, y_smote)\n",
        "\n",
        "    # Preprocess testing data using the same transformer\n",
        "    X_test, y_test, _ = preprocess_data(test_data, transformer, is_train=False)\n",
        "\n",
        "    # Evaluate the test model\n",
        "    accuracy, report = evaluate_model(model, X_test, y_test)\n",
        "    print(f'Accuracy test: {accuracy}')\n",
        "    print(f'Classification Report test:\\n{report}')\n",
        "\n",
        "    # Evaluate the test model\n",
        "    accuracy1, report1 = evaluate_model(model, X_train, y_train)\n",
        "    print(f'Accuracy train: {accuracy1}')\n",
        "    print(f'Classification Report train:\\n{report1}')\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Initial columns: Index(['age', 'work-class', 'fnlwgt', 'education', 'education_num',\n",
        "       'marital-status', 'occupation', 'relationship', 'race', 'sex',\n",
        "       'capital-gain', 'capital-loss', 'hours-worked-per-week',\n",
        "       'native-country', 'income'],\n",
        "      dtype='object')\n",
        "Categorical features before encoding: []\n",
        "Encoded 'income': [0 1]\n",
        "Initial columns: Index(['age', 'work-class', 'fnlwgt', 'education', 'education_num',\n",
        "       'marital-status', 'occupation', 'relationship', 'race', 'sex',\n",
        "       'capital-gain', 'capital-loss', 'hours-worked-per-week',\n",
        "       'native-country', 'income'],\n",
        "      dtype='object')\n",
        "Adjusted 'income' for test data: ['<=50K' '>50K']\n",
        "Categorical features before encoding: []\n",
        "Encoded 'income': [0 1]\n",
        "Accuracy test: 0.8431914501566243\n",
        "Classification Report test:\n",
        "              precision    recall  f1-score   support\n",
        "\n",
        "           0       0.90      0.90      0.90     12435\n",
        "           1       0.67      0.67      0.67      3846\n",
        "\n",
        "    accuracy                           0.84     16281\n",
        "   macro avg       0.78      0.78      0.78     16281\n",
        "weighted avg       0.84      0.84      0.84     16281\n",
        "\n",
        "Accuracy train: 0.9999385768250361\n",
        "Classification Report train:\n",
        "              precision    recall  f1-score   support\n",
        "\n",
        "           0       1.00      1.00      1.00     24720\n",
        "           1       1.00      1.00      1.00      7841\n",
        "\n",
        "    accuracy                           1.00     32561\n",
        "   macro avg       1.00      1.00      1.00     32561\n",
        "weighted avg       1.00      1.00      1.00     32561"
      ],
      "metadata": {
        "id": "8DaHWsee-fLa"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yuDT5SIupHDp",
        "outputId": "e89f9d1f-be45-42c8-d3ea-e21d587b7263"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial columns: Index(['age', 'work-class', 'fnlwgt', 'education', 'education_num',\n",
            "       'marital-status', 'occupation', 'relationship', 'race', 'sex',\n",
            "       'capital-gain', 'capital-loss', 'hours-worked-per-week',\n",
            "       'native-country', 'income'],\n",
            "      dtype='object')\n",
            "'fnlwgt' column dropped.\n",
            "Categorical features before encoding: ['work-class', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'native-country']\n",
            "Encoded 'income': [0 1]\n",
            "Initial columns: Index(['age', 'work-class', 'fnlwgt', 'education', 'education_num',\n",
            "       'marital-status', 'occupation', 'relationship', 'race', 'sex',\n",
            "       'capital-gain', 'capital-loss', 'hours-worked-per-week',\n",
            "       'native-country', 'income'],\n",
            "      dtype='object')\n",
            "'fnlwgt' column dropped.\n",
            "Adjusted 'income' for test data: ['<=50K' '>50K']\n",
            "Categorical features before encoding: ['work-class', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'native-country']\n",
            "Encoded 'income': [0 1]\n",
            "Accuracy: 0.839690436705362\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      0.91      0.90     12435\n",
            "           1       0.68      0.62      0.65      3846\n",
            "\n",
            "    accuracy                           0.84     16281\n",
            "   macro avg       0.78      0.76      0.77     16281\n",
            "weighted avg       0.84      0.84      0.84     16281\n",
            "\n"
          ]
        }
      ],
      "source": [
        "'''\n",
        "One Hot Encoding Implementation # removing fnlweight column, version 2\n",
        "# Version 2\n",
        "\n",
        "Outcome: less precision\n",
        "'''\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "\n",
        "# Assuming train_data and test_data are already loaded as dataframes\n",
        "# train_data, test_data\n",
        "\n",
        "# Function to preprocess data\n",
        "\n",
        "def preprocess_data(data, transformer=None, is_train=True):\n",
        "    print(\"Initial columns:\", data.columns)  # Initial check of all columns in the dataset\n",
        "\n",
        "    income_column = 'income'\n",
        "    fnlwgt_column = 'fnlwgt'  # Define the column name to be dropped\n",
        "\n",
        "    if income_column not in data.columns:\n",
        "        raise ValueError(f\"The column '{income_column}' does not exist in the dataset.\")\n",
        "\n",
        "    # Drop the 'fnlwgt' column from the dataset\n",
        "    if fnlwgt_column in data.columns:\n",
        "        data = data.drop(columns=[fnlwgt_column])\n",
        "        print(f\"'{fnlwgt_column}' column dropped.\")\n",
        "    else:\n",
        "        print(f\"No '{fnlwgt_column}' column to drop.\")\n",
        "\n",
        "    # If it's test data, handle the period at the end\n",
        "    if not is_train:\n",
        "        data[income_column] = data[income_column].str.strip().str.replace('.', '')\n",
        "        print(\"Adjusted 'income' for test data:\", data[income_column].unique())  # Debug\n",
        "\n",
        "    # Identify and store categorical features excluding 'income'\n",
        "    categorical_features = data.select_dtypes(include=['object']).columns.tolist()\n",
        "    if income_column in categorical_features:\n",
        "        categorical_features.remove(income_column)\n",
        "    print(\"Categorical features before encoding:\", categorical_features)  # Debug statement\n",
        "\n",
        "    # Apply ColumnTransformer only to categorical features excluding 'income'\n",
        "    if transformer is None:\n",
        "        transformer = ColumnTransformer(\n",
        "            transformers=[('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)],\n",
        "            remainder='passthrough')\n",
        "        X = transformer.fit_transform(data.drop(columns=[income_column]))\n",
        "    else:\n",
        "        X = transformer.transform(data.drop(columns=[income_column]))\n",
        "\n",
        "    # Now encode the 'income' column after categorical handling\n",
        "    y = LabelEncoder().fit_transform(data[income_column])\n",
        "    print(\"Encoded 'income':\", np.unique(y))  # Debug the output of the encoded income\n",
        "\n",
        "    return X, y, transformer\n",
        "\n",
        "# Function to train the Random Forest model with SMOTE\n",
        "def train_random_forest_with_smote(X, y):\n",
        "    # Apply SMOTE\n",
        "    smote = SMOTE(random_state=42)\n",
        "    X_smote, y_smote = smote.fit_resample(X, y)\n",
        "\n",
        "    # Train the Random Forest\n",
        "    model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "    model.fit(X_smote, y_smote)\n",
        "\n",
        "    return model\n",
        "\n",
        "# Evaluate the model\n",
        "def evaluate_model(model, X_test, y_test):\n",
        "    y_pred = model.predict(X_test)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    report = classification_report(y_test, y_pred)\n",
        "\n",
        "    return accuracy, report\n",
        "\n",
        "# Main execution function\n",
        "def main():\n",
        "    # Preprocess training data\n",
        "    X_train, y_train, transformer = preprocess_data(train_data, is_train=True)\n",
        "\n",
        "    # Train model with SMOTE\n",
        "    smote = SMOTE(random_state=42)\n",
        "    X_smote, y_smote = smote.fit_resample(X_train, y_train)\n",
        "    model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "    model.fit(X_smote, y_smote)\n",
        "\n",
        "    # Preprocess testing data using the same transformer\n",
        "    X_test, y_test, _ = preprocess_data(test_data, transformer, is_train=False)\n",
        "\n",
        "    # Evaluate the model\n",
        "    accuracy, report = evaluate_model(model, X_test, y_test)\n",
        "    print(f'Accuracy: {accuracy}')\n",
        "    print(f'Classification Report:\\n{report}')\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Initial columns: Index(['age', 'work-class', 'fnlwgt', 'education', 'education_num',\n",
        "       'marital-status', 'occupation', 'relationship', 'race', 'sex',\n",
        "       'capital-gain', 'capital-loss', 'hours-worked-per-week',\n",
        "       'native-country', 'income'],\n",
        "      dtype='object')\n",
        "'fnlwgt' column dropped.\n",
        "Categorical features before encoding: ['work-class', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'native-country']\n",
        "Encoded 'income': [0 1]\n",
        "Initial columns: Index(['age', 'work-class', 'fnlwgt', 'education', 'education_num',\n",
        "       'marital-status', 'occupation', 'relationship', 'race', 'sex',\n",
        "       'capital-gain', 'capital-loss', 'hours-worked-per-week',\n",
        "       'native-country', 'income'],\n",
        "      dtype='object')\n",
        "'fnlwgt' column dropped.\n",
        "Adjusted 'income' for test data: ['<=50K' '>50K']\n",
        "Categorical features before encoding: ['work-class', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'native-country']\n",
        "Encoded 'income': [0 1]\n",
        "Accuracy: 0.839690436705362\n",
        "Classification Report:\n",
        "              precision    recall  f1-score   support\n",
        "\n",
        "           0       0.89      0.91      0.90     12435\n",
        "           1       0.68      0.62      0.65      3846\n",
        "\n",
        "    accuracy                           0.84     16281\n",
        "   macro avg       0.78      0.76      0.77     16281\n",
        "weighted avg       0.84      0.84      0.84     16281\n"
      ],
      "metadata": {
        "id": "8Fm_yNAz-xsm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WCVcvQIMpXfw",
        "outputId": "a0afb180-4109-457a-a422-6f2391a3b138"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Index(['age', 'work-class', 'fnlwgt', 'education', 'education_num',\n",
              "       'marital-status', 'occupation', 'relationship', 'race', 'sex',\n",
              "       'capital-gain', 'capital-loss', 'hours-worked-per-week',\n",
              "       'native-country', 'income'],\n",
              "      dtype='object')"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_data.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tMD5HMgW0FEO",
        "outputId": "c8c63318-45b9-4392-b96b-439d0da55a41"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial columns: Index(['age', 'work-class', 'fnlwgt', 'education', 'education_num',\n",
            "       'marital-status', 'occupation', 'relationship', 'race', 'sex',\n",
            "       'capital-gain', 'capital-loss', 'hours-worked-per-week',\n",
            "       'native-country', 'income'],\n",
            "      dtype='object')\n",
            "Encoded features: []\n",
            "Encoded 'income': [0 1]\n",
            "Initial columns: Index(['age', 'work-class', 'fnlwgt', 'education', 'education_num',\n",
            "       'marital-status', 'occupation', 'relationship', 'race', 'sex',\n",
            "       'capital-gain', 'capital-loss', 'hours-worked-per-week',\n",
            "       'native-country', 'income'],\n",
            "      dtype='object')\n",
            "Adjusted 'income' for test data: ['<=50K' '>50K']\n",
            "Encoded features: []\n",
            "Encoded 'income': [0 1]\n",
            "Accuracy: 0.8431914501566243\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      0.90      0.90     12435\n",
            "           1       0.67      0.67      0.67      3846\n",
            "\n",
            "    accuracy                           0.84     16281\n",
            "   macro avg       0.78      0.78      0.78     16281\n",
            "weighted avg       0.84      0.84      0.84     16281\n",
            "\n",
            "Accuracy: 0.9999385768250361\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00     24720\n",
            "           1       1.00      1.00      1.00      7841\n",
            "\n",
            "    accuracy                           1.00     32561\n",
            "   macro avg       1.00      1.00      1.00     32561\n",
            "weighted avg       1.00      1.00      1.00     32561\n",
            "\n"
          ]
        }
      ],
      "source": [
        "'''\n",
        "One Hot Encoding Implementation # default, version 3\n",
        "Using Label Encoding, Smote\n",
        "'''\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "# Function to preprocess data using label encoding\n",
        "def preprocess_data(data, encoders=None, is_train=True):\n",
        "    print(\"Initial columns:\", data.columns)  # Initial check of all columns in the dataset\n",
        "\n",
        "    income_column = 'income'\n",
        "    if income_column not in data.columns:\n",
        "        raise ValueError(f\"The column '{income_column}' does not exist in the dataset.\")\n",
        "\n",
        "    # If it's test data, handle the period at the end\n",
        "    if not is_train:\n",
        "        data[income_column] = data[income_column].str.strip().str.replace('.', '')\n",
        "        print(\"Adjusted 'income' for test data:\", data[income_column].unique())  # Debug\n",
        "\n",
        "    # Identify categorical features excluding 'income'\n",
        "    categorical_features = data.select_dtypes(include=['object']).columns.tolist()\n",
        "    if income_column in categorical_features:\n",
        "        categorical_features.remove(income_column)\n",
        "\n",
        "    # Initialize or apply existing label encoders\n",
        "    if encoders is None:\n",
        "        encoders = {}\n",
        "        for feature in categorical_features:\n",
        "            le = LabelEncoder()\n",
        "            data[feature] = le.fit_transform(data[feature])\n",
        "            encoders[feature] = le\n",
        "    else:\n",
        "        for feature, le in encoders.items():\n",
        "            data[feature] = le.transform(data[feature])\n",
        "\n",
        "    print(\"Encoded features:\", categorical_features)  # Debug statement\n",
        "\n",
        "    # Encode the target variable\n",
        "    y = LabelEncoder().fit_transform(data[income_column])\n",
        "    print(\"Encoded 'income':\", np.unique(y))  # Debug the output of the encoded income\n",
        "\n",
        "    # All features are now numeric, so return the numeric dataframe directly\n",
        "    X = data.drop(columns=[income_column]).values\n",
        "\n",
        "    return X, y, encoders\n",
        "\n",
        "# Function to train the Random Forest model with SMOTE\n",
        "def train_random_forest_with_smote(X, y):\n",
        "    # Apply SMOTE\n",
        "    smote = SMOTE(random_state=42)\n",
        "    X_smote, y_smote = smote.fit_resample(X, y)\n",
        "\n",
        "    # Train the Random Forest\n",
        "    model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "    model.fit(X_smote, y_smote)\n",
        "\n",
        "    return model\n",
        "\n",
        "# Evaluate the model\n",
        "def evaluate_model(model, X_test, y_test):\n",
        "    y_pred = model.predict(X_test)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    report = classification_report(y_test, y_pred)\n",
        "\n",
        "    return accuracy, report\n",
        "\n",
        "# Main execution function\n",
        "def main():\n",
        "    # Preprocess training data with Label Encoding\n",
        "    X_train, y_train, encoders = preprocess_data(train_data, is_train=True)\n",
        "\n",
        "    # Train model with SMOTE\n",
        "    smote = SMOTE(random_state=42)\n",
        "    X_smote, y_smote = smote.fit_resample(X_train, y_train)\n",
        "    model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "    model.fit(X_smote, y_smote)\n",
        "\n",
        "    # Preprocess testing data using the same encoders\n",
        "    X_test, y_test, _ = preprocess_data(test_data, encoders, is_train=False)\n",
        "\n",
        "    # Evaluate the model\n",
        "    accuracy, report = evaluate_model(model, X_test, y_test)\n",
        "    print(f'Accuracy: {accuracy}')\n",
        "    print(f'Classification Report:\\n{report}')\n",
        "\n",
        "    # Evaluate the model\n",
        "    accuracy1, report1 = evaluate_model(model, X_train, y_train)\n",
        "    print(f'Accuracy: {accuracy1}')\n",
        "    print(f'Classification Report:\\n{report1}')\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Initial columns: Index(['age', 'work-class', 'fnlwgt', 'education', 'education_num',\n",
        "       'marital-status', 'occupation', 'relationship', 'race', 'sex',\n",
        "       'capital-gain', 'capital-loss', 'hours-worked-per-week',\n",
        "       'native-country', 'income'],\n",
        "      dtype='object')\n",
        "Encoded features: []\n",
        "Encoded 'income': [0 1]\n",
        "Initial columns: Index(['age', 'work-class', 'fnlwgt', 'education', 'education_num',\n",
        "       'marital-status', 'occupation', 'relationship', 'race', 'sex',\n",
        "       'capital-gain', 'capital-loss', 'hours-worked-per-week',\n",
        "       'native-country', 'income'],\n",
        "      dtype='object')\n",
        "Adjusted 'income' for test data: ['<=50K' '>50K']\n",
        "Encoded features: []\n",
        "Encoded 'income': [0 1]\n",
        "Accuracy: 0.8431914501566243\n",
        "Classification Report:\n",
        "              precision    recall  f1-score   support\n",
        "\n",
        "           0       0.90      0.90      0.90     12435\n",
        "           1       0.67      0.67      0.67      3846\n",
        "\n",
        "    accuracy                           0.84     16281\n",
        "   macro avg       0.78      0.78      0.78     16281\n",
        "weighted avg       0.84      0.84      0.84     16281\n",
        "\n",
        "Accuracy: 0.9999385768250361\n",
        "Classification Report:\n",
        "              precision    recall  f1-score   support\n",
        "\n",
        "           0       1.00      1.00      1.00     24720\n",
        "           1       1.00      1.00      1.00      7841\n",
        "\n",
        "    accuracy                           1.00     32561\n",
        "   macro avg       1.00      1.00      1.00     32561\n",
        "weighted avg       1.00      1.00      1.00     32561"
      ],
      "metadata": {
        "id": "0bc0Y3fM-5D2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6JR62yza52JX",
        "outputId": "8b60751f-566c-4e5a-b4e9-7b45fef09015"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial columns: Index(['age', 'work-class', 'fnlwgt', 'education', 'education_num',\n",
            "       'marital-status', 'occupation', 'relationship', 'race', 'sex',\n",
            "       'capital-gain', 'capital-loss', 'hours-worked-per-week',\n",
            "       'native-country', 'income'],\n",
            "      dtype='object')\n",
            "Encoded features: []\n",
            "Encoded 'income': [0 1]\n",
            "Initial columns: Index(['age', 'work-class', 'fnlwgt', 'education', 'education_num',\n",
            "       'marital-status', 'occupation', 'relationship', 'race', 'sex',\n",
            "       'capital-gain', 'capital-loss', 'hours-worked-per-week',\n",
            "       'native-country', 'income'],\n",
            "      dtype='object')\n",
            "Adjusted 'income' for test data: ['<=50K' '>50K']\n",
            "Encoded features: []\n",
            "Encoded 'income': [0 1]\n",
            "Accuracy: 0.8534488053559364\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.93      0.91     12435\n",
            "           1       0.73      0.61      0.66      3846\n",
            "\n",
            "    accuracy                           0.85     16281\n",
            "   macro avg       0.81      0.77      0.78     16281\n",
            "weighted avg       0.85      0.85      0.85     16281\n",
            "\n"
          ]
        }
      ],
      "source": [
        "'''\n",
        "# version 4\n",
        "Using Label Encoding, Without Smote\n",
        "'''\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# Function to preprocess data using label encoding\n",
        "def preprocess_data(data, encoders=None, is_train=True):\n",
        "    print(\"Initial columns:\", data.columns)  # Initial check of all columns in the dataset\n",
        "\n",
        "    income_column = 'income'\n",
        "    if income_column not in data.columns:\n",
        "        raise ValueError(f\"The column '{income_column}' does not exist in the dataset.\")\n",
        "\n",
        "    # If it's test data, handle the period at the end\n",
        "    if not is_train:\n",
        "        data[income_column] = data[income_column].str.strip().str.replace('.', '')\n",
        "        print(\"Adjusted 'income' for test data:\", data[income_column].unique())  # Debug\n",
        "\n",
        "    # Identify categorical features excluding 'income'\n",
        "    categorical_features = data.select_dtypes(include=['object']).columns.tolist()\n",
        "    if income_column in categorical_features:\n",
        "        categorical_features.remove(income_column)\n",
        "\n",
        "    # Initialize or apply existing label encoders\n",
        "    if encoders is None:\n",
        "        encoders = {}\n",
        "        for feature in categorical_features:\n",
        "            le = LabelEncoder()\n",
        "            data[feature] = le.fit_transform(data[feature])\n",
        "            encoders[feature] = le\n",
        "    else:\n",
        "        for feature, le in encoders.items():\n",
        "            data[feature] = le.transform(data[feature])\n",
        "\n",
        "    print(\"Encoded features:\", categorical_features)  # Debug statement\n",
        "\n",
        "    # Encode the target variable\n",
        "    y = LabelEncoder().fit_transform(data[income_column])\n",
        "    print(\"Encoded 'income':\", np.unique(y))  # Debug the output of the encoded income\n",
        "\n",
        "    # All features are now numeric, so return the numeric dataframe directly\n",
        "    X = data.drop(columns=[income_column]).values\n",
        "\n",
        "    return X, y, encoders\n",
        "\n",
        "# Function to train the Random Forest model without SMOTE\n",
        "def train_random_forest(X, y):\n",
        "    # Train the Random Forest without SMOTE\n",
        "    model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "    model.fit(X, y)\n",
        "\n",
        "    return model\n",
        "\n",
        "# Evaluate the model\n",
        "def evaluate_model(model, X_test, y_test):\n",
        "    y_pred = model.predict(X_test)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    report = classification_report(y_test, y_pred)\n",
        "\n",
        "    return accuracy, report\n",
        "\n",
        "# Main execution function\n",
        "def main():\n",
        "    # Preprocess training data with Label Encoding\n",
        "    X_train, y_train, encoders = preprocess_data(train_data, is_train=True)\n",
        "\n",
        "    # Train the Random Forest without SMOTE\n",
        "    model = train_random_forest(X_train, y_train)\n",
        "\n",
        "    # Preprocess testing data using the same encoders\n",
        "    X_test, y_test, _ = preprocess_data(test_data, encoders, is_train=False)\n",
        "\n",
        "    # Evaluate the model\n",
        "    accuracy, report = evaluate_model(model, X_test, y_test)\n",
        "    print(f'Accuracy: {accuracy}')\n",
        "    print(f'Classification Report:\\n{report}')\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Initial columns: Index(['age', 'work-class', 'fnlwgt', 'education', 'education_num',\n",
        "       'marital-status', 'occupation', 'relationship', 'race', 'sex',\n",
        "       'capital-gain', 'capital-loss', 'hours-worked-per-week',\n",
        "       'native-country', 'income'],\n",
        "      dtype='object')\n",
        "Encoded features: []\n",
        "Encoded 'income': [0 1]\n",
        "Initial columns: Index(['age', 'work-class', 'fnlwgt', 'education', 'education_num',\n",
        "       'marital-status', 'occupation', 'relationship', 'race', 'sex',\n",
        "       'capital-gain', 'capital-loss', 'hours-worked-per-week',\n",
        "       'native-country', 'income'],\n",
        "      dtype='object')\n",
        "Adjusted 'income' for test data: ['<=50K' '>50K']\n",
        "Encoded features: []\n",
        "Encoded 'income': [0 1]\n",
        "Accuracy: 0.8534488053559364\n",
        "Classification Report:\n",
        "              precision    recall  f1-score   support\n",
        "\n",
        "           0       0.88      0.93      0.91     12435\n",
        "           1       0.73      0.61      0.66      3846\n",
        "\n",
        "    accuracy                           0.85     16281\n",
        "   macro avg       0.81      0.77      0.78     16281\n",
        "weighted avg       0.85      0.85      0.85     16281\n"
      ],
      "metadata": {
        "id": "ljvmrP0J-9C-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iIqk2ZfsAM2j",
        "outputId": "905189fc-e22e-49b8-9fe6-dcdba753c761"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial columns: Index(['age', 'work-class', 'fnlwgt', 'education', 'education_num',\n",
            "       'marital-status', 'occupation', 'relationship', 'race', 'sex',\n",
            "       'capital-gain', 'capital-loss', 'hours-worked-per-week',\n",
            "       'native-country', 'income'],\n",
            "      dtype='object')\n",
            "Encoded features: ['work-class', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'native-country']\n",
            "Encoded 'income': [0 1]\n",
            "Best Parameters: {'max_depth': 20, 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 100}\n",
            "Initial columns: Index(['age', 'work-class', 'fnlwgt', 'education', 'education_num',\n",
            "       'marital-status', 'occupation', 'relationship', 'race', 'sex',\n",
            "       'capital-gain', 'capital-loss', 'hours-worked-per-week',\n",
            "       'native-country', 'income'],\n",
            "      dtype='object')\n",
            "Adjusted 'income' for test data: ['<=50K' '>50K']\n",
            "Encoded features: ['work-class', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'native-country']\n",
            "Encoded 'income': [0 1]\n",
            "Accuracy: 0.864443216018672\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      0.94      0.91     12435\n",
            "           1       0.77      0.61      0.68      3846\n",
            "\n",
            "    accuracy                           0.86     16281\n",
            "   macro avg       0.83      0.78      0.80     16281\n",
            "weighted avg       0.86      0.86      0.86     16281\n",
            "\n"
          ]
        }
      ],
      "source": [
        "'''\n",
        " # version 5\n",
        "Using Label Encoding, Without Smote\n",
        "Using hyperparameter tuning (gridsearchcv)\n",
        "'''\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Function to preprocess data using label encoding\n",
        "def preprocess_data(data, encoders=None, is_train=True):\n",
        "    print(\"Initial columns:\", data.columns)  # Initial check of all columns in the dataset\n",
        "\n",
        "    income_column = 'income'\n",
        "    if income_column not in data.columns:\n",
        "        raise ValueError(f\"The column '{income_column}' does not exist in the dataset.\")\n",
        "\n",
        "    # If it's test data, handle the period at the end\n",
        "    if not is_train:\n",
        "        data[income_column] = data[income_column].str.strip().str.replace('.', '')\n",
        "        print(\"Adjusted 'income' for test data:\", data[income_column].unique())  # Debug\n",
        "\n",
        "    # Identify categorical features excluding 'income'\n",
        "    categorical_features = data.select_dtypes(include=['object']).columns.tolist()\n",
        "    if income_column in categorical_features:\n",
        "        categorical_features.remove(income_column)\n",
        "\n",
        "    # Initialize or apply existing label encoders\n",
        "    if encoders is None:\n",
        "        encoders = {}\n",
        "        for feature in categorical_features:\n",
        "            le = LabelEncoder()\n",
        "            data[feature] = le.fit_transform(data[feature])\n",
        "            encoders[feature] = le\n",
        "    else:\n",
        "        for feature, le in encoders.items():\n",
        "            data[feature] = le.transform(data[feature])\n",
        "\n",
        "    print(\"Encoded features:\", categorical_features)  # Debug statement\n",
        "\n",
        "    # Encode the target variable\n",
        "    y = LabelEncoder().fit_transform(data[income_column])\n",
        "    print(\"Encoded 'income':\", np.unique(y))  # Debug the output of the encoded income\n",
        "\n",
        "    # All features are now numeric, so return the numeric dataframe directly\n",
        "    X = data.drop(columns=[income_column]).values\n",
        "\n",
        "    return X, y, encoders\n",
        "\n",
        "# Function to perform hyperparameter tuning with RandomForestClassifier\n",
        "def train_random_forest_with_tuning(X, y):\n",
        "    # Define parameter grid for hyperparameter tuning\n",
        "    param_grid = {\n",
        "        'n_estimators': [50, 100, 200],\n",
        "        'max_depth': [5, 10, 20, None],\n",
        "        'min_samples_split': [2, 5, 10],\n",
        "        'min_samples_leaf': [1, 2, 4]\n",
        "    }\n",
        "\n",
        "    # Initialize RandomForestClassifier\n",
        "    rf = RandomForestClassifier(random_state=42)\n",
        "\n",
        "    # Use GridSearchCV for hyperparameter tuning\n",
        "    grid_search = GridSearchCV(estimator=rf, param_grid=param_grid, cv=5, n_jobs=-1, scoring='accuracy')\n",
        "    grid_search.fit(X, y)\n",
        "\n",
        "    # Return the best model\n",
        "    print(f\"Best Parameters: {grid_search.best_params_}\")\n",
        "    return grid_search.best_estimator_\n",
        "\n",
        "# Evaluate the model\n",
        "def evaluate_model(model, X_test, y_test):\n",
        "    y_pred = model.predict(X_test)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    report = classification_report(y_test, y_pred)\n",
        "\n",
        "    return accuracy, report\n",
        "\n",
        "# Main execution function\n",
        "def main():\n",
        "    # Preprocess training data with Label Encoding\n",
        "    X_train, y_train, encoders = preprocess_data(train_data, is_train=True)\n",
        "\n",
        "    # Train the Random Forest with hyperparameter tuning\n",
        "    model = train_random_forest_with_tuning(X_train, y_train)\n",
        "\n",
        "    # Preprocess testing data using the same encoders\n",
        "    X_test, y_test, _ = preprocess_data(test_data, encoders, is_train=False)\n",
        "\n",
        "    # Evaluate the model\n",
        "    accuracy, report = evaluate_model(model, X_test, y_test)\n",
        "    print(f'Accuracy: {accuracy}')\n",
        "    print(f'Classification Report:\\n{report}')\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Version 7: Smote, OHE, using parameters\n",
        "'''\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "\n",
        "# Assuming train_data and test_data are already loaded as dataframes\n",
        "# train_data, test_data\n",
        "\n",
        "# Function to preprocess data\n",
        "def preprocess_data(data, transformer=None, is_train=True):\n",
        "    print(\"Initial columns:\", data.columns)  # Initial check of all columns in the dataset\n",
        "\n",
        "    income_column = 'income'\n",
        "    if income_column not in data.columns:\n",
        "        raise ValueError(f\"The column '{income_column}' does not exist in the dataset.\")\n",
        "\n",
        "    # If it's test data, handle the period at the end\n",
        "    if not is_train:\n",
        "        data[income_column] = data[income_column].str.strip().str.replace('.', '')\n",
        "        print(\"Adjusted 'income' for test data:\", data[income_column].unique())  # Debug\n",
        "\n",
        "    # Identify and store categorical features excluding 'income'\n",
        "    categorical_features = data.select_dtypes(include=['object']).columns.tolist()\n",
        "    if income_column in categorical_features:\n",
        "        categorical_features.remove(income_column)\n",
        "    print(\"Categorical features before encoding:\", categorical_features)  # Debug statement\n",
        "\n",
        "    # Apply ColumnTransformer only to categorical features excluding 'income'\n",
        "    if transformer is None:\n",
        "        transformer = ColumnTransformer(\n",
        "            transformers=[('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)],\n",
        "            remainder='passthrough')\n",
        "        X = transformer.fit_transform(data.drop(columns=[income_column]))\n",
        "    else:\n",
        "        X = transformer.transform(data.drop(columns=[income_column]))\n",
        "\n",
        "    # Now encode the 'income' column after categorical handling\n",
        "    y = LabelEncoder().fit_transform(data[income_column])\n",
        "    print(\"Encoded 'income':\", np.unique(y))  # Debug the output of the encoded income\n",
        "\n",
        "    return X, y, transformer\n",
        "\n",
        "\n",
        "# Function to train the Random Forest model with specified hyperparameters\n",
        "def train_random_forest(X, y):\n",
        "    # Initialize the RandomForestClassifier with the desired hyperparameters\n",
        "    model = RandomForestClassifier(\n",
        "        n_estimators=100,\n",
        "        max_depth=10,\n",
        "        min_samples_leaf=1,\n",
        "        min_samples_split=2,\n",
        "        random_state=42\n",
        "    )\n",
        "    model.fit(X, y)\n",
        "\n",
        "    return model\n",
        "\n",
        "# Evaluate the model\n",
        "def evaluate_model(model, X_test, y_test):\n",
        "    y_pred = model.predict(X_test)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    report = classification_report(y_test, y_pred)\n",
        "\n",
        "    return accuracy, report\n",
        "\n",
        "# Main execution function\n",
        "def main():\n",
        "    # Preprocess training data\n",
        "    X_train, y_train, transformer = preprocess_data(train_data, is_train=True)\n",
        "\n",
        "    # Train model using specified hyperparameters\n",
        "    model = train_random_forest(X_train, y_train)\n",
        "\n",
        "    # Preprocess testing data using the same transformer\n",
        "    X_test, y_test, _ = preprocess_data(test_data, transformer, is_train=False)\n",
        "\n",
        "    # Evaluate the model on the test data\n",
        "    accuracy, report = evaluate_model(model, X_test, y_test)\n",
        "    print(f'Accuracy (Test Data): {accuracy}')\n",
        "    print(f'Classification Report (Test Data):\\n{report}')\n",
        "\n",
        "    # Evaluate the model on the training data\n",
        "    accuracy_train, report_train = evaluate_model(model, X_train, y_train)\n",
        "    print(f'Accuracy (Training Data): {accuracy_train}')\n",
        "    print(f'Classification Report (Training Data):\\n{report_train}')\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    # Load your datasets (replace with actual file paths)\n",
        "    # train_data = pd.read_csv('./census-income.data (3).csv')\n",
        "    # test_data = pd.read_csv('./census-income.test (2).csv')\n",
        "\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z9rRIQM5oOMF",
        "outputId": "8eb28ed9-69da-430c-8be0-72701952fc05"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial columns: Index(['age', 'work-class', 'fnlwgt', 'education', 'education_num',\n",
            "       'marital-status', 'occupation', 'relationship', 'race', 'sex',\n",
            "       'capital-gain', 'capital-loss', 'hours-worked-per-week',\n",
            "       'native-country', 'income'],\n",
            "      dtype='object')\n",
            "Categorical features before encoding: ['work-class', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'native-country']\n",
            "Encoded 'income': [0 1]\n",
            "Initial columns: Index(['age', 'work-class', 'fnlwgt', 'education', 'education_num',\n",
            "       'marital-status', 'occupation', 'relationship', 'race', 'sex',\n",
            "       'capital-gain', 'capital-loss', 'hours-worked-per-week',\n",
            "       'native-country', 'income'],\n",
            "      dtype='object')\n",
            "Adjusted 'income' for test data: ['<=50K' '>50K']\n",
            "Categorical features before encoding: ['work-class', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'native-country']\n",
            "Encoded 'income': [0 1]\n",
            "Accuracy (Test Data): 0.8579325594250967\n",
            "Classification Report (Test Data):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.96      0.91     12435\n",
            "           1       0.79      0.54      0.64      3846\n",
            "\n",
            "    accuracy                           0.86     16281\n",
            "   macro avg       0.83      0.75      0.78     16281\n",
            "weighted avg       0.85      0.86      0.85     16281\n",
            "\n",
            "Accuracy (Training Data): 0.8641012253923406\n",
            "Classification Report (Training Data):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.96      0.91     24720\n",
            "           1       0.82      0.56      0.66      7841\n",
            "\n",
            "    accuracy                           0.86     32561\n",
            "   macro avg       0.85      0.76      0.79     32561\n",
            "weighted avg       0.86      0.86      0.85     32561\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Initial columns: Index(['age', 'work-class', 'fnlwgt', 'education', 'education_num',\n",
        "       'marital-status', 'occupation', 'relationship', 'race', 'sex',\n",
        "       'capital-gain', 'capital-loss', 'hours-worked-per-week',\n",
        "       'native-country', 'income'],\n",
        "      dtype='object')\n",
        "Encoded features: ['work-class', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'native-country']\n",
        "Encoded 'income': [0 1]\n",
        "Best Parameters: {'max_depth': 20, 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 100}\n",
        "Initial columns: Index(['age', 'work-class', 'fnlwgt', 'education', 'education_num',\n",
        "       'marital-status', 'occupation', 'relationship', 'race', 'sex',\n",
        "       'capital-gain', 'capital-loss', 'hours-worked-per-week',\n",
        "       'native-country', 'income'],\n",
        "      dtype='object')\n",
        "Adjusted 'income' for test data: ['<=50K' '>50K']\n",
        "Encoded features: ['work-class', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'native-country']\n",
        "Encoded 'income': [0 1]\n",
        "Accuracy: 0.864443216018672\n",
        "Classification Report:\n",
        "              precision    recall  f1-score   support\n",
        "\n",
        "           0       0.89      0.94      0.91     12435\n",
        "           1       0.77      0.61      0.68      3846\n",
        "\n",
        "    accuracy                           0.86     16281\n",
        "   macro avg       0.83      0.78      0.80     16281\n",
        "weighted avg       0.86      0.86      0.86     16281\n",
        "\n"
      ],
      "metadata": {
        "id": "wjrqe2lN_BEG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Ur7xY-Iynum",
        "outputId": "a1351aab-cec5-4f00-dac2-3c4d1b2beb8b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Predictions in training \n",
            "\n",
            "[' <=50K' ' <=50K' ' <=50K' ... ' <=50K' ' <=50K' ' >50K']\n",
            "Predictions in TESTING \n",
            "\n",
            "[' <=50K.' ' <=50K.' ' >50K.' ... ' <=50K.' ' <=50K.' ' >50K.']\n"
          ]
        }
      ],
      "source": [
        "'''\n",
        "Random Forest implementation\n",
        "'''\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "\n",
        "# Step 1 - declaring x and y values for random forests\n",
        "\n",
        "x_train_rf = train_data.drop('income', axis=1)  # Features\n",
        "y_train_rf = train_data['income']               # Target variable\n",
        "\n",
        "x_test_rf = test_data.drop('income', axis=1)  # Features\n",
        "y_test_rf = test_data['income']               # Target variable\n",
        "\n",
        "# Step 2:\n",
        "# Perform one-hot encoding if there are categorical variables\n",
        "# Example:\n",
        "\n",
        "'''\n",
        "OHE = One Hot Encoding. It's required to run the Random Forest Classifier from SKLEARN\n",
        "'''\n",
        "\n",
        "x_train_rf_ohe = pd.get_dummies(x_train_rf)\n",
        "x_test_rf_ohe = pd.get_dummies(x_test_rf)\n",
        "\n",
        "# Step 3: Instantiate the Random Forest Classifier\n",
        "# You can specify hyperparameters such as n_estimators, max_depth, etc.\n",
        "# Example:\n",
        "# rf_classifier = RandomForestClassifier(n_estimators=100, max_depth=10, random_state=42)\n",
        "rf_classifier_train = RandomForestClassifier(random_state=42)\n",
        "rf_classifier_test = RandomForestClassifier(random_state=42)\n",
        "\n",
        "# Step 4: Train the models\n",
        "rf_classifier_train.fit(x_train_rf_ohe, y_train_rf)\n",
        "rf_classifier_test.fit(x_test_rf_ohe, y_test_rf)\n",
        "\n",
        "# Step 5: Making predictions - Assuming 'new_data' is the new DataFrame\n",
        "# we want to check containing features (excluding the income column)\n",
        "\n",
        "# x_train_rf = train_data.drop('income', axis=1)  # Features\n",
        "# y_train_rf = train_data['income']               # Target variable\n",
        "predictions_train_rf = rf_classifier_train.predict(x_train_rf_ohe)\n",
        "\n",
        "predictions_test_rf = rf_classifier_test.predict(x_test_rf_ohe)\n",
        "\n",
        "print(\"Predictions in training \\n\")\n",
        "print(predictions_train_rf)\n",
        "\n",
        "print(\"Predictions in TESTING \\n\")\n",
        "print(predictions_test_rf)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kJoAT7bgoMcK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mYQimk567Eh-",
        "outputId": "dc8d6ab8-0770-4aab-bbeb-d79aa0447f92"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Confusion Matrix:\n",
            "[[12435     0]\n",
            " [    1  3845]]\n",
            "Accuracy: 0.9999385787113814\n"
          ]
        }
      ],
      "source": [
        "'''\n",
        "Confusion matrix for Random Forests\n",
        "'''\n",
        "\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "\n",
        "# Calculate confusion matrix\n",
        "conf_matrix_rf = confusion_matrix(y_test_rf, predictions_test_rf)\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy_rf = accuracy_score(y_test_rf, predictions_test_rf)\n",
        "\n",
        "print(\"Confusion Matrix:\")\n",
        "print(conf_matrix_rf)\n",
        "print(\"Accuracy:\", accuracy_rf)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HB8i-cac7Exh"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "Code block to replace missing values with mode\n",
        "'''\n",
        "\n",
        "# This function takes a dataframe and returns * A MODIFIED COPY *. Doesn't change the original\n",
        "def replace_question_marks(df, columns_to_replace):\n",
        "    most_common_elements = {}\n",
        "    most_common_counts = {}\n",
        "    df_copy = df.copy()  # Create a copy of the original DataFrame\n",
        "\n",
        "    for col in columns_to_replace:\n",
        "        # Find the most common element and its count in the column\n",
        "        value_counts = df[col].value_counts()\n",
        "        most_common = value_counts.idxmax()\n",
        "        most_common_count = value_counts.max()\n",
        "\n",
        "        most_common_elements[col] = most_common\n",
        "        most_common_counts[col] = most_common_count\n",
        "\n",
        "        # Replace ' ?' with the most common element in the column\n",
        "        df_copy[col] = df_copy[col].replace(' ?', most_common)\n",
        "\n",
        "    return df_copy, most_common_elements, most_common_counts\n",
        "\n",
        "columns_to_replace = ['work-class', 'occupation', 'native-country']\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U0uaprJC7DcR"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AQrJenVdKWTE",
        "outputId": "d1fcf5ef-26c3-4c6a-a6a7-0df31687d865"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Predictions in training \n",
            "\n",
            "[' <=50K' ' <=50K' ' <=50K' ... ' <=50K' ' <=50K' ' >50K']\n",
            "Predictions in TESTING \n",
            "\n",
            "[' <=50K.' ' <=50K.' ' >50K.' ... ' <=50K.' ' <=50K.' ' >50K.']\n"
          ]
        }
      ],
      "source": [
        "'''\n",
        "Testing without missing values\n",
        "'''\n",
        "data_train_modified_rf, most_common_elements_data_train_rf, most_common_counts_data_train_rf = replace_question_marks(train_data, columns_to_replace)\n",
        "data_test_modified_rf, most_common_elements_data_test_rf, most_common_counts_data_test_rf = replace_question_marks(test_data, columns_to_replace)\n",
        "\n",
        "# Step 1 - declaring x and y values for random forests\n",
        "\n",
        "x_train_rf_modified = data_train_modified_rf.drop('income', axis=1)  # Features\n",
        "y_train_rf_modified = data_train_modified_rf['income']               # Target variable\n",
        "\n",
        "x_test_rf_modified = data_test_modified_rf.drop('income', axis=1)  # Features\n",
        "y_test_rf_modified = data_test_modified_rf['income']               # Target variable\n",
        "\n",
        "# Step 2:\n",
        "# Perform one-hot encoding if there are categorical variables\n",
        "# Example:\n",
        "\n",
        "'''\n",
        "OHE = One Hot Encoding. It's required to run the Random Forest Classifier from SKLEARN\n",
        "'''\n",
        "\n",
        "x_train_rf_ohe_modified = pd.get_dummies(x_train_rf_modified)\n",
        "x_test_rf_ohe_modified = pd.get_dummies(x_test_rf_modified)\n",
        "\n",
        "# Step 3: Instantiate the Random Forest Classifier\n",
        "# You can specify hyperparameters such as n_estimators, max_depth, etc.\n",
        "# Example:\n",
        "# rf_classifier = RandomForestClassifier(n_estimators=100, max_depth=10, random_state=42)\n",
        "rf_classifier_train1 = RandomForestClassifier(random_state=42)\n",
        "rf_classifier_test1 = RandomForestClassifier(random_state=42)\n",
        "\n",
        "# Step 4: Train the models\n",
        "rf_classifier_train1.fit(x_train_rf_ohe_modified, y_train_rf_modified)\n",
        "rf_classifier_test1.fit(x_test_rf_ohe_modified, y_test_rf_modified)\n",
        "\n",
        "# Step 5: Making predictions - Assuming 'new_data' is the new DataFrame\n",
        "# we want to check containing features (excluding the income column)\n",
        "\n",
        "# x_train_rf = train_data.drop('income', axis=1)  # Features\n",
        "# y_train_rf = train_data['income']               # Target variable\n",
        "predictions_train_rf1 = rf_classifier_train1.predict(x_train_rf_ohe_modified)\n",
        "\n",
        "predictions_test_rf1 = rf_classifier_test1.predict(x_test_rf_ohe_modified)\n",
        "\n",
        "print(\"Predictions in training \\n\")\n",
        "print(predictions_train_rf1)\n",
        "\n",
        "print(\"Predictions in TESTING \\n\")\n",
        "print(predictions_test_rf1)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jinjVxnMMYJ4",
        "outputId": "9488ba99-c3e0-479d-debb-4aeb3347b1f2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Confusion Matrix new:\n",
            "[[12435     0]\n",
            " [    1  3845]]\n",
            "Accuracy new: 0.9999385787113814\n"
          ]
        }
      ],
      "source": [
        "'''\n",
        "Confusion matrix for Random Forests # Without missing\n",
        "'''\n",
        "\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "\n",
        "# Calculate confusion matrix\n",
        "conf_matrix_rf1 = confusion_matrix(y_test_rf_modified, predictions_test_rf1)\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy_rf1 = accuracy_score(y_test_rf_modified, predictions_test_rf1)\n",
        "\n",
        "print(\"Confusion Matrix new:\")\n",
        "print(conf_matrix_rf1)\n",
        "print(\"Accuracy new:\", accuracy_rf1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U7SzXt03ZUBk"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO8btNxBVIepZ62649flDFq",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}