{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/albertbaezd/data-mining-final-project/blob/main/(merging)_Data_Mining_project_code_Albert_Random.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c-24Su6VnRt3"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from google.colab import drive\n",
        "from sklearn.utils import resample\n",
        "import matplotlib.pyplot as plt\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Importing dependencies\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Code to replace missing values using KNN and predicting the values\n",
        "\n",
        "train_data = pd.read_csv(\"./census-income.data.csv\")\n",
        "test_data = pd.read_csv(\"./census-income.test.csv\")\n",
        "\n",
        "# Initialize LabelEncoder\n",
        "label_encoder = LabelEncoder()\n",
        "\n",
        "# Encode 'marital-status' column\n",
        "train_data['marital-status'] = label_encoder.fit_transform(train_data['marital-status'])\n",
        "train_data['relationship'] = label_encoder.fit_transform(train_data['relationship'])\n",
        "train_data['race'] = label_encoder.fit_transform(train_data['race'])\n",
        "train_data['sex'] = label_encoder.fit_transform(train_data['sex'])\n",
        "## convert 'income' data to numerical values\n",
        "train_data['income'] = label_encoder.fit_transform(train_data['income'])\n"
      ],
      "metadata": {
        "id": "xpJRQ6sVx4hv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## replace 'native-country' with mode\n",
        "train_data['native-country'] = train_data['native-country'].replace('?', 'United-States')\n",
        "label_encoder = LabelEncoder()\n",
        "train_data['native-country'] = label_encoder.fit_transform(train_data['native-country'])\n",
        "\n",
        "## replace 'work-class' with mode\n",
        "train_data['work-class'] = train_data['work-class'].replace('?', 'Private')\n",
        "train_data['work-class'] = label_encoder.fit_transform(train_data['work-class'])\n",
        "\n",
        "x_train = train_data.drop(['education','income'], axis=1)\n",
        "y_train = train_data[\"income\"]\n"
      ],
      "metadata": {
        "id": "eqgFy3N95iIR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.impute import KNNImputer\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "# Replace '?' with NaN in the 'occupation' column\n",
        "x_train['occupation'].replace('?', np.nan, inplace=True)\n",
        "\n",
        "# Separate features (X) and target variable (y)\n",
        "X_train = x_train.drop('occupation', axis=1)\n",
        "y_occupation_train = x_train['occupation']\n",
        "\n",
        "# Apply KNN Imputer\n",
        "knn_imputer = KNNImputer()\n",
        "X_imputed_train = knn_imputer.fit_transform(X_train)\n",
        "\n",
        "# Convert imputed data back to DataFrame\n",
        "X_imputed_df_train = pd.DataFrame(X_imputed_train, columns=X_train.columns)\n",
        "\n",
        "print(X_imputed_df_train)\n",
        "\n",
        "# Combine imputed data with original data\n",
        "imputed_x_train = X_imputed_df_train.copy()\n",
        "imputed_x_train['occupation'] = y_occupation_train\n",
        "imputed_x_train['occupation'] = label_encoder.fit_transform(imputed_x_train['occupation'])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XgBT6hLM4_Q0",
        "outputId": "326bad97-51fe-4aac-e627-a63840cffd47"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "        age  work-class    fnlwgt  education_num  marital-status  \\\n",
            "0      39.0         7.0   77516.0           13.0             4.0   \n",
            "1      50.0         6.0   83311.0           13.0             2.0   \n",
            "2      38.0         4.0  215646.0            9.0             0.0   \n",
            "3      53.0         4.0  234721.0            7.0             2.0   \n",
            "4      28.0         4.0  338409.0           13.0             2.0   \n",
            "...     ...         ...       ...            ...             ...   \n",
            "32556  27.0         4.0  257302.0           12.0             2.0   \n",
            "32557  40.0         4.0  154374.0            9.0             2.0   \n",
            "32558  58.0         4.0  151910.0            9.0             6.0   \n",
            "32559  22.0         4.0  201490.0            9.0             4.0   \n",
            "32560  52.0         5.0  287927.0            9.0             2.0   \n",
            "\n",
            "       relationship  race  sex  capital-gain  capital-loss  \\\n",
            "0               1.0   4.0  1.0        2174.0           0.0   \n",
            "1               0.0   4.0  1.0           0.0           0.0   \n",
            "2               1.0   4.0  1.0           0.0           0.0   \n",
            "3               0.0   2.0  1.0           0.0           0.0   \n",
            "4               5.0   2.0  0.0           0.0           0.0   \n",
            "...             ...   ...  ...           ...           ...   \n",
            "32556           5.0   4.0  0.0           0.0           0.0   \n",
            "32557           0.0   4.0  1.0           0.0           0.0   \n",
            "32558           4.0   4.0  0.0           0.0           0.0   \n",
            "32559           3.0   4.0  1.0           0.0           0.0   \n",
            "32560           5.0   4.0  0.0       15024.0           0.0   \n",
            "\n",
            "       hours-worked-per-week  native-country  \n",
            "0                       40.0            39.0  \n",
            "1                       13.0            39.0  \n",
            "2                       40.0            39.0  \n",
            "3                       40.0            39.0  \n",
            "4                       40.0             5.0  \n",
            "...                      ...             ...  \n",
            "32556                   38.0            39.0  \n",
            "32557                   40.0            39.0  \n",
            "32558                   40.0            39.0  \n",
            "32559                   20.0            39.0  \n",
            "32560                   40.0            39.0  \n",
            "\n",
            "[32561 rows x 12 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QmTZkEWhn0w0",
        "outputId": "07bf8aba-d168-4b49-8b22-0fa391385576"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       Unnamed: 0   age  work-class    fnlwgt  education_num  marital-status  \\\n",
            "0               0  39.0         6.0   77516.0           13.0             4.0   \n",
            "1               1  50.0         5.0   83311.0           13.0             2.0   \n",
            "2               2  38.0         3.0  215646.0            9.0             0.0   \n",
            "3               3  53.0         3.0  234721.0            7.0             2.0   \n",
            "4               4  28.0         3.0  338409.0           13.0             2.0   \n",
            "...           ...   ...         ...       ...            ...             ...   \n",
            "32556       32556  27.0         3.0  257302.0           12.0             2.0   \n",
            "32557       32557  40.0         3.0  154374.0            9.0             2.0   \n",
            "32558       32558  58.0         3.0  151910.0            9.0             6.0   \n",
            "32559       32559  22.0         3.0  201490.0            9.0             4.0   \n",
            "32560       32560  52.0         4.0  287927.0            9.0             2.0   \n",
            "\n",
            "       relationship  race  sex  capital-gain  capital-loss  \\\n",
            "0               1.0   4.0  1.0        2174.0           0.0   \n",
            "1               0.0   4.0  1.0           0.0           0.0   \n",
            "2               1.0   4.0  1.0           0.0           0.0   \n",
            "3               0.0   2.0  1.0           0.0           0.0   \n",
            "4               5.0   2.0  0.0           0.0           0.0   \n",
            "...             ...   ...  ...           ...           ...   \n",
            "32556           5.0   4.0  0.0           0.0           0.0   \n",
            "32557           0.0   4.0  1.0           0.0           0.0   \n",
            "32558           4.0   4.0  0.0           0.0           0.0   \n",
            "32559           3.0   4.0  1.0           0.0           0.0   \n",
            "32560           5.0   4.0  0.0       15024.0           0.0   \n",
            "\n",
            "       hours-worked-per-week  native-country  occupation  income  \n",
            "0                       40.0            38.0           0       0  \n",
            "1                       13.0            38.0           3       0  \n",
            "2                       40.0            38.0           5       0  \n",
            "3                       40.0            38.0           5       0  \n",
            "4                       40.0             4.0           9       0  \n",
            "...                      ...             ...         ...     ...  \n",
            "32556                   38.0            38.0          12       0  \n",
            "32557                   40.0            38.0           6       1  \n",
            "32558                   40.0            38.0           0       0  \n",
            "32559                   20.0            38.0           0       0  \n",
            "32560                   40.0            38.0           3       1  \n",
            "\n",
            "[32561 rows x 15 columns]\n",
            "       Unnamed: 0   age  work-class    fnlwgt  education_num  marital-status  \\\n",
            "0               0  25.0         3.0  226802.0            7.0             4.0   \n",
            "1               1  38.0         3.0   89814.0            9.0             2.0   \n",
            "2               2  28.0         1.0  336951.0           12.0             2.0   \n",
            "3               3  44.0         3.0  160323.0           10.0             2.0   \n",
            "4               4  18.0         3.0  103497.0           10.0             4.0   \n",
            "...           ...   ...         ...       ...            ...             ...   \n",
            "16276       16276  39.0         3.0  215419.0           13.0             0.0   \n",
            "16277       16277  64.0         3.0  321403.0            9.0             6.0   \n",
            "16278       16278  38.0         3.0  374983.0           13.0             2.0   \n",
            "16279       16279  44.0         3.0   83891.0           13.0             0.0   \n",
            "16280       16280  35.0         4.0  182148.0           13.0             2.0   \n",
            "\n",
            "       relationship  race  sex  capital-gain  capital-loss  \\\n",
            "0               3.0   2.0  1.0           0.0           0.0   \n",
            "1               0.0   4.0  1.0           0.0           0.0   \n",
            "2               0.0   4.0  1.0           0.0           0.0   \n",
            "3               0.0   2.0  1.0        7688.0           0.0   \n",
            "4               3.0   4.0  0.0           0.0           0.0   \n",
            "...             ...   ...  ...           ...           ...   \n",
            "16276           1.0   4.0  0.0           0.0           0.0   \n",
            "16277           2.0   2.0  1.0           0.0           0.0   \n",
            "16278           0.0   4.0  1.0           0.0           0.0   \n",
            "16279           3.0   1.0  1.0        5455.0           0.0   \n",
            "16280           0.0   4.0  1.0           0.0           0.0   \n",
            "\n",
            "       hours-worked-per-week  native-country  occupation  income  \n",
            "0                       40.0            37.0           6       0  \n",
            "1                       50.0            37.0           4       0  \n",
            "2                       40.0            37.0          10       1  \n",
            "3                       40.0            37.0           6       1  \n",
            "4                       30.0            37.0          14       0  \n",
            "...                      ...             ...         ...     ...  \n",
            "16276                   36.0            37.0           9       0  \n",
            "16277                   40.0            37.0          14       0  \n",
            "16278                   50.0            37.0           9       0  \n",
            "16279                   40.0            37.0           0       0  \n",
            "16280                   60.0            37.0           3       1  \n",
            "\n",
            "[16281 rows x 15 columns]\n"
          ]
        }
      ],
      "source": [
        "'''\n",
        "In case, you want to run the code from Google Drive, follow these steps.\n",
        "Otherwise, ignore the Google Drive commands.\n",
        "\n",
        "Here, we authenticate with Google Drive to add the datafiles from a Drive folder\n",
        "\n",
        "Instructions:\n",
        "\n",
        "1. Create a folder in your Google Drive, called data-mining-csv-files\n",
        "2. Insert both csv files (test and train) with the original names there.\n",
        "3. Just run this cell to import the code\n",
        "'''\n",
        "\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')\n",
        "\n",
        "# train_data = pd.read_csv(\"/content/drive/My Drive/data-mining-csv-files/census-income.data.csv\") #- Albert: remove comment if you want to manually place the files here. If not, it's going to use a Google Drive folder\n",
        "# test_data = pd.read_csv(\"/content/drive/My Drive/data-mining-csv-files/census-income.test.csv\")  #- Albert: remove comment if you want to manually place the files here. If not, it's going to use a Google Drive folder\n",
        "\n",
        "'''\n",
        "Importing datasets.\n",
        "\n",
        "These are the cleaned datasets without missing values,\n",
        "which were replaced by KNN algorithm. The corresponding code is in\n",
        "the previous blocks.\n",
        "'''\n",
        "\n",
        "train_data = pd.read_csv(\"./train_data_d.csv\")\n",
        "test_data = pd.read_csv(\"./test_data_d.csv\")\n",
        "\n",
        "# Displaying results:\n",
        "print(train_data)\n",
        "print(test_data)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Class Distribution: Plot the distribution of the target variable (income)\n",
        "# to check for class imbalance.\n",
        "\n",
        "# Set up a subplot grid for training and testing distributions\n",
        "fig, axs = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "# Different sky-blue-themed colors\n",
        "train_palette = ['skyblue', 'deepskyblue']\n",
        "test_palette = ['skyblue', 'deepskyblue']\n",
        "\n",
        "# Training data\n",
        "sns.countplot(x='income', data=train_data, ax=axs[0], palette=train_palette)\n",
        "axs[0].set_title('Training Data Income Distribution')\n",
        "axs[0].set_ylabel('Count')\n",
        "axs[0].set_xlabel('Income')\n",
        "\n",
        "# Testing data\n",
        "sns.countplot(x='income', data=test_data, ax=axs[1], palette=test_palette)\n",
        "axs[1].set_title('Testing Data Income Distribution')\n",
        "axs[1].set_ylabel('Count')\n",
        "axs[1].set_xlabel('Income')\n",
        "\n",
        "# Adjust layout\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 437
        },
        "id": "Ef3XL2rIbIZr",
        "outputId": "8ceeff3a-9354-4ecc-9b21-d5958b8f6a21"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-a472cde6df97>:12: FutureWarning: \n",
            "\n",
            "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n",
            "\n",
            "  sns.countplot(x='income', data=train_data, ax=axs[0], palette=train_palette)\n",
            "<ipython-input-25-a472cde6df97>:18: FutureWarning: \n",
            "\n",
            "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n",
            "\n",
            "  sns.countplot(x='income', data=test_data, ax=axs[1], palette=test_palette)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1400x500 with 2 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAABW4AAAHqCAYAAACUWtfDAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAABj5UlEQVR4nO3deVxVdf7H8TeLLC6AqIAkIlmpuIeF5J6MqLRQtmimZibVD3KURs1JEW2x0dxKy3EqsUlLbcxKjSRMrcQNZUxT0sItBZwUrloCwvn90XDGG66sR3s9H4/zmO75fs4533OE62fennuug2EYhgAAAAAAAAAAluFY3RMAAAAAAAAAANgjuAUAAAAAAAAAiyG4BQAAAAAAAACLIbgFAAAAAAAAAIshuAUAAAAAAAAAiyG4BQAAAAAAAACLIbgFAAAAAAAAAIshuAUAAAAAAAAAiyG4BQAAAAAAAACLIbgFUGaPPfaYmjRpUqZtExIS5ODgULETAi6gKn/Wunfvru7du5uv161bJwcHB3344YdVcvzy/E4CAIDLo4dFVaGHBSAR3ALXJQcHhyta1q1bV91TrRaPPfaY3XWoXbu2brzxRj3wwAP617/+peLi4jLve/HixZo1a1bFTfa/unfvrlatWlX4fq81iYmJdn92bm5u8vf3V0REhF577TWdOnWqQo5z9OhRJSQkKD09vUL2V5GsPDcAACpLVfa3v/zyixISEizXK9PDXrvoYa09N8DKnKt7AgAq3j//+U+71++++66Sk5NLrW/RokW5jvOPf/yjzA3i+PHj9dxzz5Xr+OXh6uqqt956S5L066+/6uDBg/r000/1wAMPqHv37vr444/l4eFx1ftdvHixdu3apZEjR1bwjHG+yZMnKygoSIWFhcrKytK6des0cuRIzZgxQ5988onatGlj1pblZ+3o0aOaNGmSmjRponbt2l3xdmvWrLmq45TFpeZWnt9JAACsrKr6W+m34HbSpEmSZHcXokQPi/Khh6WHBa4WwS1wHXr00UftXm/atEnJycml1v/eL7/8opo1a17xcWrUqFGm+UmSs7OznJ2r7y3I2dm51PV48cUX9corr2jcuHEaPny4lixZUk2zw+X06dNHHTp0MF+PGzdOa9eu1V133aV77rlHe/bskbu7u6Sq+Vkr+d1xcXGp1ONcTnl+JwEAsLKy9rcVjR4W5UEPe2H0sMDF8agE4A+q5GNLaWlp6tq1q2rWrKm//vWvkqSPP/5YkZGR8vf3l6urq5o2baoXXnhBRUVFdvv4/bOIDhw4IAcHB7366quaP3++mjZtKldXV912223aunWr3bYXemaTg4ODYmNjtWLFCrVq1Uqurq5q2bKlkpKSSs1/3bp16tChg9zc3NS0aVP9/e9/r5DnQD333HPq1auXli1bpu+//95cfyXXpHv37lq1apUOHjxofgyq5PoUFBQoPj5eISEh8vT0VK1atdSlSxd9+eWXZZ7r1Vyvn376ScOGDTPnHxQUpKeffloFBQVmzY8//qgHH3xQ3t7eqlmzpjp27KhVq1bZ7afkeVdLly7VpEmTdMMNN6hOnTp64IEHlJeXp/z8fI0cOVI+Pj6qXbu2hg4dqvz8/FLzee+99xQSEiJ3d3d5e3urf//+Onz4cJmvhSTdeeedmjBhgg4ePKj33nvPXH+hn4vk5GR17txZXl5eql27tpo1a2b+/K9bt0633XabJGno0KHmn2ViYqKkS//u/P75YCWKior017/+VX5+fqpVq5buueeeUufbpEkTPfbYY6W2PX+fl5vbhZ4PdubMGT377LMKCAiQq6urmjVrpldffVWGYdjVXc3PEwAAVlRcXKxZs2apZcuWcnNzk6+vr5588kmdPHnSrm7btm2KiIhQ/fr15e7urqCgID3++OOSfutnGzRoIEmaNGmS+XdtQkKCJHpYelh6WHpYoGpxxy3wB/bzzz+rT58+6t+/vx599FH5+vpK+u0ZTLVr11ZcXJxq166ttWvXKj4+XjabTdOmTbvsfhcvXqxTp07pySeflIODg6ZOnar7779fP/7442X/NfXrr7/W8uXL9X//93+qU6eOXnvtNfXr10+HDh1SvXr1JEk7duxQ79691bBhQ02aNElFRUWaPHmy2WSX16BBg7RmzRolJyfrlltukXRl1+T5559XXl6ejhw5opkzZ0qSateuLUmy2Wx66623NGDAAA0fPlynTp3S22+/rYiICG3ZsuWqPsp0viu5XkePHtXtt9+u3NxcRUdHq3nz5vrpp5/04Ycf6pdffpGLi4uys7N1xx136JdfftGIESNUr149LVy4UPfcc48+/PBD3XfffXbHnTJlitzd3fXcc89p//79ev3111WjRg05Ojrq5MmTSkhI0KZNm5SYmKigoCDFx8eb27700kuaMGGCHnroIT3xxBM6fvy4Xn/9dXXt2lU7duyQl5dXma6F9Nuf3V//+letWbNGw4cPv2DN7t27ddddd6lNmzaaPHmyXF1dtX//fn3zzTeSfvuI5eTJkxUfH6/o6Gh16dJFknTHHXeY+7jY787FvPTSS3JwcNDYsWOVk5OjWbNmKTw8XOnp6eZdFVfiSuZ2PsMwdM899+jLL7/UsGHD1K5dO33++ecaPXq0fvrpJ/PntMSV/DwBAGBVTz75pBITEzV06FCNGDFCmZmZmjNnjnbs2KFvvvlGNWrUUE5Ojnr16qUGDRroueeek5eXlw4cOKDly5dLkho0aKA333xTTz/9tO677z7df//9kmT3EfYLoYe9OvSw9uhh7dHDAucxAFz3YmJijN//unfr1s2QZMybN69U/S+//FJq3ZNPPmnUrFnTOHv2rLluyJAhRmBgoPk6MzPTkGTUq1fPOHHihLn+448/NiQZn376qblu4sSJpeYkyXBxcTH2799vrvv3v/9tSDJef/11c93dd99t1KxZ0/jpp5/Mdfv27TOcnZ1L7fNChgwZYtSqVeui4zt27DAkGaNGjTLXXek1iYyMtLsmJc6dO2fk5+fbrTt58qTh6+trPP7445edc7du3YyWLVvarbvS6zV48GDD0dHR2Lp1a6n9FhcXG4ZhGCNHjjQkGV999ZU5durUKSMoKMho0qSJUVRUZBiGYXz55ZeGJKNVq1ZGQUGBWTtgwADDwcHB6NOnj93+w8LC7K7HgQMHDCcnJ+Oll16yq/v2228NZ2fnUut/b8GCBYakC55LCU9PT6N9+/bm69//rM2cOdOQZBw/fvyi+9i6dashyViwYEGpsUv97nTr1s3o1q2b+brket1www2GzWYz1y9dutSQZMyePdtcFxgYaAwZMuSy+7zU3H7/O7lixQpDkvHiiy/a1T3wwAOGg4OD3c/Olf48AQBgBb/vb7/66itDkrFo0SK7uqSkJLv1H3300WV7iePHjxuSjIkTJ5Yao4elhz0fPSw9LFDZeFQC8Afm6uqqoUOHllp//r+enjp1Sv/5z3/UpUsX/fLLL9q7d+9l9/vwww+rbt265uuSf1H98ccfL7tteHi4mjZtar5u06aNPDw8zG2Lior0xRdfKCoqSv7+/mbdTTfdpD59+lx2/1ei5A6D87/dtbzXxMnJyXx2VHFxsU6cOKFz586pQ4cO2r59e5nnernrVVxcrBUrVujuu++2e55WiZKPX61evVq33367OnfubI7Vrl1b0dHROnDggL777ju77QYPHmx393RoaKgMwzA/Znj++sOHD+vcuXOSpOXLl6u4uFgPPfSQ/vOf/5iLn5+fbr755nJ97O78eV/qm3lL7ob4+OOPy/wlCBf73bmYwYMHq06dOubrBx54QA0bNtTq1avLdPwrtXr1ajk5OWnEiBF265999lkZhqHPPvvMbv3lfp4AALCqZcuWydPTU3/605/seoyQkBDVrl3b7DFK+oCVK1eqsLCwwo5PD3t16GFLo4f9H3pY4H8IboE/sBtuuOGCD6LfvXu37rvvPnl6esrDw0MNGjQwvwQhLy/vsvtt3Lix3euSEPf3zxe7km1Lti/ZNicnR7/++qtuuummUnUXWlcWp0+fliS7JqW810SSFi5cqDZt2sjNzU316tVTgwYNtGrVqive/kIud72OHz8um82mVq1aXXI/Bw8eVLNmzUqtL/lm5oMHD17yuJ6enpKkgICAUuuLi4vNc9y3b58Mw9DNN9+sBg0a2C179uxRTk7OJed5JU6fPm33Z/d7Dz/8sDp16qQnnnhCvr6+6t+/v5YuXXpVDfDFfncu5uabb7Z77eDgoJtuukkHDhy44n2UxcGDB+Xv71/qelzpn6tk//MEAIBV7du3T3l5efLx8SnVY5w+fdrsMbp166Z+/fpp0qRJql+/vu69914tWLDggs8zvRr0sFeHHrY0etj/oYcF/odn3AJ/YBd6LlFubq66desmDw8PTZ48WU2bNpWbm5u2b9+usWPHXlFj4OTkdMH1xu8eJF/R21aUXbt2SfpfE10R1+S9997TY489pqioKI0ePVo+Pj5ycnLSlClT9MMPP5R5rtV1vS523MvNp7i4WA4ODvrss88uWFtyp0hZHTlyRHl5eZf8P0Du7u7asGGDvvzyS61atUpJSUlasmSJ7rzzTq1Zs+ai5/D7fVS0i30pSVFR0RXNqSJY4fcPAICyKC4ulo+PjxYtWnTB8ZLnyDo4OOjDDz/Upk2b9Omnn+rzzz/X448/runTp2vTpk1l7kWs8HcoPWzZj0sPW3b0sEDlIrgFYGfdunX6+eeftXz5cnXt2tVcn5mZWY2z+h8fHx+5ublp//79pcYutK4s/vnPf8rBwUF/+tOfJF3dNblY4/Lhhx/qxhtv1PLly+1qJk6cWCFzvpgGDRrIw8PDbOQvJjAwUBkZGaXWl3yELjAwsELm07RpUxmGoaCgIPNLMyrSP//5T0lSRETEJescHR3Vs2dP9ezZUzNmzNDLL7+s559/Xl9++aXCw8PL/c3Ov7dv3z6714ZhaP/+/XZfdFK3bl3l5uaW2vbgwYO68cYbzddXM7fAwEB98cUXOnXqlN0dCxX95woAQHVr2rSpvvjiC3Xq1OmKwqmOHTuqY8eOeumll7R48WINHDhQH3zwgZ544okK7wMketirRQ97YfSw9LD44+FRCQDslPxr5fn/OllQUKA33nijuqZkx8nJSeHh4VqxYoWOHj1qrt+/f3+pZx2VxSuvvKI1a9bo4YcfNj8adDXXpFatWhf82NiF9rF582alpqaWe86X4ujoqKioKH366afatm1bqfGS+fTt21dbtmyxm8+ZM2c0f/58NWnSRMHBwRUyn/vvv19OTk6aNGlSqX8BNwxDP//8c5n3vXbtWr3wwgsKCgrSwIEDL1p34sSJUutKvhG55GOStWrVkqQLNqFl8e6779o9s+zDDz/UsWPH7J5p17RpU23atEkFBQXmupUrV+rw4cN2+7qaufXt21dFRUWaM2eO3fqZM2fKwcGhwp6pBwBAdXvooYdUVFSkF154odTYuXPnzL83T548WaoH+X0fULNmTUkV1wdI9LBXix62NHpYelj8MXHHLQA7d9xxh+rWrashQ4ZoxIgRcnBw0D//+U9LfcwkISFBa9asUadOnfT000+bf6m3atVK6enpV7SPc+fO6b333pMknT17VgcPHtQnn3yinTt3qkePHpo/f75ZezXXJCQkREuWLFFcXJxuu+021a5dW3fffbfuuusuLV++XPfdd58iIyOVmZmpefPmKTg42HweWWV5+eWXtWbNGnXr1k3R0dFq0aKFjh07pmXLlunrr7+Wl5eXnnvuOb3//vvq06ePRowYIW9vby1cuFCZmZn617/+JUfHivl3vqZNm+rFF1/UuHHjdODAAUVFRalOnTrKzMzURx99pOjoaP3lL3+57H4+++wz7d27V+fOnVN2drbWrl2r5ORkBQYG6pNPPpGbm9tFt508ebI2bNigyMhIBQYGKicnR2+88YYaNWpkfrFF06ZN5eXlpXnz5qlOnTqqVauWQkNDFRQUVKbz9vb2VufOnTV06FBlZ2dr1qxZuummmzR8+HCz5oknntCHH36o3r1766GHHtIPP/yg9957z+6LFq52bnfffbd69Oih559/XgcOHFDbtm21Zs0affzxxxo5cmSpfQMAcK3q1q2bnnzySU2ZMkXp6enq1auXatSooX379mnZsmWaPXu2HnjgAS1cuFBvvPGG7rvvPjVt2lSnTp3SP/7xD3l4eKhv376Sfvs4eXBwsJYsWaJbbrlF3t7eatWq1WWft3o59LBXhx7WHj0sPSz+oAwA172YmBjj97/u3bp1M1q2bHnB+m+++cbo2LGj4e7ubvj7+xtjxowxPv/8c0OS8eWXX5p1Q4YMMQIDA83XmZmZhiRj2rRppfYpyZg4caL5euLEiaXmJMmIiYkptW1gYKAxZMgQu3UpKSlG+/btDRcXF6Np06bGW2+9ZTz77LOGm5vbRa7C/wwZMsSQZC41a9Y0mjRpYvTr18/48MMPjaKiojJfk9OnTxuPPPKI4eXlZUgyr09xcbHx8ssvG4GBgYarq6vRvn17Y+XKlaWu4cVc6M/raq7XwYMHjcGDBxsNGjQwXF1djRtvvNGIiYkx8vPzzZoffvjBeOCBBwwvLy/Dzc3NuP32242VK1fa7efLL780JBnLli2zW79gwQJDkrF161a79SV/zsePH7db/69//cvo3LmzUatWLaNWrVpG8+bNjZiYGCMjI+OS16HkOCWLi4uL4efnZ/zpT38yZs+ebdhstlLb/P5nLSUlxbj33nsNf39/w8XFxfD39zcGDBhgfP/993bbffzxx0ZwcLDh7OxsSDIWLFhgGMalf3e6detmdOvWrdT1ev/9941x48YZPj4+hru7uxEZGWkcPHiw1PbTp083brjhBsPV1dXo1KmTsW3btlL7vNTcLvTzdOrUKWPUqFGGv7+/UaNGDePmm282pk2bZhQXF9vVXc3PEwAA1e1C/a1hGMb8+fONkJAQw93d3ahTp47RunVrY8yYMcbRo0cNwzCM7du3GwMGDDAaN25suLq6Gj4+PsZdd91lbNu2zW4/GzduNEJCQgwXFxe7PpYelh6WHpYeFqhKDoZhodvoAKAcoqKitHv37lLPYgIAAACsih4WAHAxPOMWwDXp119/tXu9b98+rV69Wt27d6+eCQEAAACXQQ8LALga3HEL4JrUsGFDPfbYY7rxxht18OBBvfnmm8rPz9eOHTvML2QAAAAArIQeFgBwNfhyMgDXpN69e+v9999XVlaWXF1dFRYWppdffpmGFwAAAJZFDwsAuBrccQsAAAAAAAAAFsMzbgEAAAAAAADAYghuAQAAAAAAAMBieMZtBSkuLtbRo0dVp04dOTg4VPd0AAAArkuGYejUqVPy9/eXoyP3IFQ0eloAAIDKdTX9LMFtBTl69KgCAgKqexoAAAB/CIcPH1ajRo2qexrXHXpaAACAqnEl/SzBbQWpU6eOpN8uuoeHRzXPBgAA4Ppks9kUEBBg9l6oWPS0AAAAletq+lmC2wpS8lEyDw8PmlwAAIBKxsf4Kwc9LQAAQNW4kn6WB4MBAAAAAAAAgMUQ3AIAAAAAAACAxRDcAgAAAAAAAIDFENwCAAAAAAAAgMUQ3AIAAAAAAACAxRDcAgAAAAAAAIDFENwCAAAAAAAAgMUQ3AIAAAAAAACAxVRrcDtlyhTddtttqlOnjnx8fBQVFaWMjAy7mu7du8vBwcFueeqpp+xqDh06pMjISNWsWVM+Pj4aPXq0zp07Z1ezbt063XrrrXJ1ddVNN92kxMTEUvOZO3eumjRpIjc3N4WGhmrLli0Vfs4AAAAAAAAAcDnVGtyuX79eMTEx2rRpk5KTk1VYWKhevXrpzJkzdnXDhw/XsWPHzGXq1KnmWFFRkSIjI1VQUKCNGzdq4cKFSkxMVHx8vFmTmZmpyMhI9ejRQ+np6Ro5cqSeeOIJff7552bNkiVLFBcXp4kTJ2r79u1q27atIiIilJOTU/kXAgAAAAAAAADO42AYhlHdkyhx/Phx+fj4aP369eratauk3+64bdeunWbNmnXBbT777DPdddddOnr0qHx9fSVJ8+bN09ixY3X8+HG5uLho7NixWrVqlXbt2mVu179/f+Xm5iopKUmSFBoaqttuu01z5syRJBUXFysgIEDPPPOMnnvuucvO3WazydPTU3l5efLw8CjPZQAAAMBF0HNVLq4vAABA5bqafstSz7jNy8uTJHl7e9utX7RokerXr69WrVpp3Lhx+uWXX8yx1NRUtW7d2gxtJSkiIkI2m027d+82a8LDw+32GRERodTUVElSQUGB0tLS7GocHR0VHh5u1vxefn6+bDab3QIAAAAAAAAAFcG5uidQori4WCNHjlSnTp3UqlUrc/0jjzyiwMBA+fv7a+fOnRo7dqwyMjK0fPlySVJWVpZdaCvJfJ2VlXXJGpvNpl9//VUnT55UUVHRBWv27t17wflOmTJFkyZNKt9JAwAAAAAAAMAFWCa4jYmJ0a5du/T111/brY+Ojjb/u3Xr1mrYsKF69uypH374QU2bNq3qaZrGjRunuLg487XNZlNAQEC1zQcAAAAAAADA9cMSwW1sbKxWrlypDRs2qFGjRpesDQ0NlSTt379fTZs2lZ+fn7Zs2WJXk52dLUny8/Mz/7dk3fk1Hh4ecnd3l5OTk5ycnC5YU7KP33N1dZWrq+uVnyQAAAAAAAAAXKFqfcatYRiKjY3VRx99pLVr1yooKOiy26Snp0uSGjZsKEkKCwvTt99+q5ycHLMmOTlZHh4eCg4ONmtSUlLs9pOcnKywsDBJkouLi0JCQuxqiouLlZKSYtYAAAAAAAAAQFWp1jtuY2JitHjxYn388ceqU6eO+UxaT09Pubu764cfftDixYvVt29f1atXTzt37tSoUaPUtWtXtWnTRpLUq1cvBQcHa9CgQZo6daqysrI0fvx4xcTEmHfEPvXUU5ozZ47GjBmjxx9/XGvXrtXSpUu1atUqcy5xcXEaMmSIOnTooNtvv12zZs3SmTNnNHTo0Kq/MAAAAAAAAAD+0Ko1uH3zzTclSd27d7dbv2DBAj322GNycXHRF198YYaoAQEB6tevn8aPH2/WOjk5aeXKlXr66acVFhamWrVqaciQIZo8ebJZExQUpFWrVmnUqFGaPXu2GjVqpLfeeksRERFmzcMPP6zjx48rPj5eWVlZateunZKSkkp9YZkVzdlyoLqnAKCcYm9vUt1TAACgWtHTAtc+eloAqFgOhmEY1T2J64HNZpOnp6fy8vLk4eFRpcemyQWufTS5AHBlqrPn+iOgpwVQHvS0AHB5V9NvVeszbgEAAAAAAAAApRHcAgAAAAAAAIDFENwCAAAAAAAAgMUQ3AIAAAAAAACAxRDcAgAAAAAAAIDFENwCAAAAAAAAgMUQ3AIAAAAAAACAxRDcAgAAAOWwYcMG3X333fL395eDg4NWrFhhjhUWFmrs2LFq3bq1atWqJX9/fw0ePFhHjx6128eJEyc0cOBAeXh4yMvLS8OGDdPp06ftanbu3KkuXbrIzc1NAQEBmjp1aqm5LFu2TM2bN5ebm5tat26t1atXV8o5AwAAoPIR3AIAAADlcObMGbVt21Zz584tNfbLL79o+/btmjBhgrZv367ly5crIyND99xzj13dwIEDtXv3biUnJ2vlypXasGGDoqOjzXGbzaZevXopMDBQaWlpmjZtmhISEjR//nyzZuPGjRowYICGDRumHTt2KCoqSlFRUdq1a1flnTwAAAAqjYNhGEZ1T+J6YLPZ5Onpqby8PHl4eFTpsedsOVClxwNQ8WJvb1LdUwCAa0J19lxXwsHBQR999JGioqIuWrN161bdfvvtOnjwoBo3bqw9e/YoODhYW7duVYcOHSRJSUlJ6tu3r44cOSJ/f3+9+eabev7555WVlSUXFxdJ0nPPPacVK1Zo7969kqSHH35YZ86c0cqVK81jdezYUe3atdO8efOuaP70tADKg54WAC7vavot7rgFAAAAqlBeXp4cHBzk5eUlSUpNTZWXl5cZ2kpSeHi4HB0dtXnzZrOma9euZmgrSREREcrIyNDJkyfNmvDwcLtjRUREKDU19aJzyc/Pl81ms1sAAABgDQS3AAAAQBU5e/asxo4dqwEDBph3WGRlZcnHx8euztnZWd7e3srKyjJrfH197WpKXl+upmT8QqZMmSJPT09zCQgIKN8JAgAAoMIQ3AIAAABVoLCwUA899JAMw9Cbb75Z3dORJI0bN055eXnmcvjw4eqeEgAAAP7LubonAAAAAFzvSkLbgwcPau3atXbPM/Pz81NOTo5d/blz53TixAn5+fmZNdnZ2XY1Ja8vV1MyfiGurq5ydXUt+4kBAACg0nDHLQAAAFCJSkLbffv26YsvvlC9evXsxsPCwpSbm6u0tDRz3dq1a1VcXKzQ0FCzZsOGDSosLDRrkpOT1axZM9WtW9esSUlJsdt3cnKywsLCKuvUAAAAUIkIbgEAAIByOH36tNLT05Weni5JyszMVHp6ug4dOqTCwkI98MAD2rZtmxYtWqSioiJlZWUpKytLBQUFkqQWLVqod+/eGj58uLZs2aJvvvlGsbGx6t+/v/z9/SVJjzzyiFxcXDRs2DDt3r1bS5Ys0ezZsxUXF2fO489//rOSkpI0ffp07d27VwkJCdq2bZtiY2Or/JoAAACg/AhuAQAAgHLYtm2b2rdvr/bt20uS4uLi1L59e8XHx+unn37SJ598oiNHjqhdu3Zq2LChuWzcuNHcx6JFi9S8eXP17NlTffv2VefOnTV//nxz3NPTU2vWrFFmZqZCQkL07LPPKj4+XtHR0WbNHXfcocWLF2v+/Plq27atPvzwQ61YsUKtWrWquosBAACACsMzbgEAAIBy6N69uwzDuOj4pcZKeHt7a/HixZesadOmjb766qtL1jz44IN68MEHL3s8AAAAWB933AIAAAAAAACAxRDcAgAAAAAAAIDFENwCAAAAAAAAgMUQ3AIAAAAAAACAxRDcAgAAAAAAAIDFENwCAAAAAAAAgMUQ3AIAAAAAAACAxRDcAgAAAAAAAIDFENwCAAAAAAAAgMUQ3AIAAAAAAACAxRDcAgAAAAAAAIDFENwCAAAAAAAAgMUQ3AIAAAAAAACAxRDcAgAAAAAAAIDFENwCAAAAAAAAgMUQ3AIAAAAAAACAxRDcAgAAAAAAAIDFENwCAAAAAAAAgMUQ3AIAAAAAAACAxRDcAgAAAAAAAIDFENwCAAAAAAAAgMUQ3AIAAAAAAACAxRDcAgAAAAAAAIDFENwCAAAAAAAAgMUQ3AIAAAAAAACAxRDcAgAAAAAAAIDFENwCAAAAAAAAgMUQ3AIAAAAAAACAxRDcAgAAAAAAAIDFENwCAAAAAAAAgMUQ3AIAAAAAAACAxRDcAgAAAAAAAIDFENwCAAAAAAAAgMUQ3AIAAAAAAACAxRDcAgAAAAAAAIDFENwCAAAAAAAAgMUQ3AIAAAAAAACAxRDcAgAAAAAAAIDFENwCAAAAAAAAgMUQ3AIAAAAAAACAxRDcAgAAAAAAAIDFENwCAAAAAAAAgMUQ3AIAAAAAAACAxRDcAgAAAAAAAIDFENwCAAAAAAAAgMUQ3AIAAAAAAACAxRDcAgAAAAAAAIDFENwCAAAAAAAAgMUQ3AIAAAAAAACAxVRrcDtlyhTddtttqlOnjnx8fBQVFaWMjAy7mrNnzyomJkb16tVT7dq11a9fP2VnZ9vVHDp0SJGRkapZs6Z8fHw0evRonTt3zq5m3bp1uvXWW+Xq6qqbbrpJiYmJpeYzd+5cNWnSRG5ubgoNDdWWLVsq/JwBAAAAAAAA4HKqNbhdv369YmJitGnTJiUnJ6uwsFC9evXSmTNnzJpRo0bp008/1bJly7R+/XodPXpU999/vzleVFSkyMhIFRQUaOPGjVq4cKESExMVHx9v1mRmZioyMlI9evRQenq6Ro4cqSeeeEKff/65WbNkyRLFxcVp4sSJ2r59u9q2bauIiAjl5ORUzcUAAAAAAAAAgP+q1uA2KSlJjz32mFq2bKm2bdsqMTFRhw4dUlpamiQpLy9Pb7/9tmbMmKE777xTISEhWrBggTZu3KhNmzZJktasWaPvvvtO7733ntq1a6c+ffrohRde0Ny5c1VQUCBJmjdvnoKCgjR9+nS1aNFCsbGxeuCBBzRz5kxzLjNmzNDw4cM1dOhQBQcHa968eapZs6beeeedqr8wAAAAuGZs2LBBd999t/z9/eXg4KAVK1bYjRuGofj4eDVs2FDu7u4KDw/Xvn377GpOnDihgQMHysPDQ15eXho2bJhOnz5tV7Nz50516dJFbm5uCggI0NSpU0vNZdmyZWrevLnc3NzUunVrrV69usLPFwAAAFXDUs+4zcvLkyR5e3tLktLS0lRYWKjw8HCzpnnz5mrcuLFSU1MlSampqWrdurV8fX3NmoiICNlsNu3evdusOX8fJTUl+ygoKFBaWppdjaOjo8LDw82a38vPz5fNZrNbAAAA8Mdz5swZtW3bVnPnzr3g+NSpU/Xaa69p3rx52rx5s2rVqqWIiAidPXvWrBk4cKB2796t5ORkrVy5Uhs2bFB0dLQ5brPZ1KtXLwUGBiotLU3Tpk1TQkKC5s+fb9Zs3LhRAwYM0LBhw7Rjxw5FRUUpKipKu3btqryTBwAAQKWxTHBbXFyskSNHqlOnTmrVqpUkKSsrSy4uLvLy8rKr9fX1VVZWlllzfmhbMl4ydqkam82mX3/9Vf/5z39UVFR0wZqSffzelClT5OnpaS4BAQFlO3EAAABc0/r06aMXX3xR9913X6kxwzA0a9YsjR8/Xvfee6/atGmjd999V0ePHjXvzN2zZ4+SkpL01ltvKTQ0VJ07d9brr7+uDz74QEePHpUkLVq0SAUFBXrnnXfUsmVL9e/fXyNGjNCMGTPMY82ePVu9e/fW6NGj1aJFC73wwgu69dZbNWfOnCq5DgAAAKhYlgluY2JitGvXLn3wwQfVPZUrMm7cOOXl5ZnL4cOHq3tKAAAAsJjMzExlZWXZfbLL09NToaGhdp8g8/LyUocOHcya8PBwOTo6avPmzWZN165d5eLiYtZEREQoIyNDJ0+eNGsu9SmzC+FTZAAAANZlieA2NjZWK1eu1JdffqlGjRqZ6/38/FRQUKDc3Fy7+uzsbPn5+Zk12dnZpcZLxi5V4+HhIXd3d9WvX19OTk4XrCnZx++5urrKw8PDbgEAAADOV/LprUt9sisrK0s+Pj52487OzvL29q6QT5ld7BNkEp8iAwAAsLJqDW4Nw1BsbKw++ugjrV27VkFBQXbjISEhqlGjhlJSUsx1GRkZOnTokMLCwiRJYWFh+vbbb5WTk2PWJCcny8PDQ8HBwWbN+fsoqSnZh4uLi0JCQuxqiouLlZKSYtYAAAAA1xs+RQYAAGBdztV58JiYGC1evFgff/yx6tSpY94N4OnpKXd3d3l6emrYsGGKi4uTt7e3PDw89MwzzygsLEwdO3aUJPXq1UvBwcEaNGiQpk6dqqysLI0fP14xMTFydXWVJD311FOaM2eOxowZo8cff1xr167V0qVLtWrVKnMucXFxGjJkiDp06KDbb79ds2bN0pkzZzR06NCqvzAAAAC4LpR8eis7O1sNGzY012dnZ6tdu3Zmzfk3IUjSuXPndOLEiQr5lNnFPkEm/fYpspKeGQAAANZSrXfcvvnmm8rLy1P37t3VsGFDc1myZIlZM3PmTN11113q16+funbtKj8/Py1fvtwcd3Jy0sqVK+Xk5KSwsDA9+uijGjx4sCZPnmzWBAUFadWqVUpOTlbbtm01ffp0vfXWW4qIiDBrHn74Yb366quKj49Xu3btlJ6erqSkpFIfNwMAAACuVFBQkPz8/Ow+2WWz2bR582a7T5Dl5uYqLS3NrFm7dq2Ki4sVGhpq1mzYsEGFhYVmTXJyspo1a6a6deuaNZf6lBkAAACuLQ6GYRjVPYnrgc1mk6enp/Ly8qr8ebdzthyo0uMBqHixtzep7ikAwDWhOnuuizl9+rT2798vSWrfvr1mzJihHj16yNvbW40bN9bf/vY3vfLKK1q4cKGCgoI0YcIE7dy5U999953c3NwkSX369FF2drbmzZunwsJCDR06VB06dNDixYslSXl5eWrWrJl69eqlsWPHateuXXr88cc1c+ZMRUdHS5I2btyobt266ZVXXlFkZKQ++OADvfzyy9q+fbtatWp1RedCTwugPOhpAeDyrqbfqtZHJQAAAADXum3btqlHjx7m67i4OEnSkCFDlJiYqDFjxujMmTOKjo5Wbm6uOnfurKSkJDO0laRFixYpNjZWPXv2lKOjo/r166fXXnvNHPf09NSaNWsUExOjkJAQ1a9fX/Hx8WZoK0l33HGHFi9erPHjx+uvf/2rbr75Zq1YseKKQ1sAAABYC3fcVhDuTgBQHtydAABXxop33F5P6GkBlAc9LQBc3tX0W9X6jFsAAAAAAAAAQGkEtwAAAAAAAABgMQS3AAAAAAAAAGAxBLcAAAAAAAAAYDEEtwAAAAAAAABgMQS3AAAAAAAAAGAxBLcAAAAAAAAAYDEEtwAAAAAAAABgMQS3AAAAAAAAAGAxBLcAAAAAAAAAYDEEtwAAAAAAAABgMQS3AAAAAAAAAGAxBLcAAAAAAAAAYDEEtwAAAAAAAABgMQS3AAAAAAAAAGAxBLcAAAAAAAAAYDEEtwAAAAAAAABgMQS3AAAAAAAAAGAxBLcAAAAAAAAAYDEEtwAAAAAAAABgMQS3AAAAAAAAAGAxBLcAAAAAAAAAYDEEtwAAAAAAAABgMQS3AAAAAAAAAGAxBLcAAAAAAAAAYDEEtwAAAAAAAABgMQS3AAAAAAAAAGAxBLcAAAAAAAAAYDEEtwAAAAAAAABgMQS3AAAAAAAAAGAxBLcAAAAAAAAAYDEEtwAAAAAAAABgMQS3AAAAAAAAAGAxBLcAAAAAAAAAYDEEtwAAAAAAAABgMQS3AAAAAAAAAGAxBLcAAAAAAAAAYDEEtwAAAAAAAABgMQS3AAAAAAAAAGAxBLcAAAAAAAAAYDEEtwAAAAAAAABgMQS3AAAAAAAAAGAxBLcAAAAAAAAAYDEEtwAAAAAAAABgMQS3AAAAAAAAAGAxBLcAAAAAAAAAYDEEtwAAAAAAAABgMQS3AAAAAAAAAGAxBLcAAAAAAAAAYDEEtwAAAAAAAABgMQS3AAAAQCUqKirShAkTFBQUJHd3dzVt2lQvvPCCDMMwawzDUHx8vBo2bCh3d3eFh4dr3759dvs5ceKEBg4cKA8PD3l5eWnYsGE6ffq0Xc3OnTvVpUsXubm5KSAgQFOnTq2ScwQAAEDFI7gFAAAAKtHf/vY3vfnmm5ozZ4727Nmjv/3tb5o6dapef/11s2bq1Kl67bXXNG/ePG3evFm1atVSRESEzp49a9YMHDhQu3fvVnJyslauXKkNGzYoOjraHLfZbOrVq5cCAwOVlpamadOmKSEhQfPnz6/S8wUAAEDFcK7uCQAAAADXs40bN+ree+9VZGSkJKlJkyZ6//33tWXLFkm/3W07a9YsjR8/Xvfee68k6d1335Wvr69WrFih/v37a8+ePUpKStLWrVvVoUMHSdLrr7+uvn376tVXX5W/v78WLVqkgoICvfPOO3JxcVHLli2Vnp6uGTNm2AW8AAAAuDZwxy0AAABQie644w6lpKTo+++/lyT9+9//1tdff60+ffpIkjIzM5WVlaXw8HBzG09PT4WGhio1NVWSlJqaKi8vLzO0laTw8HA5Ojpq8+bNZk3Xrl3l4uJi1kRERCgjI0MnT56s9PMEAABAxeKOWwAAAKASPffcc7LZbGrevLmcnJxUVFSkl156SQMHDpQkZWVlSZJ8fX3ttvP19TXHsrKy5OPjYzfu7Owsb29vu5qgoKBS+ygZq1u3bqm55efnKz8/33xts9nKc6oAAACoQNxxCwAAAFSipUuXatGiRVq8eLG2b9+uhQsX6tVXX9XChQure2qaMmWKPD09zSUgIKC6pwQAAID/IrgFAAAAKtHo0aP13HPPqX///mrdurUGDRqkUaNGacqUKZIkPz8/SVJ2drbddtnZ2eaYn5+fcnJy7MbPnTunEydO2NVcaB/nH+P3xo0bp7y8PHM5fPhwOc8WAAAAFYXgFgAAAKhEv/zyixwd7dtuJycnFRcXS5KCgoLk5+enlJQUc9xms2nz5s0KCwuTJIWFhSk3N1dpaWlmzdq1a1VcXKzQ0FCzZsOGDSosLDRrkpOT1axZsws+JkGSXF1d5eHhYbcAAADAGghuAQAAgEp0991366WXXtKqVat04MABffTRR5oxY4buu+8+SZKDg4NGjhypF198UZ988om+/fZbDR48WP7+/oqKipIktWjRQr1799bw4cO1ZcsWffPNN4qNjVX//v3l7+8vSXrkkUfk4uKiYcOGaffu3VqyZIlmz56tuLi46jp1AAAAlANfTgYAAABUotdff10TJkzQ//3f/yknJ0f+/v568sknFR8fb9aMGTNGZ86cUXR0tHJzc9W5c2clJSXJzc3NrFm0aJFiY2PVs2dPOTo6ql+/fnrttdfMcU9PT61Zs0YxMTEKCQlR/fr1FR8fr+jo6Co9XwAAAFQMB8MwjOqexPXAZrPJ09NTeXl5Vf4RszlbDlTp8QBUvNjbm1T3FADgmlCdPdcfAT0tgPKgpwWAy7uafotHJQAAAAAAAACAxRDcAgAAAAAAAIDFENwCAAAAAAAAgMUQ3AIAAAAAAACAxVRrcLthwwbdfffd8vf3l4ODg1asWGE3/thjj8nBwcFu6d27t13NiRMnNHDgQHl4eMjLy0vDhg3T6dOn7Wp27typLl26yM3NTQEBAZo6dWqpuSxbtkzNmzeXm5ubWrdurdWrV1f4+QIAAAAAAADAlajW4PbMmTNq27at5s6de9Ga3r1769ixY+by/vvv240PHDhQu3fvVnJyslauXKkNGzYoOjraHLfZbOrVq5cCAwOVlpamadOmKSEhQfPnzzdrNm7cqAEDBmjYsGHasWOHoqKiFBUVpV27dlX8SQMAAAAAAADAZThX58H79OmjPn36XLLG1dVVfn5+Fxzbs2ePkpKStHXrVnXo0EGS9Prrr6tv37569dVX5e/vr0WLFqmgoEDvvPOOXFxc1LJlS6Wnp2vGjBlmwDt79mz17t1bo0ePliS98MILSk5O1pw5czRv3rwKPGMAAAAAAAAAuDzLP+N23bp18vHxUbNmzfT000/r559/NsdSU1Pl5eVlhraSFB4eLkdHR23evNms6dq1q1xcXMyaiIgIZWRk6OTJk2ZNeHi43XEjIiKUmpp60Xnl5+fLZrPZLQAAAAAAAABQESwd3Pbu3VvvvvuuUlJS9Le//U3r169Xnz59VFRUJEnKysqSj4+P3TbOzs7y9vZWVlaWWePr62tXU/L6cjUl4xcyZcoUeXp6mktAQED5ThYAAAAAAAAA/qtaH5VwOf379zf/u3Xr1mrTpo2aNm2qdevWqWfPntU4M2ncuHGKi4szX9tsNsJbAAAAAAAAABXC0nfc/t6NN96o+vXra//+/ZIkPz8/5eTk2NWcO3dOJ06cMJ+L6+fnp+zsbLuakteXq7nYs3Wl35696+HhYbcAAAAAAAAAQEW4poLbI0eO6Oeff1bDhg0lSWFhYcrNzVVaWppZs3btWhUXFys0NNSs2bBhgwoLC82a5ORkNWvWTHXr1jVrUlJS7I6VnJyssLCwyj4lAAAAAAAAACilWoPb06dPKz09Xenp6ZKkzMxMpaen69ChQzp9+rRGjx6tTZs26cCBA0pJSdG9996rm266SREREZKkFi1aqHfv3ho+fLi2bNmib775RrGxserfv7/8/f0lSY888ohcXFw0bNgw7d69W0uWLNHs2bPtHnPw5z//WUlJSZo+fbr27t2rhIQEbdu2TbGxsVV+TQAAAAAAAACgWoPbbdu2qX379mrfvr0kKS4uTu3bt1d8fLycnJy0c+dO3XPPPbrllls0bNgwhYSE6KuvvpKrq6u5j0WLFql58+bq2bOn+vbtq86dO2v+/PnmuKenp9asWaPMzEyFhITo2WefVXx8vKKjo82aO+64Q4sXL9b8+fPVtm1bffjhh1qxYoVatWpVdRcDAAAAAAAAAP7LwTAMo7oncT2w2Wzy9PRUXl5elT/vds6WA1V6PAAVL/b2JtU9BQC4JlRnz/VHQE8LoDzoaQHg8q6m37qmnnELAAAAAAAAAH8EBLcAAAAAAAAAYDEEtwAAAAAAAABgMQS3AAAAAAAAAGAxBLcAAAAAAAAAYDEEtwAAAAAAAABgMWUKbm+88Ub9/PPPpdbn5ubqxhtvLPekAAAAgMpEPwsAAACrK1Nwe+DAARUVFZVan5+fr59++qnckwIAAAAqE/0sAAAArM75aoo/+eQT878///xzeXp6mq+LioqUkpKiJk2aVNjkAAAAgIpEPwsAAIBrxVUFt1FRUZIkBwcHDRkyxG6sRo0aatKkiaZPn15hkwMAAAAqEv0sAAAArhVXFdwWFxdLkoKCgrR161bVr1+/UiYFAAAAVAb6WQAAAFwrriq4LZGZmVnR8wAAAACqDP0sAAAArK5Mwa0kpaSkKCUlRTk5OeadCyXeeeedck8MAAAAqEz0swAAALCyMgW3kyZN0uTJk9WhQwc1bNhQDg4OFT0vAAAAoNLQzwIAAMDqyhTczps3T4mJiRo0aFBFzwcAAACodPSzAAAAsDrHsmxUUFCgO+64o6LnAgAAAFQJ+lkAAABYXZmC2yeeeEKLFy+u6LkAAAAAVYJ+FgAAAFZXpkclnD17VvPnz9cXX3yhNm3aqEaNGnbjM2bMqJDJAQAAAJWBfhYAAABWV6bgdufOnWrXrp0kadeuXXZjfLEDAAAArI5+FgAAAFZXpuD2yy+/rOh5AAAAAFWGfhYAAABWV6Zn3AIAAAAAAAAAKk+Z7rjt0aPHJT9Ctnbt2jJPCAAAAKhs9LMAAACwujIFtyXPAytRWFio9PR07dq1S0OGDKmIeQEAAACVhn4WAAAAVlem4HbmzJkXXJ+QkKDTp0+Xa0IAAABAZaOfBQAAgNVV6DNuH330Ub3zzjsVuUsAAACgytDPAgAAwCoqNLhNTU2Vm5tbRe4SAAAAqDL0swAAALCKMj0q4f7777d7bRiGjh07pm3btmnChAkVMjEAAACgstDPAgAAwOrKFNx6enravXZ0dFSzZs00efJk9erVq0ImBgAAAFQW+lkAAABYXZmC2wULFlT0PAAAAIAqQz8LAAAAqytTcFsiLS1Ne/bskSS1bNlS7du3r5BJAQAAAFWBfhYAAABWVabgNicnR/3799e6devk5eUlScrNzVWPHj30wQcfqEGDBhU5RwAAAKBC0c8CAADA6hzLstEzzzyjU6dOaffu3Tpx4oROnDihXbt2yWazacSIERU9RwAAAKBC0c8CAADA6sp0x21SUpK++OILtWjRwlwXHBysuXPn8mUOAAAAsDz6WQAAAFhdme64LS4uVo0aNUqtr1GjhoqLi8s9KQAAAKAy0c8CAADA6soU3N55553685//rKNHj5rrfvrpJ40aNUo9e/assMkBAAAAlYF+FgAAAFZXpuB2zpw5stlsatKkiZo2baqmTZsqKChINptNr7/+ekXPEQAAAKhQ9LMAAACwujIFtwEBAdq+fbtWrVqlkSNHauTIkVq9erW2b9+uRo0aVfQcAQAAgApV1f3sTz/9pEcffVT16tWTu7u7WrdurW3btpnjhmEoPj5eDRs2lLu7u8LDw7Vv3z67fZw4cUIDBw6Uh4eHvLy8NGzYMJ0+fdquZufOnerSpYvc3NwUEBCgqVOnVvi5AAAAoGpcVXC7du1aBQcHy2azycHBQX/605/0zDPP6JlnntFtt92mli1b6quvvqqsuQIAAADlUh397MmTJ9WpUyfVqFFDn332mb777jtNnz5ddevWNWumTp2q1157TfPmzdPmzZtVq1YtRURE6OzZs2bNwIEDtXv3biUnJ2vlypXasGGDoqOjzXGbzaZevXopMDBQaWlpmjZtmhISEjR//vwKPR8AAABUDeerKZ41a5aGDx8uDw+PUmOenp568sknNWPGDHXp0qXCJggAAABUlOroZ//2t78pICBACxYsMNcFBQWZ/20YhmbNmqXx48fr3nvvlSS9++678vX11YoVK9S/f3/t2bNHSUlJ2rp1qzp06CBJev3119W3b1+9+uqr8vf316JFi1RQUKB33nlHLi4uatmypdLT0zVjxgy7gBcAAADXhqu64/bf//63evfufdHxXr16KS0trdyTAgAAACpDdfSzn3zyiTp06KAHH3xQPj4+at++vf7xj3+Y45mZmcrKylJ4eLi5ztPTU6GhoUpNTZUkpaamysvLywxtJSk8PFyOjo7avHmzWdO1a1e5uLiYNREREcrIyNDJkycr9JwAAABQ+a4quM3OzlaNGjUuOu7s7Kzjx4+Xe1IAAABAZaiOfvbHH3/Um2++qZtvvlmff/65nn76aY0YMUILFy6UJGVlZUmSfH197bbz9fU1x7KysuTj41Nqrt7e3nY1F9rH+cf4vfz8fNlsNrsFAAAA1nBVwe0NN9ygXbt2XXR8586datiwYbknBQAAAFSG6uhni4uLdeutt+rll19W+/btFR0dreHDh2vevHkVepyymDJlijw9Pc0lICCguqcEAACA/7qq4LZv376aMGGC3ZcklPj11181ceJE3XXXXRU2OQAAAKAiVUc/27BhQwUHB9uta9GihQ4dOiRJ8vPzk/Tb3cDny87ONsf8/PyUk5NjN37u3DmdOHHCruZC+zj/GL83btw45eXlmcvhw4fLcooAAACoBFf15WTjx4/X8uXLdcsttyg2NlbNmjWTJO3du1dz585VUVGRnn/++UqZKAAAAFBe1dHPdurUSRkZGXbrvv/+ewUGBkr67YvK/Pz8lJKSonbt2kmSbDabNm/erKefflqSFBYWptzcXKWlpSkkJESStHbtWhUXFys0NNSsef7551VYWGg+DiI5OVnNmjVT3bp1Lzg3V1dXubq6Vuj5AgAAoGJcVXDr6+urjRs36umnn9a4ceNkGIYkycHBQREREZo7d26p52oBAAAAVlEd/eyoUaN0xx136OWXX9ZDDz2kLVu2aP78+Zo/f7557JEjR+rFF1/UzTffrKCgIE2YMEH+/v6KioqS9Nsdur179zYfsVBYWKjY2Fj1799f/v7+kqRHHnlEkyZN0rBhwzR27Fjt2rVLs2fP1syZMyv0fAAAAFA1riq4laTAwECtXr1aJ0+e1P79+2UYhm6++eaL/is+AAAAYCVV3c/edttt+uijjzRu3DhNnjxZQUFBmjVrlgYOHGjWjBkzRmfOnFF0dLRyc3PVuXNnJSUlyc3NzaxZtGiRYmNj1bNnTzk6Oqpfv3567bXXzHFPT0+tWbNGMTExCgkJUf369RUfH6/o6OhKOS8AAABULgej5DYDlIvNZpOnp6fy8vLk4eFRpcees+VAlR4PQMWLvb1JdU8BAK4J1dlz/RHQ0wIoD3paALi8q+m3rurLyQAAAAAAAAAAlY/gFgAAAAAAAAAshuAWAAAAAAAAACyG4BYAAAAAAAAALIbgFgAAAAAAAAAshuAWAAAAAAAAACyG4BYAAAAAAAAALIbgFgAAAAAAAAAshuAWAAAAAAAAACyG4BYAAAAAAAAALIbgFgAAAAAAAAAshuAWAAAAAAAAACyG4BYAAAAAAAAALIbgFgAAAAAAAAAshuAWAAAAAAAAACyG4BYAAAAAAAAALIbgFgAAAAAAAAAshuAWAAAAAAAAACyG4BYAAAAAAAAALKZag9sNGzbo7rvvlr+/vxwcHLRixQq7ccMwFB8fr4YNG8rd3V3h4eHat2+fXc2JEyc0cOBAeXh4yMvLS8OGDdPp06ftanbu3KkuXbrIzc1NAQEBmjp1aqm5LFu2TM2bN5ebm5tat26t1atXV/j5AgAAAAAAAMCVqNbg9syZM2rbtq3mzp17wfGpU6fqtdde07x587R582bVqlVLEREROnv2rFkzcOBA7d69W8nJyVq5cqU2bNig6Ohoc9xms6lXr14KDAxUWlqapk2bpoSEBM2fP9+s2bhxowYMGKBhw4Zpx44dioqKUlRUlHbt2lV5Jw8AAAAAAAAAF+FgGIZR3ZOQJAcHB3300UeKioqS9Nvdtv7+/nr22Wf1l7/8RZKUl5cnX19fJSYmqn///tqzZ4+Cg4O1detWdejQQZKUlJSkvn376siRI/L399ebb76p559/XllZWXJxcZEkPffcc1qxYoX27t0rSXr44Yd15swZrVy50pxPx44d1a5dO82bN++K5m+z2eTp6am8vDx5eHhU1GW5InO2HKjS4wGoeLG3N6nuKQDANaE6e64/AnpaAOVBTwsAl3c1/ZZln3GbmZmprKwshYeHm+s8PT0VGhqq1NRUSVJqaqq8vLzM0FaSwsPD5ejoqM2bN5s1Xbt2NUNbSYqIiFBGRoZOnjxp1px/nJKakuMAAAAAAAAAQFVyru4JXExWVpYkydfX1269r6+vOZaVlSUfHx+7cWdnZ3l7e9vVBAUFldpHyVjdunWVlZV1yeNcSH5+vvLz883XNpvtak4PAAAAAAAAAC7KsnfcWt2UKVPk6elpLgEBAdU9JQAAAAAAAADXCcsGt35+fpKk7Oxsu/XZ2dnmmJ+fn3JycuzGz507pxMnTtjVXGgf5x/jYjUl4xcybtw45eXlmcvhw4ev9hQBAAAAAAAA4IIsG9wGBQXJz89PKSkp5jqbzabNmzcrLCxMkhQWFqbc3FylpaWZNWvXrlVxcbFCQ0PNmg0bNqiwsNCsSU5OVrNmzVS3bl2z5vzjlNSUHOdCXF1d5eHhYbcAAAAAAAAAQEWo1uD29OnTSk9PV3p6uqTfvpAsPT1dhw4dkoODg0aOHKkXX3xRn3zyib799lsNHjxY/v7+ioqKkiS1aNFCvXv31vDhw7VlyxZ98803io2NVf/+/eXv7y9JeuSRR+Ti4qJhw4Zp9+7dWrJkiWbPnq24uDhzHn/+85+VlJSk6dOna+/evUpISNC2bdsUGxtb1ZcEAAAAAAAAAKr3y8m2bdumHj16mK9LwtQhQ4YoMTFRY8aM0ZkzZxQdHa3c3Fx17txZSUlJcnNzM7dZtGiRYmNj1bNnTzk6Oqpfv3567bXXzHFPT0+tWbNGMTExCgkJUf369RUfH6/o6Giz5o477tDixYs1fvx4/fWvf9XNN9+sFStWqFWrVlVwFQAAAAAAAADAnoNhGEZ1T+J6YLPZ5Onpqby8vCp/bMKcLQeq9HgAKl7s7U2qewoAcE2ozp7rj4CeFkB50NMCwOVdTb9l2WfcAgAAAAAAAMAfFcEtAAAAAAAAAFgMwS0AAAAAAAAAWAzBLQAAAAAAAABYDMEtAAAAAAAAAFgMwS0AAAAAAAAAWAzBLQAAAAAAAABYDMEtAAAAAAAAAFgMwS0AAAAAAAAAWAzBLQAAAAAAAABYDMEtAAAAAAAAAFgMwS0AAAAAAAAAWAzBLQAAAAAAAABYDMEtAAAAAAAAAFgMwS0AAAAAAAAAWAzBLQAAAAAAAABYDMEtAAAAAAAAAFgMwS0AAAAAAAAAWAzBLQAAAAAAAABYDMEtAAAAAAAAAFgMwS0AAAAAAAAAWAzBLQAAAFCFXnnlFTk4OGjkyJHmurNnzyomJkb16tVT7dq11a9fP2VnZ9ttd+jQIUVGRqpmzZry8fHR6NGjde7cObuadevW6dZbb5Wrq6tuuukmJSYmVsEZAQAAoDIQ3AIAAABVZOvWrfr73/+uNm3a2K0fNWqUPv30Uy1btkzr16/X0aNHdf/995vjRUVFioyMVEFBgTZu3KiFCxcqMTFR8fHxZk1mZqYiIyPVo0cPpaena+TIkXriiSf0+eefV9n5AQAAoOIQ3AIAAABV4PTp0xo4cKD+8Y9/qG7duub6vLw8vf3225oxY4buvPNOhYSEaMGCBdq4caM2bdokSVqzZo2+++47vffee2rXrp369OmjF154QXPnzlVBQYEkad68eQoKCtL06dPVokULxcbG6oEHHtDMmTOr5XwBAABQPgS3AAAAQBWIiYlRZGSkwsPD7danpaWpsLDQbn3z5s3VuHFjpaamSpJSU1PVunVr+fr6mjURERGy2WzavXu3WfP7fUdERJj7AAAAwLXFubonAAAAAFzvPvjgA23fvl1bt24tNZaVlSUXFxd5eXnZrff19VVWVpZZc35oWzJeMnapGpvNpl9//VXu7u6ljp2fn6/8/Hzztc1mu/qTAwAAQKXgjlsAAACgEh0+fFh//vOftWjRIrm5uVX3dOxMmTJFnp6e5hIQEFDdUwIAAMB/EdwCAAAAlSgtLU05OTm69dZb5ezsLGdnZ61fv16vvfaanJ2d5evrq4KCAuXm5tptl52dLT8/P0mSn5+fsrOzS42XjF2qxsPD44J320rSuHHjlJeXZy6HDx+uiFMGAABABeBRCQCAahG04kB1TwFAOWRGNanuKVwzevbsqW+//dZu3dChQ9W8eXONHTtWAQEBqlGjhlJSUtSvXz9JUkZGhg4dOqSwsDBJUlhYmF566SXl5OTIx8dHkpScnCwPDw8FBwebNatXr7Y7TnJysrmPC3F1dZWrq2uFnSsAAAAqDsEtAAAAUInq1KmjVq1a2a2rVauW6tWrZ64fNmyY4uLi5O3tLQ8PDz3zzDMKCwtTx44dJUm9evVScHCwBg0apKlTpyorK0vjx49XTEyMGbw+9dRTmjNnjsaMGaPHH39ca9eu1dKlS7Vq1aqqPWEAAABUCIJbAAAAoJrNnDlTjo6O6tevn/Lz8xUREaE33njDHHdyctLKlSv19NNPKywsTLVq1dKQIUM0efJksyYoKEirVq3SqFGjNHv2bDVq1EhvvfWWIiIiquOUAAAAUE4EtwAAAEAVW7dund1rNzc3zZ07V3Pnzr3oNoGBgaUehfB73bt3144dOypiigCAy+DRX8C1z+qP/+LLyQAAAAAAAADAYghuAQAAAAAAAMBiCG4BAAAAAAAAwGIIbgEAAAAAAADAYghuAQAAAAAAAMBiCG4BAAAAAAAAwGIIbgEAAAAAAADAYghuAQAAAAAAAMBiCG4BAAAAAAAAwGIIbgEAAAAAAADAYghuAQAAAAAAAMBiCG4BAAAAAAAAwGIIbgEAAAAAAADAYghuAQAAAAAAAMBiCG4BAAAAAAAAwGIIbgEAAAAAAADAYghuAQAAAAAAAMBiCG4BAAAAAAAAwGIIbgEAAAAAAADAYghuAQAAAAAAAMBiCG4BAAAAAAAAwGIIbgEAAAAAAADAYghuAQAAAAAAAMBiCG4BAAAAAAAAwGIIbgEAAAAAAADAYghuAQAAAAAAAMBiCG4BAAAAAAAAwGIIbgEAAAAAAADAYghuAQAAAAAAAMBiCG4BAAAAAAAAwGIIbgEAAAAAAADAYghuAQAAAAAAAMBiCG4BAAAAAAAAwGIIbgEAAAAAAADAYghuAQAAAAAAAMBiLB3cJiQkyMHBwW5p3ry5OX727FnFxMSoXr16ql27tvr166fs7Gy7fRw6dEiRkZGqWbOmfHx8NHr0aJ07d86uZt26dbr11lvl6uqqm266SYmJiVVxegAAAAAAAABwQZYObiWpZcuWOnbsmLl8/fXX5tioUaP06aefatmyZVq/fr2OHj2q+++/3xwvKipSZGSkCgoKtHHjRi1cuFCJiYmKj483azIzMxUZGakePXooPT1dI0eO1BNPPKHPP/+8Ss8TAAAAAAAAAEo4V/cELsfZ2Vl+fn6l1ufl5entt9/W4sWLdeedd0qSFixYoBYtWmjTpk3q2LGj1qxZo++++05ffPGFfH191a5dO73wwgsaO3asEhIS5OLionnz5ikoKEjTp0+XJLVo0UJff/21Zs6cqYiIiCo9VwAAAAAAAACQroE7bvft2yd/f3/deOONGjhwoA4dOiRJSktLU2FhocLDw83a5s2bq3HjxkpNTZUkpaamqnXr1vL19TVrIiIiZLPZtHv3brPm/H2U1JTsAwAAAAAAAACqmqXvuA0NDVViYqKaNWumY8eOadKkSerSpYt27dqlrKwsubi4yMvLy24bX19fZWVlSZKysrLsQtuS8ZKxS9XYbDb9+uuvcnd3v+Dc8vPzlZ+fb7622WzlOlcAAAAAAAAAKGHp4LZPnz7mf7dp00ahoaEKDAzU0qVLLxqoVpUpU6Zo0qRJ1ToHAAAAAAAAANcnyz8q4XxeXl665ZZbtH//fvn5+amgoEC5ubl2NdnZ2eYzcf38/JSdnV1qvGTsUjUeHh6XDIfHjRunvLw8czl8+HB5Tw8AAAAAAAAAJF1jwe3p06f1ww8/qGHDhgoJCVGNGjWUkpJijmdkZOjQoUMKCwuTJIWFhenbb79VTk6OWZOcnCwPDw8FBwebNefvo6SmZB8X4+rqKg8PD7sFAAAAAAAAACqCpYPbv/zlL1q/fr0OHDigjRs36r777pOTk5MGDBggT09PDRs2THFxcfryyy+VlpamoUOHKiwsTB07dpQk9erVS8HBwRo0aJD+/e9/6/PPP9f48eMVExMjV1dXSdJTTz2lH3/8UWPGjNHevXv1xhtvaOnSpRo1alR1njoAAAAAAACAPzBLP+P2yJEjGjBggH7++Wc1aNBAnTt31qZNm9SgQQNJ0syZM+Xo6Kh+/fopPz9fEREReuONN8ztnZyctHLlSj399NMKCwtTrVq1NGTIEE2ePNmsCQoK0qpVqzRq1CjNnj1bjRo10ltvvaWIiIgqP18AAAAAAAAAkCwe3H7wwQeXHHdzc9PcuXM1d+7ci9YEBgZq9erVl9xP9+7dtWPHjjLNEQAAAAAAAAAqmqUflQAAAAAAAAAAf0QEtwAAAAAAAABgMQS3AAAAAAAAAGAxBLcAAAAAAAAAYDEEtwAAAAAAAABgMQS3AAAAQCWaMmWKbrvtNtWpU0c+Pj6KiopSRkaGXc3Zs2cVExOjevXqqXbt2urXr5+ys7Ptag4dOqTIyEjVrFlTPj4+Gj16tM6dO2dXs27dOt16661ydXXVTTfdpMTExMo+PQAAAFQSglsAAACgEq1fv14xMTHatGmTkpOTVVhYqF69eunMmTNmzahRo/Tpp59q2bJlWr9+vY4ePar777/fHC8qKlJkZKQKCgq0ceNGLVy4UImJiYqPjzdrMjMzFRkZqR49eig9PV0jR47UE088oc8//7xKzxcAAAAVw7m6JwAAAABcz5KSkuxeJyYmysfHR2lpaeratavy8vL09ttva/HixbrzzjslSQsWLFCLFi20adMmdezYUWvWrNF3332nL774Qr6+vmrXrp1eeOEFjR07VgkJCXJxcdG8efMUFBSk6dOnS5JatGihr7/+WjNnzlRERESVnzcAAADKhztuAQAAgCqUl5cnSfL29pYkpaWlqbCwUOHh4WZN8+bN1bhxY6WmpkqSUlNT1bp1a/n6+po1ERERstls2r17t1lz/j5Kakr2AQAAgGsLd9wCAAAAVaS4uFgjR45Up06d1KpVK0lSVlaWXFxc5OXlZVfr6+urrKwss+b80LZkvGTsUjU2m02//vqr3N3dS80nPz9f+fn55mubzVa+EwQAAECF4Y5bAAAAoIrExMRo165d+uCDD6p7KpJ+++I0T09PcwkICKjuKQEAAOC/CG4BAACAKhAbG6uVK1fqyy+/VKNGjcz1fn5+KigoUG5url19dna2/Pz8zJrs7OxS4yVjl6rx8PC44N22kjRu3Djl5eWZy+HDh8t1jgAAAKg4BLcAAABAJTIMQ7Gxsfroo4+0du1aBQUF2Y2HhISoRo0aSklJMddlZGTo0KFDCgsLkySFhYXp22+/VU5OjlmTnJwsDw8PBQcHmzXn76OkpmQfF+Lq6ioPDw+7BQAAANbAM24BAACAShQTE6PFixfr448/Vp06dcxn0np6esrd3V2enp4aNmyY4uLi5O3tLQ8PDz3zzDMKCwtTx44dJUm9evVScHCwBg0apKlTpyorK0vjx49XTEyMXF1dJUlPPfWU5syZozFjxujxxx/X2rVrtXTpUq1atarazh0AAABlxx23AAAAQCV68803lZeXp+7du6thw4bmsmTJErNm5syZuuuuu9SvXz917dpVfn5+Wr58uTnu5OSklStXysnJSWFhYXr00Uc1ePBgTZ482awJCgrSqlWrlJycrLZt22r69Ol66623FBERUaXnCwAAgIrBHbcAAABAJTIM47I1bm5umjt3rubOnXvRmsDAQK1evfqS++nevbt27Nhx1XMEAACA9XDHLQAAAAAAAABYDMEtAAAAAAAAAFgMwS0AAAAAAAAAWAzBLQAAAAAAAABYDMEtAAAAAAAAAFgMwS0AAAAAAAAAWAzBLQAAAAAAAABYDMEtAAAAAAAAAFgMwS0AAAAAAAAAWAzBLQAAAAAAAABYDMEtAAAAAAAAAFgMwS0AAAAAAAAAWAzBLQAAAAAAAABYDMEtAAAAAAAAAFgMwS0AAAAAAAAAWAzBLQAAAAAAAABYDMEtAAAAAAAAAFgMwS0AAAAAAAAAWAzBLQAAAAAAAABYDMEtAAAAAAAAAFgMwS0AAAAAAAAAWAzBLQAAAAAAAABYDMEtAAAAAAAAAFgMwS0AAAAAAAAAWAzBLQAAAAAAAABYDMEtAAAAAAAAAFgMwS0AAAAAAAAAWAzBLQAAAAAAAABYDMEtAAAAAAAAAFgMwS0AAAAAAAAAWAzBLQAAAAAAAABYDMEtAAAAAAAAAFgMwS0AAAAAAAAAWAzBLQAAAAAAAABYDMEtAAAAAAAAAFgMwS0AAAAAAAAAWAzBLQAAAAAAAABYDMEtAAAAAAAAAFgMwS0AAAAAAAAAWAzBLQAAAAAAAABYDMEtAAAAAAAAAFgMwS0AAAAAAAAAWAzBLQAAAAAAAABYDMEtAAAAAAAAAFgMwS0AAAAAAAAAWAzBLQAAAAAAAABYDMEtAAAAAAAAAFgMwS0AAAAAAAAAWAzBLQAAAAAAAABYDMEtAAAAAAAAAFgMwS0AAAAAAAAAWAzB7e/MnTtXTZo0kZubm0JDQ7Vly5bqnhIAAABwxehnAQAArg8Et+dZsmSJ4uLiNHHiRG3fvl1t27ZVRESEcnJyqntqAAAAwGXRzwIAAFw/CG7PM2PGDA0fPlxDhw5VcHCw5s2bp5o1a+qdd96p7qkBAAAAl0U/CwAAcP0guP2vgoICpaWlKTw83Fzn6Oio8PBwpaamVuPMAAAAgMujnwUAALi+OFf3BKziP//5j4qKiuTr62u33tfXV3v37i1Vn5+fr/z8fPN1Xl6eJMlms1XuRC/g19OnqvyYACpWdbx3VLfiX3jvAq5l1fW+VXJcwzCq5fhWdrX9rERPC6Bi/dF6WvpZ4NpXHe9bV9PPEtyW0ZQpUzRp0qRS6wMCAqphNgCudWOqewIAcJU8q/n4p06dkqdndc/i2kdPC6Ai0dMCuNZUZzd5Jf0swe1/1a9fX05OTsrOzrZbn52dLT8/v1L148aNU1xcnPm6uLhYJ06cUL169eTg4FDp88Ufh81mU0BAgA4fPiwPD4/qng4AXBbvW6hMhmHo1KlT8vf3r+6pWM7V9rMSPS2qDn83ALjW8L6FynI1/SzB7X+5uLgoJCREKSkpioqKkvRb45qSkqLY2NhS9a6urnJ1dbVb5+XlVQUzxR+Vh4cHf1kAuKbwvoXKwp22F3a1/axET4uqx98NAK41vG+hMlxpP0twe564uDgNGTJEHTp00O23365Zs2bpzJkzGjp0aHVPDQAAALgs+lkAAIDrB8HteR5++GEdP35c8fHxysrKUrt27ZSUlFTqCx4AAAAAK6KfBQAAuH4Q3P5ObGzsRT9KBlQHV1dXTZw4sdTHGAHAqnjfAqoX/SysiL8bAFxreN+CFTgYhmFU9yQAAAAAAAAAAP/jWN0TAAAAAAAAAADYI7gFAAAAAAAAAIshuAUAAAAAAAAAiyG4Ba4hTZo0kYODg93yyiuv2NXs3LlTXbp0kZubmwICAjR16lS78YSEBLVr185u3VdffSUvLy+NHDlSPPYaQFkkJCSUen9q3ry5Xc3Zs2cVExOjevXqqXbt2urXr5+ys7PN8QMHDsjBwUHp6enmulOnTqlHjx4KDg7WkSNHqup0AAAVjD4WgFXRx8LKCG6BKlRcXKyffvqpXPuYPHmyjh07Zi7PPPOMOWaz2dSrVy8FBgYqLS1N06ZNU0JCgubPn3/R/a1atUoRERGKi4vTrFmz5ODgUK75Abg+nD17VsePH7+qbVq2bGn3/vT111/bjY8aNUqffvqpli1bpvXr1+vo0aO6//77L7q/48ePq0ePHjpz5oy++uorNWrUqEznAgAoP/pYANcK+lhcTwhugSqwd+9ejRs3To0bN9arr75arn3VqVNHfn5+5lKrVi1zbNGiRSooKNA777yjli1bqn///hoxYoRmzJhxwX0tXrxY999/v6ZOnar4+PhyzQvA9SU7O1s33HCDoqKi9NFHH6mwsPCy2zg7O9u9P9WvX98cy8vL09tvv60ZM2bozjvvVEhIiBYsWKCNGzdq06ZNpfZ1+PBhdenSRZ6enlq7dq3q1atXoecHALgy9LEArjX0sbieENwCleTkyZN688031bFjR7Vq1Urbt2/XK6+8opdeesmsefnll1W7du1LLocOHbLb7yuvvKJ69eqpffv2mjZtms6dO2eOpaamqmvXrnJxcTHXRUREKCMjQydPnrTbz9y5czV06FC98847io2NraSrAOBaFRgYqNTUVAUGBurJJ59Uw4YNNWLECKWlpV10m3379snf31833nijBg4caPf+lZaWpsLCQoWHh5vrmjdvrsaNGys1NdVuPxkZGerUqZOCg4O1evVq1a5du+JPEABwUfSxAK5l9LG4njhX9wSA60lxcbE+++wzLVy4UJ988oluueUWDRo0SB999JEaNmxYqv6pp57SQw89dMl9+vv7m/89YsQI3XrrrfL29tbGjRs1btw4HTt2zLwTISsrS0FBQXbb+/r6mmN169aVJO3Zs0exsbF6++23NXDgwHKdM4DrV0hIiEJCQjR9+nR99tlnevfdd9WpUyfdfPPNGjJkiAYNGmS+x4SGhioxMVHNmjXTsWPHNGnSJHXp0kW7du1SnTp1lJWVJRcXF3l5edkdw9fXV1lZWXbrBg8erE6dOmnZsmVycnKqqtMFgD80+lgA1xP6WFwvCG6BCnTo0CHdddddqlu3rt5//33dd999l6z39vaWt7f3Fe8/Li7O/O82bdrIxcVFTz75pKZMmSJXV9cr3k+jRo3k5eWladOmqU+fPhdsxgGghLOzs+6++27dfffdOnbsmAYPHqzRo0fryJEjmjVrliSpT58+Zn2bNm0UGhqqwMBALV26VMOGDbuq491zzz1asWKFli9frgcffLAiTwUAcBH0sQCuR/SxuNbxqASgAjVq1Ejvv/++QkND9dBDD6lr1676xz/+odzc3AvWl+UjZucLDQ3VuXPndODAAUmSn5+f3TdbSjJf+/n5mevq1KmjL774QrVq1VKPHj107Nix8p04gOuaYRjasGGDhg8frhYtWmj//v2Kj4+3+z/hv+fl5aVbbrlF+/fvl/Tbe1BBQUGp98Ps7Gy79ydJev755xUfH69HHnlES5curfDzAQCURh8L4HpEH4trHcEtUIGcnZ3Vv39/ffbZZ+ZdC7NmzZKfn58efPBBffLJJ3YPRn/qqaeUnp5+yeX8j5j9Xnp6uhwdHeXj4yNJCgsL04YNG+yOkZycrGbNmpkfLytRt25dffHFF/Lw8FD37t119OjRCr4aAK5133//vSZMmKAbb7xRkZGROnfunFasWKEff/xRkyZNUuPGjS+67enTp/XDDz+Yd0KFhISoRo0aSklJMWsyMjJ06NAhhYWFldp+woQJSkhI0MCBA7VkyZKKPzkAgB36WADXE/pYXDcMAJVu69atRkxMjFGvXj0jLi6uTPvYuHGjMXPmTCM9Pd344YcfjPfee89o0KCBMXjwYLMmNzfX8PX1NQYNGmTs2rXL+OCDD4yaNWsaf//7382aiRMnGm3btrXbJjQ01Lj55puNn376qcznCOD6cvDgQcPR0dG48847jYULFxqnT5++ZP2zzz5rrFu3zsjMzDS++eYbIzw83Khfv76Rk5Nj1jz11FNG48aNjbVr1xrbtm0zwsLCjLCwMHM8MzPTkGTs2LHDXDdlyhTDycnJWLx4cYWfIwDg8q61Pnb58uVGs2bNynayAK4LVu5jmzVrZixfvrziThbXPZ5xC1SBDh06qEOHDpoxY4aOHDlSpn24urrqgw8+UEJCgvLz8xUUFKRRo0bZfcTD09NTa9asUUxMjEJCQlS/fn3Fx8crOjr6ovst2aZ3797q1q2b1q1bpxtuuKFMcwRw/ahfv74yMzMveTfC+Y4cOaIBAwbo559/VoMGDdS5c2dt2rRJDRo0MGtmzpwpR0dH9evXT/n5+YqIiNAbb7xxyf0+99xzcnR01KBBg2QYhh555JFynRcA4Opca31sXl6eMjIyyjRPANcHK/exGRkZysvLK9f54Y/FwTAMo7onAQAAAAAAAAD4H55xCwAAAAAAAAAWQ3ALAAAAAAAAABZDcAsAAAAAAAAAFkNwCwAAAAAAAAAWQ3ALAAAAAAAAABZDcAsAAAAAAAAAFkNwCwAAAAAAAAAWQ3ALAAAAAAAAABZDcAsAAAAAAAAAFkNwCwAW9thjjykqKqq6pwEAAACUGT0tAJQNwS0AAAAAAAAAWAzBLQBcI7p3764RI0ZozJgx8vb2lp+fnxISEuxqcnNz9eSTT8rX11dubm5q1aqVVq5caY7/61//UsuWLeXq6qomTZpo+vTpdts3adJEL774ogYPHqzatWsrMDBQn3zyiY4fP657771XtWvXVps2bbRt2za77b7++mt16dJF7u7uCggI0IgRI3TmzJlKuxYAAAC4NtHTAsCVI7gFgGvIwoULVatWLW3evFlTp07V5MmTlZycLEkqLi5Wnz599M033+i9997Td999p1deeUVOTk6SpLS0ND300EPq37+/vv32WyUkJGjChAlKTEy0O8bMmTPVqVMn7dixQ5GRkRo0aJAGDx6sRx99VNu3b1fTpk01ePBgGYYhSfrhhx/Uu3dv9evXTzt37tSSJUv09ddfKzY2tkqvDQAAAK4N9LQAcGUcjJJ3KQCA5Tz22GPKzc3VihUr1L17dxUVFemrr74yx2+//XbdeeedeuWVV7RmzRr16dNHe/bs0S233FJqXwMHDtTx48e1Zs0ac92YMWO0atUq7d69W9Jvdyd06dJF//znPyVJWVlZatiwoSZMmKDJkydLkjZt2qSwsDAdO3ZMfn5+euKJJ+Tk5KS///3v5n6//vprdevWTWfOnJGbm1ulXBsAAABcG+hpAaBsuOMWAK4hbdq0sXvdsGFD5eTkSJLS09PVqFGjCza4krRnzx516tTJbl2nTp20b98+FRUVXfAYvr6+kqTWrVuXWldy3H//+99KTExU7dq1zSUiIkLFxcXKzMws66kCAADgOkVPCwBXxrm6JwAAuHI1atSwe+3g4KDi4mJJkru7e4Ufw8HB4aLrSo57+vRpPfnkkxoxYkSpfTVu3LhC5gQAAIDrBz0tAFwZglsAuE60adNGR44c0ffff3/BOxRatGihb775xm7dN998o1tuucV8ZlhZ3Hrrrfruu+900003lXkfAAAAgERPCwDn41EJAHCd6Natm7p27ap+/fopOTlZmZmZ+uyzz5SUlCRJevbZZ5WSkqIXXnhB33//vRYuXKg5c+boL3/5S7mOO3bsWG3cuFGxsbFKT0/Xvn379PHHH/NFDgAAALhq9LQA8D8EtwBwHfnXv/6l2267TQMGDFBwcLDGjBljPuvr1ltv1dKlS/XBBx+oVatWio+P1+TJk/XYY4+V65ht2rTR+vXr9f3336tLly5q37694uPj5e/vXwFnBAAAgD8aeloA+I2DYRhGdU8CAAAAAAAAAPA/3HELAAAAAAAAABZDcAsAAAAAAAAAFkNwCwAAAAAAAAAWQ3ALAAAAAAAAABZDcAsAAAAAAAAAFkNwCwAAAAAAAAAWQ3ALAAAAAAAAABZDcAsAAAAAAAAAFkNwCwAAAAAAAAAWQ3ALAAAAAAAAABZDcAsAAAAAAAAAFkNwCwAAAAAAAAAW8/8wn91gId189wAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Model 1: imbalanced dataset and One Hot Encoding\n",
        "'''\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "\n",
        "# Function to preprocess data\n",
        "def preprocess_data(data, transformer=None, is_train=True):\n",
        "    print(\"Initial columns:\", data.columns)  # Initial check of all columns in the dataset\n",
        "\n",
        "    income_column = 'income'\n",
        "    if income_column not in data.columns:\n",
        "        raise ValueError(f\"The column '{income_column}' does not exist in the dataset.\")\n",
        "\n",
        "    # If it's test data, handle the period at the end\n",
        "    if not is_train:\n",
        "        # Convert values to strings before applying string methods\n",
        "        data[income_column] = data[income_column].astype(str).str.strip().str.replace('.', '')\n",
        "        print(\"Adjusted 'income' for test data:\", data[income_column].unique())\n",
        "\n",
        "    # Identify and store categorical features excluding 'income'\n",
        "    categorical_features = data.select_dtypes(include=['object']).columns.tolist()\n",
        "    if income_column in categorical_features:\n",
        "        categorical_features.remove(income_column)\n",
        "    print(\"Categorical features before encoding:\", categorical_features)\n",
        "\n",
        "    # Apply ColumnTransformer only to categorical features excluding 'income'\n",
        "    if transformer is None:\n",
        "        transformer = ColumnTransformer(\n",
        "            transformers=[('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)],\n",
        "            remainder='passthrough')\n",
        "        X = transformer.fit_transform(data.drop(columns=[income_column]))\n",
        "    else:\n",
        "        X = transformer.transform(data.drop(columns=[income_column]))\n",
        "\n",
        "    # Now encode the 'income' column after categorical handling\n",
        "    y = LabelEncoder().fit_transform(data[income_column])\n",
        "    print(\"Encoded 'income':\", np.unique(y))\n",
        "\n",
        "    return X, y, transformer\n",
        "\n",
        "\n",
        "# Function to train the Random Forest model\n",
        "def train_random_forest(X, y):\n",
        "    model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "    model.fit(X, y)\n",
        "\n",
        "    return model\n",
        "\n",
        "# Evaluate the model\n",
        "def evaluate_model(model, X, y):\n",
        "    y_pred = model.predict(X)\n",
        "    accuracy = accuracy_score(y, y_pred)\n",
        "    report = classification_report(y, y_pred)\n",
        "\n",
        "    return accuracy, report\n",
        "\n",
        "# Main execution function\n",
        "def main():\n",
        "    # Preprocess training data\n",
        "    X_train, y_train, transformer = preprocess_data(train_data, is_train=True)\n",
        "\n",
        "    # Train model without SMOTE\n",
        "    model = train_random_forest(X_train, y_train)\n",
        "\n",
        "    # Preprocess testing data using the same transformer\n",
        "    X_test, y_test, _ = preprocess_data(test_data, transformer, is_train=False)\n",
        "\n",
        "    # Evaluate the test model\n",
        "    accuracy_test, report_test = evaluate_model(model, X_test, y_test)\n",
        "    print(f'Accuracy (Test Data): {accuracy_test}')\n",
        "    print(f'Classification Report (Test Data):\\n{report_test}')\n",
        "\n",
        "    # Evaluate the training model to check for overfitting\n",
        "    accuracy_train, report_train = evaluate_model(model, X_train, y_train)\n",
        "    print(f'Accuracy (Training Data): {accuracy_train}')\n",
        "    print(f'Classification Report (Training Data):\\n{report_train}')\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()\n"
      ],
      "metadata": {
        "id": "TVcTc1YG0jVb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9c98ecf4-9c19-4a5d-e854-e2aea390cfe5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial columns: Index(['Unnamed: 0', 'age', 'work-class', 'fnlwgt', 'education_num',\n",
            "       'marital-status', 'relationship', 'race', 'sex', 'capital-gain',\n",
            "       'capital-loss', 'hours-worked-per-week', 'native-country', 'occupation',\n",
            "       'income'],\n",
            "      dtype='object')\n",
            "Categorical features before encoding: []\n",
            "Encoded 'income': [0 1]\n",
            "Initial columns: Index(['Unnamed: 0', 'age', 'work-class', 'fnlwgt', 'education_num',\n",
            "       'marital-status', 'relationship', 'race', 'sex', 'capital-gain',\n",
            "       'capital-loss', 'hours-worked-per-week', 'native-country', 'occupation',\n",
            "       'income'],\n",
            "      dtype='object')\n",
            "Adjusted 'income' for test data: ['0' '1']\n",
            "Categorical features before encoding: []\n",
            "Encoded 'income': [0 1]\n",
            "Accuracy (Test Data): 0.861249309010503\n",
            "Classification Report (Test Data):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.94      0.91     12435\n",
            "           1       0.77      0.59      0.67      3846\n",
            "\n",
            "    accuracy                           0.86     16281\n",
            "   macro avg       0.82      0.77      0.79     16281\n",
            "weighted avg       0.86      0.86      0.85     16281\n",
            "\n",
            "Accuracy (Training Data): 1.0\n",
            "Classification Report (Training Data):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00     24720\n",
            "           1       1.00      1.00      1.00      7841\n",
            "\n",
            "    accuracy                           1.00     32561\n",
            "   macro avg       1.00      1.00      1.00     32561\n",
            "weighted avg       1.00      1.00      1.00     32561\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DMxm_vjjcTWh",
        "outputId": "c91c3d3b-42f4-4bf8-a9e1-e6c85c5db7e8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial columns: Index(['Unnamed: 0', 'age', 'work-class', 'fnlwgt', 'education_num',\n",
            "       'marital-status', 'relationship', 'race', 'sex', 'capital-gain',\n",
            "       'capital-loss', 'hours-worked-per-week', 'native-country', 'occupation',\n",
            "       'income'],\n",
            "      dtype='object')\n",
            "Categorical features before encoding: []\n",
            "Encoded 'income': [0 1]\n",
            "Initial columns: Index(['Unnamed: 0', 'age', 'work-class', 'fnlwgt', 'education_num',\n",
            "       'marital-status', 'relationship', 'race', 'sex', 'capital-gain',\n",
            "       'capital-loss', 'hours-worked-per-week', 'native-country', 'occupation',\n",
            "       'income'],\n",
            "      dtype='object')\n",
            "Adjusted 'income' for test data: ['0' '1']\n",
            "Categorical features before encoding: []\n",
            "Encoded 'income': [0 1]\n",
            "Accuracy test: 0.8538173330876482\n",
            "Classification Report test:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      0.92      0.91     12435\n",
            "           1       0.71      0.65      0.68      3846\n",
            "\n",
            "    accuracy                           0.85     16281\n",
            "   macro avg       0.80      0.78      0.79     16281\n",
            "weighted avg       0.85      0.85      0.85     16281\n",
            "\n",
            "Accuracy train: 0.9999692884125181\n",
            "Classification Report train:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00     24720\n",
            "           1       1.00      1.00      1.00      7841\n",
            "\n",
            "    accuracy                           1.00     32561\n",
            "   macro avg       1.00      1.00      1.00     32561\n",
            "weighted avg       1.00      1.00      1.00     32561\n",
            "\n"
          ]
        }
      ],
      "source": [
        "'''\n",
        "Model 2: Balanced dataset (SMOTE) and One Hot Encoding\n",
        "'''\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "\n",
        "# Assuming train_data and test_data are already loaded as dataframes\n",
        "# train_data, test_data\n",
        "\n",
        "# Function to preprocess data\n",
        "\n",
        "def preprocess_data(data, transformer=None, is_train=True):\n",
        "    print(\"Initial columns:\", data.columns)  # Initial check of all columns in the dataset\n",
        "\n",
        "    income_column = 'income'\n",
        "    if income_column not in data.columns:\n",
        "        raise ValueError(f\"The column '{income_column}' does not exist in the dataset.\")\n",
        "\n",
        "    # If it's test data, handle the period at the end\n",
        "    if not is_train:\n",
        "        data[income_column] = data[income_column].str.strip().str.replace('.', '')\n",
        "        print(\"Adjusted 'income' for test data:\", data[income_column].unique())  # Debug\n",
        "\n",
        "    # Identify and store categorical features excluding 'income'\n",
        "    categorical_features = data.select_dtypes(include=['object']).columns.tolist()\n",
        "    if income_column in categorical_features:\n",
        "        categorical_features.remove(income_column)\n",
        "    print(\"Categorical features before encoding:\", categorical_features)  # Debug statement\n",
        "\n",
        "    # Apply ColumnTransformer only to categorical features excluding 'income'\n",
        "    if transformer is None:\n",
        "        transformer = ColumnTransformer(\n",
        "            transformers=[('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)],\n",
        "            remainder='passthrough')\n",
        "        X = transformer.fit_transform(data.drop(columns=[income_column]))\n",
        "    else:\n",
        "        X = transformer.transform(data.drop(columns=[income_column]))\n",
        "\n",
        "    # Now encode the 'income' column after categorical handling\n",
        "    y = LabelEncoder().fit_transform(data[income_column])\n",
        "    print(\"Encoded 'income':\", np.unique(y))  # Debug the output of the encoded income\n",
        "\n",
        "    return X, y, transformer\n",
        "\n",
        "\n",
        "# Function to train the Random Forest model with SMOTE\n",
        "def train_random_forest_with_smote(X, y):\n",
        "    # Apply SMOTE\n",
        "    smote = SMOTE(random_state=42)\n",
        "    X_smote, y_smote = smote.fit_resample(X, y)\n",
        "\n",
        "    # Train the Random Forest\n",
        "    model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "    model.fit(X_smote, y_smote)\n",
        "\n",
        "    return model\n",
        "\n",
        "# Evaluate the model\n",
        "def evaluate_model(model, X_test, y_test):\n",
        "    y_pred = model.predict(X_test)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    report = classification_report(y_test, y_pred)\n",
        "\n",
        "    return accuracy, report\n",
        "\n",
        "# Main execution function\n",
        "def main():\n",
        "    # Preprocess training data\n",
        "    X_train, y_train, transformer = preprocess_data(train_data, is_train=True)\n",
        "\n",
        "    # Train model with SMOTE\n",
        "    smote = SMOTE(random_state=42)\n",
        "    X_smote, y_smote = smote.fit_resample(X_train, y_train)\n",
        "    model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "    model.fit(X_smote, y_smote)\n",
        "\n",
        "    # Preprocess testing data using the same transformer\n",
        "    X_test, y_test, _ = preprocess_data(test_data, transformer, is_train=False)\n",
        "\n",
        "    # Evaluate the test model\n",
        "    accuracy, report = evaluate_model(model, X_test, y_test)\n",
        "    print(f'Accuracy test: {accuracy}')\n",
        "    print(f'Classification Report test:\\n{report}')\n",
        "\n",
        "    # Evaluate the test model\n",
        "    accuracy_train, report_train = evaluate_model(model, X_train, y_train)\n",
        "    print(f'Accuracy train: {accuracy_train}')\n",
        "    print(f'Classification Report train:\\n{report_train}')\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Initial columns: Index(['age', 'work-class', 'fnlwgt', 'education', 'education_num',\n",
        "       'marital-status', 'occupation', 'relationship', 'race', 'sex',\n",
        "       'capital-gain', 'capital-loss', 'hours-worked-per-week',\n",
        "       'native-country', 'income'],\n",
        "      dtype='object')\n",
        "Categorical features before encoding: []\n",
        "Encoded 'income': [0 1]\n",
        "Initial columns: Index(['age', 'work-class', 'fnlwgt', 'education', 'education_num',\n",
        "       'marital-status', 'occupation', 'relationship', 'race', 'sex',\n",
        "       'capital-gain', 'capital-loss', 'hours-worked-per-week',\n",
        "       'native-country', 'income'],\n",
        "      dtype='object')\n",
        "Adjusted 'income' for test data: ['<=50K' '>50K']\n",
        "Categorical features before encoding: []\n",
        "Encoded 'income': [0 1]\n",
        "Accuracy test: 0.8431914501566243\n",
        "Classification Report test:\n",
        "              precision    recall  f1-score   support\n",
        "\n",
        "           0       0.90      0.90      0.90     12435\n",
        "           1       0.67      0.67      0.67      3846\n",
        "\n",
        "    accuracy                           0.84     16281\n",
        "   macro avg       0.78      0.78      0.78     16281\n",
        "weighted avg       0.84      0.84      0.84     16281\n",
        "\n",
        "Accuracy train: 0.9999385768250361\n",
        "Classification Report train:\n",
        "              precision    recall  f1-score   support\n",
        "\n",
        "           0       1.00      1.00      1.00     24720\n",
        "           1       1.00      1.00      1.00      7841\n",
        "\n",
        "    accuracy                           1.00     32561\n",
        "   macro avg       1.00      1.00      1.00     32561\n",
        "weighted avg       1.00      1.00      1.00     32561"
      ],
      "metadata": {
        "id": "8DaHWsee-fLa"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yuDT5SIupHDp",
        "outputId": "e89f9d1f-be45-42c8-d3ea-e21d587b7263"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial columns: Index(['age', 'work-class', 'fnlwgt', 'education', 'education_num',\n",
            "       'marital-status', 'occupation', 'relationship', 'race', 'sex',\n",
            "       'capital-gain', 'capital-loss', 'hours-worked-per-week',\n",
            "       'native-country', 'income'],\n",
            "      dtype='object')\n",
            "'fnlwgt' column dropped.\n",
            "Categorical features before encoding: ['work-class', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'native-country']\n",
            "Encoded 'income': [0 1]\n",
            "Initial columns: Index(['age', 'work-class', 'fnlwgt', 'education', 'education_num',\n",
            "       'marital-status', 'occupation', 'relationship', 'race', 'sex',\n",
            "       'capital-gain', 'capital-loss', 'hours-worked-per-week',\n",
            "       'native-country', 'income'],\n",
            "      dtype='object')\n",
            "'fnlwgt' column dropped.\n",
            "Adjusted 'income' for test data: ['<=50K' '>50K']\n",
            "Categorical features before encoding: ['work-class', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'native-country']\n",
            "Encoded 'income': [0 1]\n",
            "Accuracy: 0.839690436705362\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      0.91      0.90     12435\n",
            "           1       0.68      0.62      0.65      3846\n",
            "\n",
            "    accuracy                           0.84     16281\n",
            "   macro avg       0.78      0.76      0.77     16281\n",
            "weighted avg       0.84      0.84      0.84     16281\n",
            "\n"
          ]
        }
      ],
      "source": [
        "'''\n",
        "One Hot Encoding Implementation # removing fnlweight column, version 2\n",
        "# Version 2\n",
        "\n",
        "Outcome: less precision\n",
        "'''\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "\n",
        "# Assuming train_data and test_data are already loaded as dataframes\n",
        "# train_data, test_data\n",
        "\n",
        "# Function to preprocess data\n",
        "\n",
        "def preprocess_data(data, transformer=None, is_train=True):\n",
        "    print(\"Initial columns:\", data.columns)  # Initial check of all columns in the dataset\n",
        "\n",
        "    income_column = 'income'\n",
        "    fnlwgt_column = 'fnlwgt'  # Define the column name to be dropped\n",
        "\n",
        "    if income_column not in data.columns:\n",
        "        raise ValueError(f\"The column '{income_column}' does not exist in the dataset.\")\n",
        "\n",
        "    # Drop the 'fnlwgt' column from the dataset\n",
        "    if fnlwgt_column in data.columns:\n",
        "        data = data.drop(columns=[fnlwgt_column])\n",
        "        print(f\"'{fnlwgt_column}' column dropped.\")\n",
        "    else:\n",
        "        print(f\"No '{fnlwgt_column}' column to drop.\")\n",
        "\n",
        "    # If it's test data, handle the period at the end\n",
        "    if not is_train:\n",
        "        data[income_column] = data[income_column].str.strip().str.replace('.', '')\n",
        "        print(\"Adjusted 'income' for test data:\", data[income_column].unique())  # Debug\n",
        "\n",
        "    # Identify and store categorical features excluding 'income'\n",
        "    categorical_features = data.select_dtypes(include=['object']).columns.tolist()\n",
        "    if income_column in categorical_features:\n",
        "        categorical_features.remove(income_column)\n",
        "    print(\"Categorical features before encoding:\", categorical_features)  # Debug statement\n",
        "\n",
        "    # Apply ColumnTransformer only to categorical features excluding 'income'\n",
        "    if transformer is None:\n",
        "        transformer = ColumnTransformer(\n",
        "            transformers=[('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)],\n",
        "            remainder='passthrough')\n",
        "        X = transformer.fit_transform(data.drop(columns=[income_column]))\n",
        "    else:\n",
        "        X = transformer.transform(data.drop(columns=[income_column]))\n",
        "\n",
        "    # Now encode the 'income' column after categorical handling\n",
        "    y = LabelEncoder().fit_transform(data[income_column])\n",
        "    print(\"Encoded 'income':\", np.unique(y))  # Debug the output of the encoded income\n",
        "\n",
        "    return X, y, transformer\n",
        "\n",
        "# Function to train the Random Forest model with SMOTE\n",
        "def train_random_forest_with_smote(X, y):\n",
        "    # Apply SMOTE\n",
        "    smote = SMOTE(random_state=42)\n",
        "    X_smote, y_smote = smote.fit_resample(X, y)\n",
        "\n",
        "    # Train the Random Forest\n",
        "    model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "    model.fit(X_smote, y_smote)\n",
        "\n",
        "    return model\n",
        "\n",
        "# Evaluate the model\n",
        "def evaluate_model(model, X_test, y_test):\n",
        "    y_pred = model.predict(X_test)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    report = classification_report(y_test, y_pred)\n",
        "\n",
        "    return accuracy, report\n",
        "\n",
        "# Main execution function\n",
        "def main():\n",
        "    # Preprocess training data\n",
        "    X_train, y_train, transformer = preprocess_data(train_data, is_train=True)\n",
        "\n",
        "    # Train model with SMOTE\n",
        "    smote = SMOTE(random_state=42)\n",
        "    X_smote, y_smote = smote.fit_resample(X_train, y_train)\n",
        "    model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "    model.fit(X_smote, y_smote)\n",
        "\n",
        "    # Preprocess testing data using the same transformer\n",
        "    X_test, y_test, _ = preprocess_data(test_data, transformer, is_train=False)\n",
        "\n",
        "    # Evaluate the model\n",
        "    accuracy, report = evaluate_model(model, X_test, y_test)\n",
        "    print(f'Accuracy: {accuracy}')\n",
        "    print(f'Classification Report:\\n{report}')\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Initial columns: Index(['age', 'work-class', 'fnlwgt', 'education', 'education_num',\n",
        "       'marital-status', 'occupation', 'relationship', 'race', 'sex',\n",
        "       'capital-gain', 'capital-loss', 'hours-worked-per-week',\n",
        "       'native-country', 'income'],\n",
        "      dtype='object')\n",
        "'fnlwgt' column dropped.\n",
        "Categorical features before encoding: ['work-class', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'native-country']\n",
        "Encoded 'income': [0 1]\n",
        "Initial columns: Index(['age', 'work-class', 'fnlwgt', 'education', 'education_num',\n",
        "       'marital-status', 'occupation', 'relationship', 'race', 'sex',\n",
        "       'capital-gain', 'capital-loss', 'hours-worked-per-week',\n",
        "       'native-country', 'income'],\n",
        "      dtype='object')\n",
        "'fnlwgt' column dropped.\n",
        "Adjusted 'income' for test data: ['<=50K' '>50K']\n",
        "Categorical features before encoding: ['work-class', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'native-country']\n",
        "Encoded 'income': [0 1]\n",
        "Accuracy: 0.839690436705362\n",
        "Classification Report:\n",
        "              precision    recall  f1-score   support\n",
        "\n",
        "           0       0.89      0.91      0.90     12435\n",
        "           1       0.68      0.62      0.65      3846\n",
        "\n",
        "    accuracy                           0.84     16281\n",
        "   macro avg       0.78      0.76      0.77     16281\n",
        "weighted avg       0.84      0.84      0.84     16281\n"
      ],
      "metadata": {
        "id": "8Fm_yNAz-xsm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WCVcvQIMpXfw",
        "outputId": "a0afb180-4109-457a-a422-6f2391a3b138"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Index(['age', 'work-class', 'fnlwgt', 'education', 'education_num',\n",
              "       'marital-status', 'occupation', 'relationship', 'race', 'sex',\n",
              "       'capital-gain', 'capital-loss', 'hours-worked-per-week',\n",
              "       'native-country', 'income'],\n",
              "      dtype='object')"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_data.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tMD5HMgW0FEO",
        "outputId": "c8c63318-45b9-4392-b96b-439d0da55a41"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial columns: Index(['age', 'work-class', 'fnlwgt', 'education', 'education_num',\n",
            "       'marital-status', 'occupation', 'relationship', 'race', 'sex',\n",
            "       'capital-gain', 'capital-loss', 'hours-worked-per-week',\n",
            "       'native-country', 'income'],\n",
            "      dtype='object')\n",
            "Encoded features: []\n",
            "Encoded 'income': [0 1]\n",
            "Initial columns: Index(['age', 'work-class', 'fnlwgt', 'education', 'education_num',\n",
            "       'marital-status', 'occupation', 'relationship', 'race', 'sex',\n",
            "       'capital-gain', 'capital-loss', 'hours-worked-per-week',\n",
            "       'native-country', 'income'],\n",
            "      dtype='object')\n",
            "Adjusted 'income' for test data: ['<=50K' '>50K']\n",
            "Encoded features: []\n",
            "Encoded 'income': [0 1]\n",
            "Accuracy: 0.8431914501566243\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      0.90      0.90     12435\n",
            "           1       0.67      0.67      0.67      3846\n",
            "\n",
            "    accuracy                           0.84     16281\n",
            "   macro avg       0.78      0.78      0.78     16281\n",
            "weighted avg       0.84      0.84      0.84     16281\n",
            "\n",
            "Accuracy: 0.9999385768250361\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00     24720\n",
            "           1       1.00      1.00      1.00      7841\n",
            "\n",
            "    accuracy                           1.00     32561\n",
            "   macro avg       1.00      1.00      1.00     32561\n",
            "weighted avg       1.00      1.00      1.00     32561\n",
            "\n"
          ]
        }
      ],
      "source": [
        "'''\n",
        "One Hot Encoding Implementation # default, version 3\n",
        "Using Label Encoding, Smote\n",
        "'''\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "# Function to preprocess data using label encoding\n",
        "def preprocess_data(data, encoders=None, is_train=True):\n",
        "    print(\"Initial columns:\", data.columns)  # Initial check of all columns in the dataset\n",
        "\n",
        "    income_column = 'income'\n",
        "    if income_column not in data.columns:\n",
        "        raise ValueError(f\"The column '{income_column}' does not exist in the dataset.\")\n",
        "\n",
        "    # If it's test data, handle the period at the end\n",
        "    if not is_train:\n",
        "        data[income_column] = data[income_column].str.strip().str.replace('.', '')\n",
        "        print(\"Adjusted 'income' for test data:\", data[income_column].unique())  # Debug\n",
        "\n",
        "    # Identify categorical features excluding 'income'\n",
        "    categorical_features = data.select_dtypes(include=['object']).columns.tolist()\n",
        "    if income_column in categorical_features:\n",
        "        categorical_features.remove(income_column)\n",
        "\n",
        "    # Initialize or apply existing label encoders\n",
        "    if encoders is None:\n",
        "        encoders = {}\n",
        "        for feature in categorical_features:\n",
        "            le = LabelEncoder()\n",
        "            data[feature] = le.fit_transform(data[feature])\n",
        "            encoders[feature] = le\n",
        "    else:\n",
        "        for feature, le in encoders.items():\n",
        "            data[feature] = le.transform(data[feature])\n",
        "\n",
        "    print(\"Encoded features:\", categorical_features)  # Debug statement\n",
        "\n",
        "    # Encode the target variable\n",
        "    y = LabelEncoder().fit_transform(data[income_column])\n",
        "    print(\"Encoded 'income':\", np.unique(y))  # Debug the output of the encoded income\n",
        "\n",
        "    # All features are now numeric, so return the numeric dataframe directly\n",
        "    X = data.drop(columns=[income_column]).values\n",
        "\n",
        "    return X, y, encoders\n",
        "\n",
        "# Function to train the Random Forest model with SMOTE\n",
        "def train_random_forest_with_smote(X, y):\n",
        "    # Apply SMOTE\n",
        "    smote = SMOTE(random_state=42)\n",
        "    X_smote, y_smote = smote.fit_resample(X, y)\n",
        "\n",
        "    # Train the Random Forest\n",
        "    model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "    model.fit(X_smote, y_smote)\n",
        "\n",
        "    return model\n",
        "\n",
        "# Evaluate the model\n",
        "def evaluate_model(model, X_test, y_test):\n",
        "    y_pred = model.predict(X_test)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    report = classification_report(y_test, y_pred)\n",
        "\n",
        "    return accuracy, report\n",
        "\n",
        "# Main execution function\n",
        "def main():\n",
        "    # Preprocess training data with Label Encoding\n",
        "    X_train, y_train, encoders = preprocess_data(train_data, is_train=True)\n",
        "\n",
        "    # Train model with SMOTE\n",
        "    smote = SMOTE(random_state=42)\n",
        "    X_smote, y_smote = smote.fit_resample(X_train, y_train)\n",
        "    model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "    model.fit(X_smote, y_smote)\n",
        "\n",
        "    # Preprocess testing data using the same encoders\n",
        "    X_test, y_test, _ = preprocess_data(test_data, encoders, is_train=False)\n",
        "\n",
        "    # Evaluate the model\n",
        "    accuracy, report = evaluate_model(model, X_test, y_test)\n",
        "    print(f'Accuracy: {accuracy}')\n",
        "    print(f'Classification Report:\\n{report}')\n",
        "\n",
        "    # Evaluate the model\n",
        "    accuracy1, report1 = evaluate_model(model, X_train, y_train)\n",
        "    print(f'Accuracy: {accuracy1}')\n",
        "    print(f'Classification Report:\\n{report1}')\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Initial columns: Index(['age', 'work-class', 'fnlwgt', 'education', 'education_num',\n",
        "       'marital-status', 'occupation', 'relationship', 'race', 'sex',\n",
        "       'capital-gain', 'capital-loss', 'hours-worked-per-week',\n",
        "       'native-country', 'income'],\n",
        "      dtype='object')\n",
        "Encoded features: []\n",
        "Encoded 'income': [0 1]\n",
        "Initial columns: Index(['age', 'work-class', 'fnlwgt', 'education', 'education_num',\n",
        "       'marital-status', 'occupation', 'relationship', 'race', 'sex',\n",
        "       'capital-gain', 'capital-loss', 'hours-worked-per-week',\n",
        "       'native-country', 'income'],\n",
        "      dtype='object')\n",
        "Adjusted 'income' for test data: ['<=50K' '>50K']\n",
        "Encoded features: []\n",
        "Encoded 'income': [0 1]\n",
        "Accuracy: 0.8431914501566243\n",
        "Classification Report:\n",
        "              precision    recall  f1-score   support\n",
        "\n",
        "           0       0.90      0.90      0.90     12435\n",
        "           1       0.67      0.67      0.67      3846\n",
        "\n",
        "    accuracy                           0.84     16281\n",
        "   macro avg       0.78      0.78      0.78     16281\n",
        "weighted avg       0.84      0.84      0.84     16281\n",
        "\n",
        "Accuracy: 0.9999385768250361\n",
        "Classification Report:\n",
        "              precision    recall  f1-score   support\n",
        "\n",
        "           0       1.00      1.00      1.00     24720\n",
        "           1       1.00      1.00      1.00      7841\n",
        "\n",
        "    accuracy                           1.00     32561\n",
        "   macro avg       1.00      1.00      1.00     32561\n",
        "weighted avg       1.00      1.00      1.00     32561"
      ],
      "metadata": {
        "id": "0bc0Y3fM-5D2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6JR62yza52JX",
        "outputId": "8b60751f-566c-4e5a-b4e9-7b45fef09015"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial columns: Index(['age', 'work-class', 'fnlwgt', 'education', 'education_num',\n",
            "       'marital-status', 'occupation', 'relationship', 'race', 'sex',\n",
            "       'capital-gain', 'capital-loss', 'hours-worked-per-week',\n",
            "       'native-country', 'income'],\n",
            "      dtype='object')\n",
            "Encoded features: []\n",
            "Encoded 'income': [0 1]\n",
            "Initial columns: Index(['age', 'work-class', 'fnlwgt', 'education', 'education_num',\n",
            "       'marital-status', 'occupation', 'relationship', 'race', 'sex',\n",
            "       'capital-gain', 'capital-loss', 'hours-worked-per-week',\n",
            "       'native-country', 'income'],\n",
            "      dtype='object')\n",
            "Adjusted 'income' for test data: ['<=50K' '>50K']\n",
            "Encoded features: []\n",
            "Encoded 'income': [0 1]\n",
            "Accuracy: 0.8534488053559364\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.93      0.91     12435\n",
            "           1       0.73      0.61      0.66      3846\n",
            "\n",
            "    accuracy                           0.85     16281\n",
            "   macro avg       0.81      0.77      0.78     16281\n",
            "weighted avg       0.85      0.85      0.85     16281\n",
            "\n"
          ]
        }
      ],
      "source": [
        "'''\n",
        "# version 4\n",
        "Using Label Encoding, Without Smote\n",
        "'''\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# Function to preprocess data using label encoding\n",
        "def preprocess_data(data, encoders=None, is_train=True):\n",
        "    print(\"Initial columns:\", data.columns)  # Initial check of all columns in the dataset\n",
        "\n",
        "    income_column = 'income'\n",
        "    if income_column not in data.columns:\n",
        "        raise ValueError(f\"The column '{income_column}' does not exist in the dataset.\")\n",
        "\n",
        "    # If it's test data, handle the period at the end\n",
        "    if not is_train:\n",
        "        data[income_column] = data[income_column].str.strip().str.replace('.', '')\n",
        "        print(\"Adjusted 'income' for test data:\", data[income_column].unique())  # Debug\n",
        "\n",
        "    # Identify categorical features excluding 'income'\n",
        "    categorical_features = data.select_dtypes(include=['object']).columns.tolist()\n",
        "    if income_column in categorical_features:\n",
        "        categorical_features.remove(income_column)\n",
        "\n",
        "    # Initialize or apply existing label encoders\n",
        "    if encoders is None:\n",
        "        encoders = {}\n",
        "        for feature in categorical_features:\n",
        "            le = LabelEncoder()\n",
        "            data[feature] = le.fit_transform(data[feature])\n",
        "            encoders[feature] = le\n",
        "    else:\n",
        "        for feature, le in encoders.items():\n",
        "            data[feature] = le.transform(data[feature])\n",
        "\n",
        "    print(\"Encoded features:\", categorical_features)  # Debug statement\n",
        "\n",
        "    # Encode the target variable\n",
        "    y = LabelEncoder().fit_transform(data[income_column])\n",
        "    print(\"Encoded 'income':\", np.unique(y))  # Debug the output of the encoded income\n",
        "\n",
        "    # All features are now numeric, so return the numeric dataframe directly\n",
        "    X = data.drop(columns=[income_column]).values\n",
        "\n",
        "    return X, y, encoders\n",
        "\n",
        "# Function to train the Random Forest model without SMOTE\n",
        "def train_random_forest(X, y):\n",
        "    # Train the Random Forest without SMOTE\n",
        "    model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "    model.fit(X, y)\n",
        "\n",
        "    return model\n",
        "\n",
        "# Evaluate the model\n",
        "def evaluate_model(model, X_test, y_test):\n",
        "    y_pred = model.predict(X_test)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    report = classification_report(y_test, y_pred)\n",
        "\n",
        "    return accuracy, report\n",
        "\n",
        "# Main execution function\n",
        "def main():\n",
        "    # Preprocess training data with Label Encoding\n",
        "    X_train, y_train, encoders = preprocess_data(train_data, is_train=True)\n",
        "\n",
        "    # Train the Random Forest without SMOTE\n",
        "    model = train_random_forest(X_train, y_train)\n",
        "\n",
        "    # Preprocess testing data using the same encoders\n",
        "    X_test, y_test, _ = preprocess_data(test_data, encoders, is_train=False)\n",
        "\n",
        "    # Evaluate the model\n",
        "    accuracy, report = evaluate_model(model, X_test, y_test)\n",
        "    print(f'Accuracy: {accuracy}')\n",
        "    print(f'Classification Report:\\n{report}')\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Initial columns: Index(['age', 'work-class', 'fnlwgt', 'education', 'education_num',\n",
        "       'marital-status', 'occupation', 'relationship', 'race', 'sex',\n",
        "       'capital-gain', 'capital-loss', 'hours-worked-per-week',\n",
        "       'native-country', 'income'],\n",
        "      dtype='object')\n",
        "Encoded features: []\n",
        "Encoded 'income': [0 1]\n",
        "Initial columns: Index(['age', 'work-class', 'fnlwgt', 'education', 'education_num',\n",
        "       'marital-status', 'occupation', 'relationship', 'race', 'sex',\n",
        "       'capital-gain', 'capital-loss', 'hours-worked-per-week',\n",
        "       'native-country', 'income'],\n",
        "      dtype='object')\n",
        "Adjusted 'income' for test data: ['<=50K' '>50K']\n",
        "Encoded features: []\n",
        "Encoded 'income': [0 1]\n",
        "Accuracy: 0.8534488053559364\n",
        "Classification Report:\n",
        "              precision    recall  f1-score   support\n",
        "\n",
        "           0       0.88      0.93      0.91     12435\n",
        "           1       0.73      0.61      0.66      3846\n",
        "\n",
        "    accuracy                           0.85     16281\n",
        "   macro avg       0.81      0.77      0.78     16281\n",
        "weighted avg       0.85      0.85      0.85     16281\n"
      ],
      "metadata": {
        "id": "ljvmrP0J-9C-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iIqk2ZfsAM2j",
        "outputId": "905189fc-e22e-49b8-9fe6-dcdba753c761"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial columns: Index(['age', 'work-class', 'fnlwgt', 'education', 'education_num',\n",
            "       'marital-status', 'occupation', 'relationship', 'race', 'sex',\n",
            "       'capital-gain', 'capital-loss', 'hours-worked-per-week',\n",
            "       'native-country', 'income'],\n",
            "      dtype='object')\n",
            "Encoded features: ['work-class', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'native-country']\n",
            "Encoded 'income': [0 1]\n",
            "Best Parameters: {'max_depth': 20, 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 100}\n",
            "Initial columns: Index(['age', 'work-class', 'fnlwgt', 'education', 'education_num',\n",
            "       'marital-status', 'occupation', 'relationship', 'race', 'sex',\n",
            "       'capital-gain', 'capital-loss', 'hours-worked-per-week',\n",
            "       'native-country', 'income'],\n",
            "      dtype='object')\n",
            "Adjusted 'income' for test data: ['<=50K' '>50K']\n",
            "Encoded features: ['work-class', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'native-country']\n",
            "Encoded 'income': [0 1]\n",
            "Accuracy: 0.864443216018672\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      0.94      0.91     12435\n",
            "           1       0.77      0.61      0.68      3846\n",
            "\n",
            "    accuracy                           0.86     16281\n",
            "   macro avg       0.83      0.78      0.80     16281\n",
            "weighted avg       0.86      0.86      0.86     16281\n",
            "\n"
          ]
        }
      ],
      "source": [
        "'''\n",
        " # version 5\n",
        "Using Label Encoding, Without Smote\n",
        "Using hyperparameter tuning (gridsearchcv)\n",
        "'''\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Function to preprocess data using label encoding\n",
        "def preprocess_data(data, encoders=None, is_train=True):\n",
        "    print(\"Initial columns:\", data.columns)  # Initial check of all columns in the dataset\n",
        "\n",
        "    income_column = 'income'\n",
        "    if income_column not in data.columns:\n",
        "        raise ValueError(f\"The column '{income_column}' does not exist in the dataset.\")\n",
        "\n",
        "    # If it's test data, handle the period at the end\n",
        "    if not is_train:\n",
        "        data[income_column] = data[income_column].str.strip().str.replace('.', '')\n",
        "        print(\"Adjusted 'income' for test data:\", data[income_column].unique())  # Debug\n",
        "\n",
        "    # Identify categorical features excluding 'income'\n",
        "    categorical_features = data.select_dtypes(include=['object']).columns.tolist()\n",
        "    if income_column in categorical_features:\n",
        "        categorical_features.remove(income_column)\n",
        "\n",
        "    # Initialize or apply existing label encoders\n",
        "    if encoders is None:\n",
        "        encoders = {}\n",
        "        for feature in categorical_features:\n",
        "            le = LabelEncoder()\n",
        "            data[feature] = le.fit_transform(data[feature])\n",
        "            encoders[feature] = le\n",
        "    else:\n",
        "        for feature, le in encoders.items():\n",
        "            data[feature] = le.transform(data[feature])\n",
        "\n",
        "    print(\"Encoded features:\", categorical_features)  # Debug statement\n",
        "\n",
        "    # Encode the target variable\n",
        "    y = LabelEncoder().fit_transform(data[income_column])\n",
        "    print(\"Encoded 'income':\", np.unique(y))  # Debug the output of the encoded income\n",
        "\n",
        "    # All features are now numeric, so return the numeric dataframe directly\n",
        "    X = data.drop(columns=[income_column]).values\n",
        "\n",
        "    return X, y, encoders\n",
        "\n",
        "# Function to perform hyperparameter tuning with RandomForestClassifier\n",
        "def train_random_forest_with_tuning(X, y):\n",
        "    # Define parameter grid for hyperparameter tuning\n",
        "    param_grid = {\n",
        "        'n_estimators': [50, 100, 200],\n",
        "        'max_depth': [5, 10, 20, None],\n",
        "        'min_samples_split': [2, 5, 10],\n",
        "        'min_samples_leaf': [1, 2, 4]\n",
        "    }\n",
        "\n",
        "    # Initialize RandomForestClassifier\n",
        "    rf = RandomForestClassifier(random_state=42)\n",
        "\n",
        "    # Use GridSearchCV for hyperparameter tuning\n",
        "    grid_search = GridSearchCV(estimator=rf, param_grid=param_grid, cv=5, n_jobs=-1, scoring='accuracy')\n",
        "    grid_search.fit(X, y)\n",
        "\n",
        "    # Return the best model\n",
        "    print(f\"Best Parameters: {grid_search.best_params_}\")\n",
        "    return grid_search.best_estimator_\n",
        "\n",
        "# Evaluate the model\n",
        "def evaluate_model(model, X_test, y_test):\n",
        "    y_pred = model.predict(X_test)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    report = classification_report(y_test, y_pred)\n",
        "\n",
        "    return accuracy, report\n",
        "\n",
        "# Main execution function\n",
        "def main():\n",
        "    # Preprocess training data with Label Encoding\n",
        "    X_train, y_train, encoders = preprocess_data(train_data, is_train=True)\n",
        "\n",
        "    # Train the Random Forest with hyperparameter tuning\n",
        "    model = train_random_forest_with_tuning(X_train, y_train)\n",
        "\n",
        "    # Preprocess testing data using the same encoders\n",
        "    X_test, y_test, _ = preprocess_data(test_data, encoders, is_train=False)\n",
        "\n",
        "    # Evaluate the model\n",
        "    accuracy, report = evaluate_model(model, X_test, y_test)\n",
        "    print(f'Accuracy: {accuracy}')\n",
        "    print(f'Classification Report:\\n{report}')\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Version 7: no smote, OHE, using parameters\n",
        "'''\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "\n",
        "# Assuming train_data and test_data are already loaded as dataframes\n",
        "# train_data, test_data\n",
        "\n",
        "# Function to preprocess data\n",
        "def preprocess_data(data, transformer=None, is_train=True):\n",
        "    print(\"Initial columns:\", data.columns)  # Initial check of all columns in the dataset\n",
        "\n",
        "    income_column = 'income'\n",
        "    if income_column not in data.columns:\n",
        "        raise ValueError(f\"The column '{income_column}' does not exist in the dataset.\")\n",
        "\n",
        "    # If it's test data, handle the period at the end\n",
        "    if not is_train:\n",
        "        data[income_column] = data[income_column].str.strip().str.replace('.', '')\n",
        "        print(\"Adjusted 'income' for test data:\", data[income_column].unique())  # Debug\n",
        "\n",
        "    # Identify and store categorical features excluding 'income'\n",
        "    categorical_features = data.select_dtypes(include=['object']).columns.tolist()\n",
        "    if income_column in categorical_features:\n",
        "        categorical_features.remove(income_column)\n",
        "    print(\"Categorical features before encoding:\", categorical_features)  # Debug statement\n",
        "\n",
        "    # Apply ColumnTransformer only to categorical features excluding 'income'\n",
        "    if transformer is None:\n",
        "        transformer = ColumnTransformer(\n",
        "            transformers=[('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)],\n",
        "            remainder='passthrough')\n",
        "        X = transformer.fit_transform(data.drop(columns=[income_column]))\n",
        "    else:\n",
        "        X = transformer.transform(data.drop(columns=[income_column]))\n",
        "\n",
        "    # Now encode the 'income' column after categorical handling\n",
        "    y = LabelEncoder().fit_transform(data[income_column])\n",
        "    print(\"Encoded 'income':\", np.unique(y))  # Debug the output of the encoded income\n",
        "\n",
        "    return X, y, transformer\n",
        "\n",
        "# Function to train the Random Forest model with specified hyperparameters\n",
        "def train_random_forest(X, y):\n",
        "    # Initialize the RandomForestClassifier with the desired hyperparameters\n",
        "    model = RandomForestClassifier(\n",
        "        n_estimators=100,\n",
        "        max_depth=10,\n",
        "        min_samples_leaf=1,\n",
        "        min_samples_split=2,\n",
        "        bootstrap=True,\n",
        "        random_state=42\n",
        "    )\n",
        "    model.fit(X, y)\n",
        "\n",
        "    return model\n",
        "\n",
        "# Evaluate the model\n",
        "def evaluate_model(model, X_test, y_test):\n",
        "    y_pred = model.predict(X_test)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    report = classification_report(y_test, y_pred)\n",
        "\n",
        "    return accuracy, report\n",
        "\n",
        "# Main execution function\n",
        "def main():\n",
        "    # Preprocess training data\n",
        "    X_train, y_train, transformer = preprocess_data(train_data, is_train=True)\n",
        "\n",
        "    # Train model using specified hyperparameters\n",
        "    model = train_random_forest(X_train, y_train)\n",
        "\n",
        "    # Preprocess testing data using the same transformer\n",
        "    X_test, y_test, _ = preprocess_data(test_data, transformer, is_train=False)\n",
        "\n",
        "    # Evaluate the model on the test data\n",
        "    accuracy, report = evaluate_model(model, X_test, y_test)\n",
        "    print(f'Accuracy (Test Data): {accuracy}')\n",
        "    print(f'Classification Report (Test Data):\\n{report}')\n",
        "\n",
        "    # Evaluate the model on the training data\n",
        "    accuracy_train, report_train = evaluate_model(model, X_train, y_train)\n",
        "    print(f'Accuracy (Training Data): {accuracy_train}')\n",
        "    print(f'Classification Report (Training Data):\\n{report_train}')\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    # Load your datasets (replace with actual file paths)\n",
        "    # train_data = pd.read_csv('./census-income.data (3).csv')\n",
        "    # test_data = pd.read_csv('./census-income.test (2).csv')\n",
        "\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z9rRIQM5oOMF",
        "outputId": "6c16385d-f73a-4682-9d4e-f1a918f8a235"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial columns: Index(['age', 'work-class', 'fnlwgt', 'education', 'education_num',\n",
            "       'marital-status', 'occupation', 'relationship', 'race', 'sex',\n",
            "       'capital-gain', 'capital-loss', 'hours-worked-per-week',\n",
            "       'native-country', 'income'],\n",
            "      dtype='object')\n",
            "Categorical features before encoding: ['work-class', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'native-country']\n",
            "Encoded 'income': [0 1]\n",
            "Initial columns: Index(['age', 'work-class', 'fnlwgt', 'education', 'education_num',\n",
            "       'marital-status', 'occupation', 'relationship', 'race', 'sex',\n",
            "       'capital-gain', 'capital-loss', 'hours-worked-per-week',\n",
            "       'native-country', 'income'],\n",
            "      dtype='object')\n",
            "Adjusted 'income' for test data: ['<=50K' '>50K']\n",
            "Categorical features before encoding: ['work-class', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'native-country']\n",
            "Encoded 'income': [0 1]\n",
            "Accuracy (Test Data): 0.8579325594250967\n",
            "Classification Report (Test Data):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.96      0.91     12435\n",
            "           1       0.79      0.54      0.64      3846\n",
            "\n",
            "    accuracy                           0.86     16281\n",
            "   macro avg       0.83      0.75      0.78     16281\n",
            "weighted avg       0.85      0.86      0.85     16281\n",
            "\n",
            "Accuracy (Training Data): 0.8641012253923406\n",
            "Classification Report (Training Data):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.96      0.91     24720\n",
            "           1       0.82      0.56      0.66      7841\n",
            "\n",
            "    accuracy                           0.86     32561\n",
            "   macro avg       0.85      0.76      0.79     32561\n",
            "weighted avg       0.86      0.86      0.85     32561\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Model 3: Balanced dataset (Smote), O.H.E. and Hyperparameter\n",
        "tuning (focused on accuracy), in the balanced dataset\n",
        "Using: ACCURACY focused prediction\n",
        "'''\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "\n",
        "def preprocess_data(data, transformer=None, is_train=True):\n",
        "    print(\"Initial columns:\", data.columns)\n",
        "\n",
        "    income_column = 'income'\n",
        "    if income_column not in data.columns:\n",
        "        raise ValueError(f\"The column '{income_column}' does not exist in the dataset.\")\n",
        "\n",
        "    # Convert 'income' to string explicitly to avoid AttributeError\n",
        "    data[income_column] = data[income_column].astype(str)\n",
        "\n",
        "    # If it's test data, handle the period at the end\n",
        "    if not is_train:\n",
        "        data[income_column] = data[income_column].str.strip().str.replace('.', '', regex=False)\n",
        "        print(\"Adjusted 'income' for test data:\", data[income_column].unique())\n",
        "\n",
        "    # Identify and store categorical features excluding 'income'\n",
        "    categorical_features = data.select_dtypes(include=['object']).columns.tolist()\n",
        "    if income_column in categorical_features:\n",
        "        categorical_features.remove(income_column)\n",
        "    print(\"Categorical features before encoding:\", categorical_features)\n",
        "\n",
        "    # Apply ColumnTransformer only to categorical features excluding 'income'\n",
        "    if transformer is None:\n",
        "        transformer = ColumnTransformer(\n",
        "            transformers=[('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)],\n",
        "            remainder='passthrough')\n",
        "        X = transformer.fit_transform(data.drop(columns=[income_column]))\n",
        "    else:\n",
        "        X = transformer.transform(data.drop(columns=[income_column]))\n",
        "\n",
        "    # Now encode the 'income' column after categorical handling\n",
        "    y = LabelEncoder().fit_transform(data[income_column])\n",
        "    print(\"Encoded 'income':\", np.unique(y))  # Debug the output of the encoded income\n",
        "\n",
        "    return X, y, transformer\n",
        "\n",
        "# Function to train the Random Forest model with SMOTE\n",
        "def train_random_forest_with_smote(X, y):\n",
        "    # Apply SMOTE\n",
        "    smote = SMOTE(random_state=42)\n",
        "    X_smote, y_smote = smote.fit_resample(X, y)\n",
        "\n",
        "    # Define the Random Forest model with specified hyperparameters\n",
        "    model = RandomForestClassifier(\n",
        "        n_estimators=100,\n",
        "        max_depth=20,\n",
        "        min_samples_leaf=1,\n",
        "        min_samples_split=10,\n",
        "        bootstrap=False,\n",
        "        random_state=42\n",
        "    )\n",
        "\n",
        "    # Train (fit) the model using the resampled data\n",
        "    model.fit(X_smote, y_smote)\n",
        "    return model\n",
        "\n",
        "# Function to evaluate the model\n",
        "def evaluate_model(model, X_test, y_test):\n",
        "    y_pred = model.predict(X_test)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    report = classification_report(y_test, y_pred)\n",
        "\n",
        "    return accuracy, report\n",
        "\n",
        "# Main execution function\n",
        "def main():\n",
        "    # Preprocess training data\n",
        "    X_train, y_train, transformer = preprocess_data(train_data, is_train=True)\n",
        "\n",
        "    # Train model with SMOTE and specified hyperparameters\n",
        "    model = train_random_forest_with_smote(X_train, y_train)\n",
        "\n",
        "    # Preprocess testing data using the same transformer\n",
        "    X_test, y_test, _ = preprocess_data(test_data, transformer, is_train=False)\n",
        "\n",
        "    # Evaluate the test model\n",
        "    accuracy, report = evaluate_model(model, X_test, y_test)\n",
        "    print(f'Accuracy test: {accuracy}')\n",
        "    print(f'Classification Report test:\\n{report}')\n",
        "\n",
        "    # Evaluate the training model\n",
        "    accuracy_train, report_train = evaluate_model(model, X_train, y_train)\n",
        "    print(f'Accuracy train: {accuracy_train}')\n",
        "    print(f'Classification Report train:\\n{report_train}')\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Trar2XqZihM-",
        "outputId": "0d403791-888d-46b1-cf73-ac39504a2190"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial columns: Index(['Unnamed: 0', 'age', 'work-class', 'fnlwgt', 'education_num',\n",
            "       'marital-status', 'relationship', 'race', 'sex', 'capital-gain',\n",
            "       'capital-loss', 'hours-worked-per-week', 'native-country', 'occupation',\n",
            "       'income'],\n",
            "      dtype='object')\n",
            "Categorical features before encoding: []\n",
            "Encoded 'income': [0 1]\n",
            "Initial columns: Index(['Unnamed: 0', 'age', 'work-class', 'fnlwgt', 'education_num',\n",
            "       'marital-status', 'relationship', 'race', 'sex', 'capital-gain',\n",
            "       'capital-loss', 'hours-worked-per-week', 'native-country', 'occupation',\n",
            "       'income'],\n",
            "      dtype='object')\n",
            "Adjusted 'income' for test data: ['0' '1']\n",
            "Categorical features before encoding: []\n",
            "Encoded 'income': [0 1]\n",
            "Accuracy test: 0.8544315459738345\n",
            "Classification Report test:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      0.91      0.91     12435\n",
            "           1       0.70      0.67      0.69      3846\n",
            "\n",
            "    accuracy                           0.85     16281\n",
            "   macro avg       0.80      0.79      0.80     16281\n",
            "weighted avg       0.85      0.85      0.85     16281\n",
            "\n",
            "Accuracy train: 0.9324345075396947\n",
            "Classification Report train:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.96      0.96     24720\n",
            "           1       0.87      0.85      0.86      7841\n",
            "\n",
            "    accuracy                           0.93     32561\n",
            "   macro avg       0.91      0.91      0.91     32561\n",
            "weighted avg       0.93      0.93      0.93     32561\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Model 4: Balanced dataset (SMOTE), O.H.E. and Hyperparameter\n",
        "tuning (focused on a balance), in the balanced dataset\n",
        "Using: BALANCED focused prediction\n",
        "'''\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "# Preprocessing data\n",
        "def preprocess_data(data, transformer=None, is_train=True):\n",
        "    print(\"Initial columns:\", data.columns)\n",
        "\n",
        "    income_column = 'income'\n",
        "    if income_column not in data.columns:\n",
        "        raise ValueError(f\"The column '{income_column}' does not exist in the dataset.\")\n",
        "\n",
        "    # Convert 'income' to string explicitly to avoid AttributeError\n",
        "    data[income_column] = data[income_column].astype(str)\n",
        "\n",
        "    # If it's test data, handle the period at the end\n",
        "    if not is_train:\n",
        "        data[income_column] = data[income_column].str.strip().str.replace('.', '', regex=False)\n",
        "        print(\"Adjusted 'income' for test data:\", data[income_column].unique())\n",
        "\n",
        "    # Identify and store categorical features excluding 'income'\n",
        "    categorical_features = data.select_dtypes(include=['object']).columns.tolist()\n",
        "    if income_column in categorical_features:\n",
        "        categorical_features.remove(income_column)\n",
        "    print(\"Categorical features before encoding:\", categorical_features)\n",
        "\n",
        "    # Apply ColumnTransformer only to categorical features excluding 'income'\n",
        "    if transformer is None:\n",
        "        transformer = ColumnTransformer(\n",
        "            transformers=[('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)],\n",
        "            remainder='passthrough')\n",
        "        X = transformer.fit_transform(data.drop(columns=[income_column]))\n",
        "    else:\n",
        "        X = transformer.transform(data.drop(columns=[income_column]))\n",
        "\n",
        "    # Now encode the 'income' column after categorical handling\n",
        "    y = LabelEncoder().fit_transform(data[income_column])\n",
        "    print(\"Encoded 'income':\", np.unique(y))\n",
        "\n",
        "    return X, y, transformer\n",
        "\n",
        "# Function to train the Random Forest model with SMOTE\n",
        "def train_random_forest_with_smote(X, y):\n",
        "    # Apply SMOTE\n",
        "    smote = SMOTE(random_state=42)\n",
        "    X_smote, y_smote = smote.fit_resample(X, y)\n",
        "\n",
        "    # Define the Random Forest model with specified hyperparameters\n",
        "    model = RandomForestClassifier(\n",
        "        n_estimators=100,\n",
        "        max_depth=10,\n",
        "        min_samples_leaf=1,\n",
        "        min_samples_split=2,\n",
        "        bootstrap=False,\n",
        "        random_state=42\n",
        "    )\n",
        "\n",
        "    # Train (fit) the model using the resampled data\n",
        "    model.fit(X_smote, y_smote)\n",
        "    return model\n",
        "\n",
        "# Function to evaluate the model\n",
        "def evaluate_model(model, X_test, y_test):\n",
        "    y_pred = model.predict(X_test)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    report = classification_report(y_test, y_pred)\n",
        "\n",
        "    return accuracy, report\n",
        "\n",
        "# Main execution function\n",
        "def main():\n",
        "    # Preprocess training data\n",
        "    X_train, y_train, transformer = preprocess_data(train_data, is_train=True)\n",
        "\n",
        "    # Train model with SMOTE and specified hyperparameters\n",
        "    model = train_random_forest_with_smote(X_train, y_train)\n",
        "\n",
        "    # Preprocess testing data using the same transformer\n",
        "    X_test, y_test, _ = preprocess_data(test_data, transformer, is_train=False)\n",
        "\n",
        "    # Evaluate the test model\n",
        "    accuracy, report = evaluate_model(model, X_test, y_test)\n",
        "    print(f'Accuracy test: {accuracy}')\n",
        "    print(f'Classification Report test:\\n{report}')\n",
        "\n",
        "    # Evaluate the training model\n",
        "    accuracy_train, report_train = evaluate_model(model, X_train, y_train)\n",
        "    print(f'Accuracy train: {accuracy_train}')\n",
        "    print(f'Classification Report train:\\n{report_train}')\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GqhnA20jlQpD",
        "outputId": "33f44aff-38c1-4d1c-dfbc-6415f559dd70"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial columns: Index(['Unnamed: 0', 'age', 'work-class', 'fnlwgt', 'education_num',\n",
            "       'marital-status', 'relationship', 'race', 'sex', 'capital-gain',\n",
            "       'capital-loss', 'hours-worked-per-week', 'native-country', 'occupation',\n",
            "       'income'],\n",
            "      dtype='object')\n",
            "Categorical features before encoding: []\n",
            "Encoded 'income': [0 1]\n",
            "Initial columns: Index(['Unnamed: 0', 'age', 'work-class', 'fnlwgt', 'education_num',\n",
            "       'marital-status', 'relationship', 'race', 'sex', 'capital-gain',\n",
            "       'capital-loss', 'hours-worked-per-week', 'native-country', 'occupation',\n",
            "       'income'],\n",
            "      dtype='object')\n",
            "Adjusted 'income' for test data: ['0' '1']\n",
            "Categorical features before encoding: []\n",
            "Encoded 'income': [0 1]\n",
            "Accuracy test: 0.8414102327866838\n",
            "Classification Report test:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.91      0.88      0.89     12435\n",
            "           1       0.65      0.72      0.68      3846\n",
            "\n",
            "    accuracy                           0.84     16281\n",
            "   macro avg       0.78      0.80      0.79     16281\n",
            "weighted avg       0.85      0.84      0.84     16281\n",
            "\n",
            "Accuracy train: 0.8510488007125089\n",
            "Classification Report train:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.88      0.90     24720\n",
            "           1       0.67      0.75      0.71      7841\n",
            "\n",
            "    accuracy                           0.85     32561\n",
            "   macro avg       0.79      0.82      0.80     32561\n",
            "weighted avg       0.86      0.85      0.85     32561\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mu-dDj1J6W4K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HB8i-cac7Exh"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "Code block to replace missing values with mode\n",
        "'''\n",
        "\n",
        "# This function takes a dataframe and returns * A MODIFIED COPY *. Doesn't change the original\n",
        "def replace_question_marks(df, columns_to_replace):\n",
        "    most_common_elements = {}\n",
        "    most_common_counts = {}\n",
        "    df_copy = df.copy()  # Create a copy of the original DataFrame\n",
        "\n",
        "    for col in columns_to_replace:\n",
        "        # Find the most common element and its count in the column\n",
        "        value_counts = df[col].value_counts()\n",
        "        most_common = value_counts.idxmax()\n",
        "        most_common_count = value_counts.max()\n",
        "\n",
        "        most_common_elements[col] = most_common\n",
        "        most_common_counts[col] = most_common_count\n",
        "\n",
        "        # Replace ' ?' with the most common element in the column\n",
        "        df_copy[col] = df_copy[col].replace(' ?', most_common)\n",
        "\n",
        "    return df_copy, most_common_elements, most_common_counts\n",
        "\n",
        "columns_to_replace = ['work-class', 'occupation', 'native-country']\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN+o23/a/b6D+k03AQ4Ccf6",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}